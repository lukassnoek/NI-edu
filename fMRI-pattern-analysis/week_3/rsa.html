

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Representational Similarity Analysis &#8212; NI-edu</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=12da95d707ffb74b382d" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=12da95d707ffb74b382d" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d" />

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'fMRI-pattern-analysis/week_3/rsa';</script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Bibliography" href="../../misc/bibliography.html" />
    <link rel="prev" title="Machine learning (“decoding”) analyses" href="../week_2/decoding_analyses.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../index.html">
  
  
  
  
    
    
      
    
    
    <img src="../../_static/fmri.gif" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../../_static/fmri.gif" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to NI-edu
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/about.html">About this course</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../getting_started/installation.html">Installation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">fMRI-introduction</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/1_python.html">Python for (f)MRI analysis</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../other/python_recap.html">Python recap</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_1/python_for_mri.html">Working with MRI data in Python (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/2_glm.html">Using the GLM to model fMRI data</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_2/glm_part1_estimation.html">The GLM: estimation (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_3/glm_part2_inference.html">The GLM: inference (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/3_design_of_experiments_T.html">Design of experiments</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_3/design_of_experiments.html">Design of experiments (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_3/neurodesign.html">Neurodesign (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/4_preprocessing.html">Preprocessing</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_4/temporal_preprocessing.html">Temporal preprocessing (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_4/spatial_preprocessing.html">Spatial preprocessing (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_4/fmriprep.html">Fmriprep (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/5_multilevel.html">First &amp; run-level analyses</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_5/linux_and_the_command_line.html">Linux and the CMD (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_5/first_level_analyses.html">First level analyses (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_5/run_level_analyses.html">Run-level analyses (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/6_grouplevel.html">Group-level analyses</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_6/group_level_analyses.html">Group-level analyses (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_6/MCC.html">Multiple comparison correction (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_6/ROI_analysis.html">ROI analysis (T)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../section_intros/7_nilearn.html">Introduction to Nilearn</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_7/nilearn.html">Introduction to Nilearn (T)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../fMRI-introduction/week_7/nilearn_stats.html">Statistics with Nilearn (T)</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">fMRI-pattern-analysis</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../week_1/design_and_pattern_estimation.html">Design and pattern estimation (T)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../week_2/decoding_analyses.html">Machine learning/decoding (T)</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Representational Similarity Analysis (T)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Misc</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../misc/bibliography.html">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../misc/for_educators.html">For educators</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../misc/CONTRIBUTING.html">Contributing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../misc/CONDUCT.html">Code of Conduct</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/lukassnoek/NI-edu/master?urlpath=tree/NI-edu/fMRI-pattern-analysis/week_3/rsa.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://neuroimaging.lukas-snoek.com/hub/user-redirect/git-pull?repo=https%3A//github.com/lukassnoek/NI-edu&urlpath=tree/NI-edu/NI-edu/fMRI-pattern-analysis/week_3/rsa.ipynb&branch=master" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onJupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/lukassnoek/NI-edu" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/lukassnoek/NI-edu/edit/master/NI-edu/fMRI-pattern-analysis/week_3/rsa.ipynb" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/lukassnoek/NI-edu/issues/new?title=Issue%20on%20page%20%2FfMRI-pattern-analysis/week_3/rsa.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/fMRI-pattern-analysis/week_3/rsa.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Representational Similarity Analysis</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-in-the-data">Loading in the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-noise-normalization">Multivariate noise normalization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-rdms">Neural RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-analysis-using-mds">Exploratory analysis using MDS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-rdms">Categorical RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-computational-rdms">Continuous/computational RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-rdms">Testing RDMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-based-tests">Correlation-based tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reweighting-rdvs">Reweighting RDVs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#group-level-analyses">Group-level analyses</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <div class="tex2jax_ignore mathjax_ignore section" id="representational-similarity-analysis">
<h1>Representational Similarity Analysis<a class="headerlink" href="#representational-similarity-analysis" title="Permalink to this heading">#</a></h1>
<p>This week’s tutorial is about Representational Similarity Analysis (RSA)! We’ll be looking at how to transform patterns into RDMs using various distance measures, how to test the relation between “feature RDMs” and “brain RDMs”, and take a look at exploratory RDM visualization using multidimensional-scaling (MDS).</p>
<p><strong>What you’ll learn</strong>: At the end of this tutorial, you …</p>
<ul class="simple">
<li><p>know how to preprocess patterns for RSA</p></li>
<li><p>understand the concept of an RDM and how it can be computed</p></li>
<li><p>can list different types of candidate RDMs and their differences</p></li>
<li><p>are able to test the association between candidate and neural RDMs</p></li>
</ul>
<p><strong>Estimated time needed to complete</strong>: 8-12 hours</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Some imports for the rest of the tutorial</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">nibabel</span> <span class="k">as</span> <span class="nn">nib</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">glob</span> <span class="kn">import</span> <span class="n">glob</span>
<span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span><span class="p">,</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">plotting</span><span class="p">,</span> <span class="n">masking</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="loading-in-the-data">
<h2>Loading in the data<a class="headerlink" href="#loading-in-the-data" title="Permalink to this heading">#</a></h2>
<p>In this notebook, we are going to work with real data straightaway! Like in the previous decoding tutorial, we’ll work only with the data from a single run, though. In addition, to not use too much RAM, we’ll analyze only the data from an specific ROI. In contrast to last week, we are going to use a “functional ROI” based on the localizer data from our “flocBLOCKED” task. To derive a functional ROI, we already computed (for each subject) multiple contrasts and the associated whole-brain <span class="math notranslate nohighlight">\(z\)</span>-score maps in both subject “native” space (<em>T1w</em>) and standard space (<em>MNI152NLin2009cAsym</em>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~&#39;</span><span class="p">),</span> <span class="s1">&#39;NI-edu-data&#39;</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading ROIs for sub-003 (+- 5 MB) ...&quot;</span><span class="p">)</span>
<span class="o">!</span>aws<span class="w"> </span>s3<span class="w"> </span>sync<span class="w"> </span>--no-sign-request<span class="w"> </span>s3://openneuro.org/ds003965<span class="w"> </span><span class="o">{</span>data_dir<span class="o">}</span><span class="w"> </span>--exclude<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;derivatives/floc/*&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading ROIs for sub-003 (+- 5 MB) ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">floc_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span> <span class="s1">&#39;floc&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-03&#39;</span><span class="p">,</span> <span class="s1">&#39;rois&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;We have the following maps:</span><span class="se">\n</span><span class="s2">-&quot;</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">- &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">floc_dir</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>We have the following maps:
- sub-03_task-flocBLOCKED_space-MNI152NLin2009cAsym_desc-body_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-MNI152NLin2009cAsym_desc-character_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-MNI152NLin2009cAsym_desc-face_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-MNI152NLin2009cAsym_desc-place_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-T1w_desc-body_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-T1w_desc-character_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-T1w_desc-face_zscore.nii.gz
- sub-03_task-flocBLOCKED_space-T1w_desc-place_zscore.nii.gz
</pre></div>
</div>
</div>
</div>
<p>These maps have been computed using a “condition &gt; other conditions”. We are, of course, going to use the “face &gt; (place, character, body, object)” map for our ROI and use the data in MNI space:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">floc_roi</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">floc_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03_task-flocBLOCKED_space-MNI152NLin2009cAsym_desc-face_zscore.nii.gz&#39;</span><span class="p">)</span>

<span class="c1"># Let&#39;s plot the unthresholded map as well</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span><span class="n">floc_roi</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;nilearn.plotting.displays._slicers.OrthoSlicer at 0x13c689310&gt;
</pre></div>
</div>
<img alt="../../_images/db6198ab3fdcf9d5e291a24401138ae4f78f2e6be97dc0317f38aa4cfbc1856c.png" src="../../_images/db6198ab3fdcf9d5e291a24401138ae4f78f2e6be97dc0317f38aa4cfbc1856c.png" />
</div>
</div>
<p>As you can see in the plot above, this subject shows a strong response to faces (relative to other conditions) in right temporal lobe, just where you’d expect to find the fusiform face area (FFA). But to derive an ROI from this map, we should somehow binarize this image. While this choice is somewhat arbitrary, let’s threshold this map at <span class="math notranslate nohighlight">\(z &gt; 3\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">floc_roi_bin</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">math_img</span><span class="p">(</span><span class="s1">&#39;(img &gt; 3).astype(np.int32)&#39;</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">floc_roi</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">floc_roi_bin</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d181ce9f359a3d3e1650c66e571d193648c90931526031161c12e29810ccc324.png" src="../../_images/d181ce9f359a3d3e1650c66e571d193648c90931526031161c12e29810ccc324.png" />
</div>
</div>
<p>The current ROI, however, contains <em>a lot</em> of voxels, also many far outside the location of where we’d expect the FFA. One “trick” we can use to further restrict the number of voxels is to constrain our functional ROI to a particular anatomical location. Here, we’ll pick the right temporal ocipital fusiform (rTOF):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ho_atlas</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">fetch_atlas_harvard_oxford</span><span class="p">(</span><span class="s1">&#39;cort-maxprob-thr25-2mm&#39;</span><span class="p">,</span> <span class="n">symmetric_split</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ho_map</span> <span class="o">=</span> <span class="n">ho_atlas</span><span class="p">[</span><span class="s1">&#39;maps&#39;</span><span class="p">]</span>
<span class="n">rTOF_idx</span> <span class="o">=</span> <span class="n">ho_atlas</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;Right Temporal Occipital Fusiform Cortex&#39;</span><span class="p">)</span>
<span class="n">rTOF_roi</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">((</span><span class="n">ho_map</span><span class="o">.</span><span class="n">get_fdata</span><span class="p">()</span> <span class="o">==</span> <span class="n">rTOF_idx</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">),</span> <span class="n">ho_map</span><span class="o">.</span><span class="n">affine</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">rTOF_roi</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/828c45d416b244f07dac0aeb69cea7adc242f8bcae07040276e0c0ca671f2450.png" src="../../_images/828c45d416b244f07dac0aeb69cea7adc242f8bcae07040276e0c0ca671f2450.png" />
</div>
</div>
<p>Note that the anatomical ROI has a slightly higher spatial resolution (2 mm<span class="math notranslate nohighlight">\(^2\)</span>, instead of <span class="math notranslate nohighlight">\(2.7 \times 2.7 \times 2.97\)</span>). As such, we need to resample the anatomical mask to our functional resolution:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rTOF_roi_resamp</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resample_to_img</span><span class="p">(</span><span class="n">rTOF_roi</span><span class="p">,</span> <span class="n">floc_roi_bin</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we can intersect the two masks using the <code class="docutils literal notranslate"><span class="pre">intersect_masks</span></code> from the Nilearn <code class="docutils literal notranslate"><span class="pre">masking</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Setting the threshold to 1 means: only select voxels that are in *both* masks</span>
<span class="n">ffa_mask</span> <span class="o">=</span> <span class="n">masking</span><span class="o">.</span><span class="n">intersect_masks</span><span class="p">((</span><span class="n">floc_roi_bin</span><span class="p">,</span> <span class="n">rTOF_roi_resamp</span><span class="p">),</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">ffa_mask</span><span class="p">,</span> <span class="n">cut_coords</span><span class="o">=</span><span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">46</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">));</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/f90add37b420906c992fff7eca3237ffa6e1acf7b99bf1ae30d9a07ccd8d64f0.png" src="../../_images/f90add37b420906c992fff7eca3237ffa6e1acf7b99bf1ae30d9a07ccd8d64f0.png" />
</div>
</div>
<p>Alright, now let’s download the patterns from sub-03, run 1 (if not downloaded already):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Download the patterns (if not done already)</span>
<span class="o">!</span>aws<span class="w"> </span>s3<span class="w"> </span>sync<span class="w"> </span>--no-sign-request<span class="w"> </span>s3://openneuro.org/ds003965<span class="w"> </span><span class="o">{</span>data_dir<span class="o">}</span><span class="w"> </span>--exclude<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;derivatives/pattern_estimation/sub-03/ses-1/patterns/*&quot;</span>
</pre></div>
</div>
</div>
</div>
<p>… and load them in:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">patterns_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span> <span class="s1">&#39;pattern_estimation&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-03&#39;</span><span class="p">,</span> <span class="s1">&#39;ses-1&#39;</span><span class="p">,</span> <span class="s1">&#39;patterns&#39;</span><span class="p">)</span>
<span class="n">betas_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">patterns_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz&#39;</span><span class="p">)</span>

<span class="c1"># Load 4D array and immediately mask it</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">masking</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">betas_path</span><span class="p">,</span> <span class="n">ffa_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of R:&quot;</span><span class="p">,</span> <span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">aspect</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Voxels&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Samples (trials)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\mathbf</span><span class="si">{R}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of R: (40, 70)
</pre></div>
</div>
<img alt="../../_images/2edf86a0d306485f86fa8a7ddb733d675d863492baa404953f167603eba09eb9.png" src="../../_images/2edf86a0d306485f86fa8a7ddb733d675d863492baa404953f167603eba09eb9.png" />
</div>
</div>
<p>Lastly, we need some experimental variable(s) to relate to this brain pattern. For convenience, we included the events file in the same directory as the estimated (variance of the) patterns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">events_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">patterns_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03_ses-1_task-face_run-1_events.tsv&#39;</span><span class="p">)</span>
<span class="n">events_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">events_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Let&#39;s remove the rating/response events</span>
<span class="c1"># The .query method is great for filtering!</span>
<span class="n">events_df</span> <span class="o">=</span> <span class="n">events_df</span><span class="o">.</span><span class="n">query</span><span class="p">(</span><span class="s2">&quot;trial_type != &#39;rating&#39; and trial_type != &#39;response&#39;&quot;</span><span class="p">)</span>
<span class="n">events_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>onset</th>
      <th>duration</th>
      <th>trial_type</th>
      <th>expression</th>
      <th>face_id</th>
      <th>face_age</th>
      <th>face_sex</th>
      <th>face_eth</th>
      <th>average_attractiveness</th>
      <th>catch</th>
      <th>rating_score</th>
      <th>response_hand</th>
      <th>subject_attractiveness</th>
      <th>subject_dominance</th>
      <th>subject_trustworthiness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>6.022445</td>
      <td>1.233307</td>
      <td>00STIM117smiling</td>
      <td>smiling</td>
      <td>117.0</td>
      <td>26.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.485729</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.9900</td>
      <td>1.1850</td>
      <td>1.3625</td>
    </tr>
    <tr>
      <th>1</th>
      <td>11.022318</td>
      <td>1.233310</td>
      <td>01STIM027smiling</td>
      <td>smiling</td>
      <td>27.0</td>
      <td>26.0</td>
      <td>female</td>
      <td>white</td>
      <td>1.772827</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.1325</td>
      <td>0.6525</td>
      <td>1.1575</td>
    </tr>
    <tr>
      <th>2</th>
      <td>16.022165</td>
      <td>1.233322</td>
      <td>02STIM027neutral</td>
      <td>neutral</td>
      <td>27.0</td>
      <td>26.0</td>
      <td>female</td>
      <td>white</td>
      <td>1.772827</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.1325</td>
      <td>0.6525</td>
      <td>1.1575</td>
    </tr>
    <tr>
      <th>3</th>
      <td>21.022053</td>
      <td>1.233282</td>
      <td>03STIM092smiling</td>
      <td>smiling</td>
      <td>92.0</td>
      <td>32.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.932899</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.2825</td>
      <td>-0.9725</td>
      <td>-0.3100</td>
    </tr>
    <tr>
      <th>4</th>
      <td>26.021899</td>
      <td>1.233297</td>
      <td>04STIM066neutral</td>
      <td>neutral</td>
      <td>66.0</td>
      <td>22.0</td>
      <td>female</td>
      <td>west_asian</td>
      <td>0.637872</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1250</td>
      <td>2.1400</td>
      <td>2.1300</td>
    </tr>
    <tr>
      <th>5</th>
      <td>31.021738</td>
      <td>1.233324</td>
      <td>05STIM092neutral</td>
      <td>neutral</td>
      <td>92.0</td>
      <td>32.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.932899</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.2825</td>
      <td>-0.9725</td>
      <td>-0.3100</td>
    </tr>
    <tr>
      <th>6</th>
      <td>36.021618</td>
      <td>1.233313</td>
      <td>06STIM061smiling</td>
      <td>smiling</td>
      <td>61.0</td>
      <td>40.0</td>
      <td>male</td>
      <td>black</td>
      <td>-0.911501</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-1.1075</td>
      <td>1.6350</td>
      <td>1.0650</td>
    </tr>
    <tr>
      <th>7</th>
      <td>41.021482</td>
      <td>1.233311</td>
      <td>07STIM101neutral</td>
      <td>neutral</td>
      <td>101.0</td>
      <td>37.0</td>
      <td>male</td>
      <td>white</td>
      <td>0.723899</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.1725</td>
      <td>0.9775</td>
      <td>0.7200</td>
    </tr>
    <tr>
      <th>8</th>
      <td>46.021346</td>
      <td>1.233311</td>
      <td>08STIM062smiling</td>
      <td>smiling</td>
      <td>62.0</td>
      <td>30.0</td>
      <td>female</td>
      <td>black</td>
      <td>-0.553853</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0875</td>
      <td>-0.4800</td>
      <td>0.1200</td>
    </tr>
    <tr>
      <th>9</th>
      <td>51.021228</td>
      <td>1.233279</td>
      <td>09STIM137neutral</td>
      <td>neutral</td>
      <td>137.0</td>
      <td>21.0</td>
      <td>male</td>
      <td>black</td>
      <td>-0.295769</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.2100</td>
      <td>-0.0825</td>
      <td>0.7825</td>
    </tr>
    <tr>
      <th>12</th>
      <td>60.020963</td>
      <td>1.233313</td>
      <td>10STIM141smiling</td>
      <td>smiling</td>
      <td>141.0</td>
      <td>23.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.671322</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-2.9225</td>
      <td>-0.5475</td>
      <td>-0.7125</td>
    </tr>
    <tr>
      <th>15</th>
      <td>69.012388</td>
      <td>1.241642</td>
      <td>11STIM030neutral</td>
      <td>neutral</td>
      <td>30.0</td>
      <td>24.0</td>
      <td>female</td>
      <td>east_asian</td>
      <td>1.284608</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.1225</td>
      <td>0.6675</td>
      <td>0.4450</td>
    </tr>
    <tr>
      <th>16</th>
      <td>74.012240</td>
      <td>1.241653</td>
      <td>12STIM100neutral</td>
      <td>neutral</td>
      <td>100.0</td>
      <td>19.0</td>
      <td>female</td>
      <td>white</td>
      <td>1.162772</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.4550</td>
      <td>-1.5400</td>
      <td>2.6975</td>
    </tr>
    <tr>
      <th>17</th>
      <td>79.012104</td>
      <td>1.241649</td>
      <td>13STIM091neutral</td>
      <td>neutral</td>
      <td>91.0</td>
      <td>20.0</td>
      <td>female</td>
      <td>white</td>
      <td>0.780232</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1350</td>
      <td>-1.4900</td>
      <td>2.2100</td>
    </tr>
    <tr>
      <th>18</th>
      <td>84.020339</td>
      <td>1.233276</td>
      <td>14STIM038smiling</td>
      <td>smiling</td>
      <td>38.0</td>
      <td>40.0</td>
      <td>female</td>
      <td>west_asian</td>
      <td>-1.823308</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-0.9400</td>
      <td>0.2925</td>
      <td>-0.2650</td>
    </tr>
    <tr>
      <th>19</th>
      <td>89.020173</td>
      <td>1.233305</td>
      <td>15STIM082smiling</td>
      <td>smiling</td>
      <td>82.0</td>
      <td>20.0</td>
      <td>male</td>
      <td>black</td>
      <td>-0.145112</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.0475</td>
      <td>-0.4650</td>
      <td>0.6725</td>
    </tr>
    <tr>
      <th>20</th>
      <td>94.020035</td>
      <td>1.233300</td>
      <td>16STIM124neutral</td>
      <td>neutral</td>
      <td>124.0</td>
      <td>28.0</td>
      <td>female</td>
      <td>white</td>
      <td>2.675026</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.7275</td>
      <td>1.7075</td>
      <td>0.9675</td>
    </tr>
    <tr>
      <th>21</th>
      <td>99.019894</td>
      <td>1.233310</td>
      <td>17STIM006smiling</td>
      <td>smiling</td>
      <td>6.0</td>
      <td>31.0</td>
      <td>female</td>
      <td>west_asian</td>
      <td>-0.959537</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.3750</td>
      <td>1.4275</td>
      <td>0.3525</td>
    </tr>
    <tr>
      <th>22</th>
      <td>104.019757</td>
      <td>1.233330</td>
      <td>18STIM036smiling</td>
      <td>smiling</td>
      <td>36.0</td>
      <td>21.0</td>
      <td>male</td>
      <td>east_asian/white</td>
      <td>0.288084</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.5450</td>
      <td>-2.1125</td>
      <td>1.0075</td>
    </tr>
    <tr>
      <th>23</th>
      <td>109.019625</td>
      <td>1.233305</td>
      <td>19STIM102neutral</td>
      <td>neutral</td>
      <td>102.0</td>
      <td>31.0</td>
      <td>female</td>
      <td>white</td>
      <td>-1.159977</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-2.8300</td>
      <td>1.0000</td>
      <td>0.8100</td>
    </tr>
    <tr>
      <th>24</th>
      <td>114.019502</td>
      <td>1.233330</td>
      <td>20STIM012neutral</td>
      <td>neutral</td>
      <td>12.0</td>
      <td>24.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.135941</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.2700</td>
      <td>0.5025</td>
      <td>0.6800</td>
    </tr>
    <tr>
      <th>25</th>
      <td>119.019367</td>
      <td>1.233296</td>
      <td>21STIM066smiling</td>
      <td>smiling</td>
      <td>66.0</td>
      <td>22.0</td>
      <td>female</td>
      <td>west_asian</td>
      <td>0.637872</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1250</td>
      <td>2.1400</td>
      <td>2.1300</td>
    </tr>
    <tr>
      <th>26</th>
      <td>124.019221</td>
      <td>1.233300</td>
      <td>22STIM091smiling</td>
      <td>smiling</td>
      <td>91.0</td>
      <td>20.0</td>
      <td>female</td>
      <td>white</td>
      <td>0.780232</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.1350</td>
      <td>-1.4900</td>
      <td>2.2100</td>
    </tr>
    <tr>
      <th>27</th>
      <td>129.019086</td>
      <td>1.233295</td>
      <td>23STIM042neutral</td>
      <td>neutral</td>
      <td>42.0</td>
      <td>27.0</td>
      <td>male</td>
      <td>black</td>
      <td>0.343543</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.4825</td>
      <td>-0.7925</td>
      <td>1.3450</td>
    </tr>
    <tr>
      <th>28</th>
      <td>140.268799</td>
      <td>1.233281</td>
      <td>24STIM036neutral</td>
      <td>neutral</td>
      <td>36.0</td>
      <td>21.0</td>
      <td>male</td>
      <td>east_asian/white</td>
      <td>0.288084</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.5450</td>
      <td>-2.1125</td>
      <td>1.0075</td>
    </tr>
    <tr>
      <th>29</th>
      <td>145.268632</td>
      <td>1.233296</td>
      <td>25STIM044smiling</td>
      <td>smiling</td>
      <td>44.0</td>
      <td>22.0</td>
      <td>male</td>
      <td>black</td>
      <td>-0.517608</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>3.4650</td>
      <td>-1.1450</td>
      <td>-1.2900</td>
    </tr>
    <tr>
      <th>30</th>
      <td>150.268493</td>
      <td>1.233348</td>
      <td>26STIM011smiling</td>
      <td>smiling</td>
      <td>11.0</td>
      <td>36.0</td>
      <td>female</td>
      <td>white</td>
      <td>-0.531582</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-1.1325</td>
      <td>1.7575</td>
      <td>-0.4950</td>
    </tr>
    <tr>
      <th>33</th>
      <td>159.268261</td>
      <td>1.233305</td>
      <td>27STIM121neutral</td>
      <td>neutral</td>
      <td>121.0</td>
      <td>34.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.645557</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.4400</td>
      <td>0.6775</td>
      <td>1.9400</td>
    </tr>
    <tr>
      <th>34</th>
      <td>164.268123</td>
      <td>1.233300</td>
      <td>28STIM042smiling</td>
      <td>smiling</td>
      <td>42.0</td>
      <td>27.0</td>
      <td>male</td>
      <td>black</td>
      <td>0.343543</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2.4825</td>
      <td>-0.7925</td>
      <td>1.3450</td>
    </tr>
    <tr>
      <th>35</th>
      <td>169.267997</td>
      <td>1.233288</td>
      <td>29STIM043neutral</td>
      <td>neutral</td>
      <td>43.0</td>
      <td>20.0</td>
      <td>male</td>
      <td>black</td>
      <td>-0.690973</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.5775</td>
      <td>-1.1400</td>
      <td>0.5625</td>
    </tr>
    <tr>
      <th>36</th>
      <td>174.267849</td>
      <td>1.233300</td>
      <td>30STIM009neutral</td>
      <td>neutral</td>
      <td>9.0</td>
      <td>22.0</td>
      <td>female</td>
      <td>white</td>
      <td>1.508630</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.7375</td>
      <td>-1.7225</td>
      <td>2.5075</td>
    </tr>
    <tr>
      <th>37</th>
      <td>179.267707</td>
      <td>1.233307</td>
      <td>31STIM024neutral</td>
      <td>neutral</td>
      <td>24.0</td>
      <td>47.0</td>
      <td>male</td>
      <td>east_asian</td>
      <td>-1.172204</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-1.3075</td>
      <td>-2.9625</td>
      <td>2.4700</td>
    </tr>
    <tr>
      <th>38</th>
      <td>184.267562</td>
      <td>1.233317</td>
      <td>32STIM012smiling</td>
      <td>smiling</td>
      <td>12.0</td>
      <td>24.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.135941</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.2700</td>
      <td>0.5025</td>
      <td>0.6800</td>
    </tr>
    <tr>
      <th>41</th>
      <td>193.267315</td>
      <td>1.233315</td>
      <td>33STIM121smiling</td>
      <td>smiling</td>
      <td>121.0</td>
      <td>34.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.645557</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.4400</td>
      <td>0.6775</td>
      <td>1.9400</td>
    </tr>
    <tr>
      <th>42</th>
      <td>198.267180</td>
      <td>1.233315</td>
      <td>34STIM062neutral</td>
      <td>neutral</td>
      <td>62.0</td>
      <td>30.0</td>
      <td>female</td>
      <td>black</td>
      <td>-0.553853</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.0875</td>
      <td>-0.4800</td>
      <td>0.1200</td>
    </tr>
    <tr>
      <th>43</th>
      <td>203.267059</td>
      <td>1.233301</td>
      <td>35STIM009smiling</td>
      <td>smiling</td>
      <td>9.0</td>
      <td>22.0</td>
      <td>female</td>
      <td>white</td>
      <td>1.508630</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.7375</td>
      <td>-1.7225</td>
      <td>2.5075</td>
    </tr>
    <tr>
      <th>44</th>
      <td>208.266925</td>
      <td>1.233306</td>
      <td>36STIM102smiling</td>
      <td>smiling</td>
      <td>102.0</td>
      <td>31.0</td>
      <td>female</td>
      <td>white</td>
      <td>-1.159977</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-2.8300</td>
      <td>1.0000</td>
      <td>0.8100</td>
    </tr>
    <tr>
      <th>45</th>
      <td>213.266764</td>
      <td>1.233321</td>
      <td>37STIM064neutral</td>
      <td>neutral</td>
      <td>64.0</td>
      <td>25.0</td>
      <td>female</td>
      <td>west_asian</td>
      <td>-0.618483</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>1.3000</td>
      <td>-1.3175</td>
      <td>2.1450</td>
    </tr>
    <tr>
      <th>48</th>
      <td>222.266536</td>
      <td>1.233323</td>
      <td>38STIM099smiling</td>
      <td>smiling</td>
      <td>99.0</td>
      <td>24.0</td>
      <td>female</td>
      <td>black</td>
      <td>-0.157776</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>0.1425</td>
      <td>-1.5625</td>
      <td>1.3300</td>
    </tr>
    <tr>
      <th>49</th>
      <td>227.266389</td>
      <td>1.233319</td>
      <td>39STIM141neutral</td>
      <td>neutral</td>
      <td>141.0</td>
      <td>23.0</td>
      <td>male</td>
      <td>white</td>
      <td>-0.671322</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>-2.9225</td>
      <td>-0.5475</td>
      <td>-0.7125</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>There are many different experimental features that we’d could use for our analysis, but for now, we’ll stick with a single categorical (binary) one: face sex (“male” or “female”).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">S</span> <span class="o">=</span> <span class="n">events_df</span><span class="p">[</span><span class="s1">&#39;face_sex&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;male&#39; &#39;female&#39; &#39;female&#39; &#39;male&#39; &#39;female&#39; &#39;male&#39; &#39;male&#39; &#39;male&#39; &#39;female&#39;
 &#39;male&#39; &#39;male&#39; &#39;female&#39; &#39;female&#39; &#39;female&#39; &#39;female&#39; &#39;male&#39; &#39;female&#39;
 &#39;female&#39; &#39;male&#39; &#39;female&#39; &#39;male&#39; &#39;female&#39; &#39;female&#39; &#39;male&#39; &#39;male&#39; &#39;male&#39;
 &#39;female&#39; &#39;male&#39; &#39;male&#39; &#39;male&#39; &#39;female&#39; &#39;male&#39; &#39;male&#39; &#39;male&#39; &#39;female&#39;
 &#39;female&#39; &#39;female&#39; &#39;female&#39; &#39;female&#39; &#39;male&#39;]
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): For our analysis, we'll need the labels ($S$) in numeric format. Convert the string labels ("male", "female") to a numeric format (male: 1, female: 0) and store the result in a variable called <tt>S_num</tt> (which should be a numpy array).
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_str2num</span>
<span class="n">test_str2num</span><span class="p">(</span><span class="n">S</span><span class="p">,</span> <span class="n">S_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="preprocessing">
<h2>Preprocessing<a class="headerlink" href="#preprocessing" title="Permalink to this heading">#</a></h2>
<p>In terms of preprocessing, there are a couple of things that you need to keep in mind when planning to use representational similarity analyses. First, while standardization (ensuring zero mean and unit standard deviation for each brain feature) is a common preprocessing step in decoding analyses, it is somewhat of a controversial for RSA (see e.g. <a class="reference external" href="https://www.frontiersin.org/articles/10.3389/fnins.2013.00174/full">this article</a>). As such, we are not going to apply standardization to our data.</p>
<div class="section" id="multivariate-noise-normalization">
<h3>Multivariate noise normalization<a class="headerlink" href="#multivariate-noise-normalization" title="Permalink to this heading">#</a></h3>
<p>In week 1, we discussed univariate noise normalization, i.e., dividing each brain feature’s activity estimate (<span class="math notranslate nohighlight">\(\hat{\beta}\)</span>) by the standard deviation of the noise (<span class="math notranslate nohighlight">\(\hat{\sigma}\)</span>), which allows you to “downweigh” noisy voxels. Specifically for RSA, some people use <em>multivariate</em> noise normalization, which additionally incorporates the noise <em>covariance</em> between voxels. Like the temporal “uncorrelation” method we discussed in week 1, multivariate noise normalization effectively uncorrelates the data, yet this time in the <em>spatial</em> dimension. One often-cited reason for multivariate noise normalization in representational similarity analyses is that some distance metrics (discussed later) assume that the brain feature (e.g., voxels) of the data are independent.</p>
<p>So, before going on, let’s first load in the residuals from run 1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First, let&#39;s download them!</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading residuals for ses-1, run-1, sub-03 (+- ... MB) ...&quot;</span><span class="p">)</span>
<span class="o">!</span>aws<span class="w"> </span>s3<span class="w"> </span>sync<span class="w"> </span>--no-sign-request<span class="w"> </span>s3://openneuro.org/ds003965<span class="w"> </span><span class="o">{</span>data_dir<span class="o">}</span><span class="w"> </span>--exclude<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;derivatives/pattern_estimation/sub-03/ses-1/model/*task-face*run-1*residuals.nii.gz&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading residuals for ses-1, run-1, sub-03 (+- ... MB) ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_dir</span> <span class="o">=</span> <span class="n">patterns_dir</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">&#39;patterns&#39;</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">)</span>
<span class="n">resids_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">model_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-model_residuals.nii.gz&#39;</span><span class="p">)</span>
<span class="c1"># We immediately apply the FFA mask to the residuals</span>
<span class="n">resids</span> <span class="o">=</span> <span class="n">masking</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">resids_path</span><span class="p">,</span> <span class="n">ffa_mask</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of masked residuals (TxK):&quot;</span><span class="p">,</span> <span class="n">resids</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of masked residuals (TxK): (342, 70)
</pre></div>
</div>
</div>
</div>
<p>In week 1, we computed the voxelwise noise standard deviation using the numpy <code class="docutils literal notranslate"><span class="pre">std</span></code> function (or method) on our time axis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise_std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">resids</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Voxel&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\hat{\sigma}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">noise_std</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/e822ff886d5a9116be46a207fc849f5c50d4475d0cde5c98cf55f5f96929b0db.png" src="../../_images/e822ff886d5a9116be46a207fc849f5c50d4475d0cde5c98cf55f5f96929b0db.png" />
</div>
</div>
<p>However, we can also get the voxelwise noise standard deviation by computing the noise variance-covariance matrix and extracting the (square root of the) diagonal, because the diagonal represents the variance of the voxels (the “covariance with itself”, so to say).</p>
<p>Let’s first compute the covariance matrix:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need to transpose (.T) the residuals,</span>
<span class="c1"># otherwise we&#39;d get a TxT covariance matrix</span>
<span class="n">noise_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cov</span><span class="p">(</span><span class="n">resids</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">noise_cov</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Noise covariance matrix&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Voxels&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Voxels&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/30cf33f3b7a3ecfe4ea76dd349ba5f8b33fbc1a7f11a280ebeb02ef6a1277180.png" src="../../_images/30cf33f3b7a3ecfe4ea76dd349ba5f8b33fbc1a7f11a280ebeb02ef6a1277180.png" />
</div>
</div>
<p>Just to convince you that the (square root of the) diagonal is the same as the standard deviation we computed earlier:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">noise_std_from_cov</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">noise_cov</span><span class="p">))</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">noise_std</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">noise_std_from_cov</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Voxel&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Voxel&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="sa">r</span><span class="s1">&#39;$\hat{\sigma}$&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">sns</span><span class="o">.</span><span class="n">despine</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/d474916bef1d089a20cfcf87f684be99257ed672a2b6b5088418a0edbc7759b1.png" src="../../_images/d474916bef1d089a20cfcf87f684be99257ed672a2b6b5088418a0edbc7759b1.png" />
</div>
</div>
<p>The reason we need the variance-covariance matrix is that for <em>multivariate</em> noise normalization, we use the <em>full</em> matrix, i.e., including the off-diagonal elements (the covariance between voxels). To do so, we first need to compute the <em>whitening</em> matrix, which is often denoted by <span class="math notranslate nohighlight">\(D\)</span> and is computed by taking the square root of the inverse of the estimated variance-covariance matrix (<span class="math notranslate nohighlight">\(\hat{\Sigma}\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-50bd334f-5f33-4c5d-a0de-ed68215d70b4">
<span class="eqno">(99)<a class="headerlink" href="#equation-50bd334f-5f33-4c5d-a0de-ed68215d70b4" title="Permalink to this equation">#</a></span>\[\begin{align}
D = \hat{\Sigma}^{-\frac{1}{2}}
\end{align}\]</div>
<p>Whitening using this particular whitening matrix (<span class="math notranslate nohighlight">\(\hat{\Sigma}^{-\frac{1}{2}}\)</span>) is also called <a class="reference external" href="https://en.wikipedia.org/wiki/Whitening_transformation">ZCA or Mahalanobis whitening</a>. To apply this whitening matrix to our patterns (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>), we simply take the dot product between the patterns and the whitening matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-80ae5f0a-a163-4a29-b138-cda872e532c2">
<span class="eqno">(100)<a class="headerlink" href="#equation-80ae5f0a-a163-4a29-b138-cda872e532c2" title="Permalink to this equation">#</a></span>\[\begin{align}
R_{\mathrm{mnn}} = RD
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(R_{\mathrm{mnn}}\)</span> is the multivariate noise normalized pattern matrix. Note that this operation is <em>very</em> similar to the temporal uncorrelation method, but instead of uncorrelating the trials (i.e., the rows of the pattern matrix), it uncorrelates the brain features (i.e., the columns of the pattern matrix).</p>
<p>Let’s first compute the whitening matrix. We can use the matrix square root function <code class="docutils literal notranslate"><span class="pre">sqrtm</span></code> from the <code class="docutils literal notranslate"><span class="pre">scipy.linalg</span></code> package:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># square root of inv = ^(-1/2)</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">sqrtm</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">sqrtm</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">noise_cov</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>And to get the multivariate noise normalized patterns, we compute the dot product:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_mnn</span> <span class="o">=</span> <span class="n">R</span> <span class="o">@</span> <span class="n">D</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s visualize the unnormalized, univariate noise normalized, and multivariate noise normalized patterns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_unn</span> <span class="o">=</span> <span class="n">R</span> <span class="o">/</span> <span class="n">noise_std</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">ncols</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">R</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;No normalization&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">R_unn</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;UNN&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">R_mnn</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;MNN&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">axes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Voxels&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">fig</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/cb380d1e2e8dfab2697be139519946f9999d20e4e5f8ddeb568e00bd6dfe0ab6.png" src="../../_images/cb380d1e2e8dfab2697be139519946f9999d20e4e5f8ddeb568e00bd6dfe0ab6.png" />
</div>
</div>
<p>Here, our patterns consist of only 64 voxels. Often, however, you might want to use patterns with (many) more voxels. For multivariate noise normalization, which uses the full <span class="math notranslate nohighlight">\(K \times K\)</span> variance-covariance matrix, using more brain features (<span class="math notranslate nohighlight">\(K\)</span>) than samples (<span class="math notranslate nohighlight">\(N\)</span>) often lead to a very unstable variance-covariance matrix (or in technical terms, a matrix that is not “positive semidefinite”). One trick that makes the variance-covariance matrix estimation more stable is to apply <em>regularization</em> (sometimes called “shrinkage”). This regularization will “shrink” the matrix more towards the identity matrix (<span class="math notranslate nohighlight">\(I\)</span>, i.e., a matrix with all zeros except the diagonal, which contains ones) when the ratio between brain features and samples becomes larger.<br></p>
<p>One such shrinkage method is the “Ledoit-Wolf” covariance estimator. Below, we import this function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.covariance</span> <span class="kn">import</span> <span class="n">ledoit_wolf</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Read through the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.covariance.ledoit_wolf.html#sklearn.covariance.ledoit_wolf">documentation of the ledoit_wolf function</a> and then use it to compute the regularized covariance matrix of our pattern matrix and subsequently use this to multivariate noise normalize our pattern matrix. Store the result in a new variable called <tt>R_mnn_reg</tt>.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the ToDo above. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_ledoit_wolf</span>    
<span class="n">test_ledoit_wolf</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">resids</span><span class="p">,</span> <span class="n">R_mnn_reg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="neural-rdms">
<h2>Neural RDMs<a class="headerlink" href="#neural-rdms" title="Permalink to this heading">#</a></h2>
<p>The first step in a representational similarity analysis is to create a “neural representational dissimilarity matrix” (RDM). This matrix is a symmetric <span class="math notranslate nohighlight">\(N \times N\)</span> matrix which represents how “dissimilar” patterns of different samples (i.e., rows in your pattern matrix, <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>). Note that the samples could be trials (e.g., “face 1”, “face 2”, “face 3”, etc.) but could also be conditions (e.g., “faces”, “houses”, “objects”, etc.). In our case, we’re focusing on trials.</p>
<p>For example, suppose we have only data from four trials (i.e., four rows in our pattern matrix <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>). A corresponding <span class="math notranslate nohighlight">\(4\times 4\)</span> RDM could like the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># some made up RDM</span>
<span class="n">example_rdm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">7.2</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">,</span> <span class="mf">5.2</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">7.2</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mf">4.7</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">1.2</span><span class="p">,</span> <span class="mf">3.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">],</span>
    <span class="p">[</span><span class="mf">5.2</span><span class="p">,</span> <span class="mf">4.7</span><span class="p">,</span> <span class="mf">6.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<span class="p">])</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">example_rdm</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Example RDM&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Dissimilarity&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/104f4962ffcb01d4780decc9a8387cb202b73263e29de4cda9b3cc722284c4d5.png" src="../../_images/104f4962ffcb01d4780decc9a8387cb202b73263e29de4cda9b3cc722284c4d5.png" />
</div>
</div>
<p>In this example RDM, each cell represents a particular distance between two patterns. For example, the cell in the bottom left corner represents the dissimilarity between trial 1 and trial 4. Note that the RDM is symmetric, because the dissimilarity between trial 1 and 4 is the same as trial 4 and 1; also, the cells on the diagonal are all zero, as they represent the distance between a particular pattern and itself, which is zero!  Note that these two properties (symmetricity, zero diagonal) are only true when you compute your RDM on trials within the same run (unlike the between-run pattern distances, discussed previously).</p>
<p>For now, we’ll stick with within-run RDMs (as they’re a little easier to compute).</p>
<p>In a way, you can think about RDMs as “inverse” correlation matrices in which cells do not represent correlations (a kind of <em>similarity</em> metric) but distances.</p>
<p>By now, you might ask youself: “but how do you actually compute these dissimilarities?” Well, this depends on what <em>distance metric</em> you use! There are many different functions you can use to quantify the dissimilarity between two vectors (i.e., two rows in our pattern matrix). Actually, reflecting the intuition that an RDM is basically the inverse of a correlation matrix, one metric that is sometimes used is the <span class="math notranslate nohighlight">\(1-r\)</span> distance*. This distance simply quantifies distance as the 1 minus the correlation between two patterns. For example, the <span class="math notranslate nohighlight">\(1-r\)</span> distance between “pattern A” and “pattern B” is <span class="math notranslate nohighlight">\(1-\mathrm{corr(pattern\ A, pattern\ B})\)</span>.</p>
<hr class="docutils" />
<p>* In the RSA literature, some people use the <em>cosine distance</em>, which is the angle between two vectors; when the patterns are mean centered (i.e., the rows in <span class="math notranslate nohighlight">\(\mathbf{R}\)</span> have a mean of 0), this is exactly the same as the <span class="math notranslate nohighlight">\(1-r\)</span> distance!</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): For our data (the variable <tt>R</tt>), compute the RDM using the $1 -r$ distance and store it in a variable named <tt>rdm_1minr</tt>. Note: no need for a for-loop! (You might want to check out the <tt>np.corrcoef</tt> function.)
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_1minr</span>    
<span class="n">test_1minr</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">rdm_1minr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Another often-used distance metric used for RDMs, and perhaps the most intuitive one, is the Euclidean distance. This distance is computed as the square root of the sum of squared distances between two patterns (e.g., <span class="math notranslate nohighlight">\(p\)</span> and <span class="math notranslate nohighlight">\(q\)</span>) consisting of <span class="math notranslate nohighlight">\(K\)</span> elements:</p>
<div class="amsmath math notranslate nohighlight" id="equation-41fe8c55-b15c-4b67-ab36-2edb89ec4bc2">
<span class="eqno">(101)<a class="headerlink" href="#equation-41fe8c55-b15c-4b67-ab36-2edb89ec4bc2" title="Permalink to this equation">#</a></span>\[\begin{align}
\delta_{euclidean} = \sqrt{\sum_{j=1}^{K}{(p_{j} - q_{j})^{2}}}
\end{align}\]</div>
<p>Below, we define two example patterns with four features and compute the Euclidean distance between them:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="o">-</span><span class="mi">4</span><span class="p">])</span>
<span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">5</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># No need for a for loop!</span>
<span class="n">euc_dist</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">p</span> <span class="o">-</span> <span class="n">q</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Euclidean distance between p and q:&quot;</span><span class="p">,</span> <span class="n">euc_dist</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Euclidean distance between p and q: 10.63014581273465
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): While all pairwise distances were easy to calculate using the $1-r$ distance, it takes a little more code to do this using the Euclidean distance. Compute the RDM based on the Euclidean distance for our data (the variable <tt>R</tt>) and store this in a variable named <tt>rdm_euc</tt>. Also visualize the RDM using the pyplot <tt>imshow</tt> function. Unless you're a linear algebra wizard, you need to use for loops to compute the RDM. Do not use any external functions (beyond numpy). Hint: pre-allocate your RDM first and then fill it cell by cell in a nested for loop.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">euclidean_distances</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">euclidean_distances</span><span class="p">(</span><span class="n">R</span><span class="p">),</span> <span class="n">rdm_euc</span><span class="p">,</span> <span class="n">decimal</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>As you might have seen in the test cell, scikit-learn actually provides several functions to quickly compute distance matrices (RDMs) using various distance metrics. We recommend using the generic <code class="docutils literal notranslate"><span class="pre">pairwise_distances</span></code> function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">pairwise_distances</span>
</pre></div>
</div>
</div>
</div>
<p>To compute an <span class="math notranslate nohighlight">\(N\times N\)</span> distance matrix from a <span class="math notranslate nohighlight">\(N\times K\)</span> pattern array (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>), you can use it as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">rdm</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;name_of_metric&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>For example, to compute an RDM based on the “cosine” distance (which is similar to the <span class="math notranslate nohighlight">\(1-r\)</span> distance), you can run:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdm_cosine</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;cosine&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rdm_cosine</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Trials&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Cosine-based RDM&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">cbar</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">cbar</span><span class="o">.</span><span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s1">&#39;Cosine distance&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/7df2024a5b7520853bb7c717bc0a6c16b59d8d6746a26d995585a5c651babcf7.png" src="../../_images/7df2024a5b7520853bb7c717bc0a6c16b59d8d6746a26d995585a5c651babcf7.png" />
</div>
</div>
<p>Note that there is no agreed-upon “best” distance metric! If you want to know more about the different (dis)similarity metrics for pattern analyses, check out <a class="reference external" href="https://link.springer.com/article/10.1007/s42113-019-00068-5">this article</a>.</p>
<p>For the next couple of sections, we’ll use the Euclidean distance-based RDM:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdm_R</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): Euclidean and $1-r$/cosine distances differ in one major aspect related to the "type" of information they can encode/pick up. What do you think this is?
</div><p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="exploratory-analysis-using-mds">
<h2>Exploratory analysis using MDS<a class="headerlink" href="#exploratory-analysis-using-mds" title="Permalink to this heading">#</a></h2>
<p>Most applications of RSA involve relating <em>neural</em> RDMs with RDMs based on experimental features (which we’ll discuss in the next section). However, you can also do exploratory analyses on your neural RDM only! This is usually done by investigating the (dis)similarity structure (or “representational geometry” in RSA terms), usually in a 2D or 3D space.</p>
<p>As pattern analyses are often applied to very high-dimensional data (i.e., patterns with many brain features, <span class="math notranslate nohighlight">\(K\)</span>), people often project the data (i.e., the patterns) into a lower dimensional space. We already encountered one such method in week 1: PCA! However, when interested in the (dis)similarity structure of your data, <em>multidimensional scaling</em> (MDS) is more appropriate. Just like PCA, this technique aims to create combinations of features into a lower-dimensional subset of components, such that the high-dimensional distances are presented as much as possible in the lower-dimensional space. For example, if the distance between A and B is 436 in high-dimensional space (e.g., <span class="math notranslate nohighlight">\(K=500\)</span>), MDS tries to create a lower-dimensional space (usually 2 components) in which the distance between A and B is as close as possible to 436 (as well as all other distances between patterns).</p>
<p>Of course, scikit-learn contains an implementation of MDS that uses the familiar <code class="docutils literal notranslate"><span class="pre">fit</span></code>/<code class="docutils literal notranslate"><span class="pre">transform</span></code> methods. Importantly, it can take in a <span class="math notranslate nohighlight">\(N\times K\)</span> matrix (like our pattern matrix <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) and compute the high-dimensional distance structure (i.e., the RDM) internally or you can give it your precomputed RDM. In the latter case, you need to initialize it with <code class="docutils literal notranslate"><span class="pre">dissimilarity='prepcomputed'</span></code>, which is what we’re going to do:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.manifold</span> <span class="kn">import</span> <span class="n">MDS</span>
<span class="n">mds</span> <span class="o">=</span> <span class="n">MDS</span><span class="p">(</span><span class="n">dissimilarity</span><span class="o">=</span><span class="s1">&#39;precomputed&#39;</span><span class="p">,</span> <span class="n">n_components</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">normalized_stress</span><span class="o">=</span><span class="s1">&#39;auto&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Then, we call the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> method to compute lower-dimensional (<span class="math notranslate nohighlight">\(K=2\)</span>) representation of the data (which is, again, an <span class="math notranslate nohighlight">\(N \times K\)</span> array, but this time, <span class="math notranslate nohighlight">\(K=2\)</span>!):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mds_R</span> <span class="o">=</span> <span class="n">mds</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">rdm_R</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of mds_R:&quot;</span><span class="p">,</span> <span class="n">mds_R</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">mds_R</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">mds_R</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;MDS component 1&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;MDS component 2&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of mds_R: (40, 2)
</pre></div>
</div>
<img alt="../../_images/667f33b97b6f71387acd0b30d8386f99f370e978bf93552a4de7fd101de2cdce.png" src="../../_images/667f33b97b6f71387acd0b30d8386f99f370e978bf93552a4de7fd101de2cdce.png" />
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Below, re-plot the MDS scatterplot, but this time, color the datapoints (i.e., the trial patterns) according to their trial onset (you can set the color of the points with <tt>c</tt> parameter in the <tt>scatter</tt> function), which you can extract from the <tt>events_df</tt> dataframe. This way, datapoints (i.e., patterns) with a similar onset have a similar hue.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): Which phenomenon (that we discussed before) is clearly visible in this low-dimensional embedding of the data? 
</div><p>YOUR ANSWER HERE</p>
<p>Instead of coloring the datapoints according to some experimental property/feature (such as onset), an even more potent way to visualize MDS-embeddings is to plot the actual images that correspond with the trial patterns (here: the faces shown to the subject)! This way, you may find patterns in the data that you might not have thought of!</p>
<p>However, in our opinion, the true strength of RSA lies in their ability to test hypotheses about complex representational structures using experimental features, which is discussed next.</p>
</div>
<div class="section" id="categorical-rdms">
<h2>Categorical RDMs<a class="headerlink" href="#categorical-rdms" title="Permalink to this heading">#</a></h2>
<p>In most pattern analyses, we’d like to evaluate the association between experimental features and brain patterns. In RSA, this is done by comparing neural RDMs (discussed in the previous sections) with RDMs based on experimental features. These experimental feature RDMs (let’s call them “feature RDMs”) are constructed in largely the same way as neural RDMs: by computing the pairwise distance between samples!</p>
<p>The experimental features (<span class="math notranslate nohighlight">\(P\)</span>) that you use for your feature RDM of course depend on your hypothesis! Importantly, unlike decoding models, RSA naturally handles high-dimensional feature spaces very well. Like neural RDMs, no matter how many features you use, you’ll always analyze the resulting <span class="math notranslate nohighlight">\(N\times N\)</span> RDM!</p>
<p>After constructing your feature RDM, you can test whether the “geometry” of your hypothesized feature space matches the geometry of your brain patterns. In other words, you test whether the pattern of distances is similar in your brain data and your experimental features. Technically, you can use <em>any</em> (set of) feature(s) that you believe match the geometry of the corresponding brain patterns. How to actually test this will be discussed in section 5.</p>
<p>In this section, we’ll focus on the most straightforward type of feature RDM: the categorical RDM. This RDM, basically, investigates whether patterns belonging to the same condition are more similar than patterns belonging to a different condition (note the similarity to decoding models). For example, we could hypothesize that the FFA represents face gender, which should accordingly lead to relatively small neural distances between images of the same face gender and relatively large neural distances between images of a different face gender. Before delving into how we should construct a corresponding feature RDM, let’s first define our experimental feature: face gender. In the first section, we already extracted this from the events file. Now, let’s convert it to a numeric format:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
<span class="n">face_gen</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">S</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Face gender, numeric:&quot;</span><span class="p">,</span> <span class="n">face_gen</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Face gender, numeric: [1 0 0 1 0 1 1 1 0 1 1 0 0 0 0 1 0 0 1 0 1 0 0 1 1 1 0 1 1 1 0 1 1 1 0 0 0
 0 0 1]
</pre></div>
</div>
</div>
</div>
<p>Now, to capture this feature into an RDM, we can construct an RDM with zeros in cells corresponding to trials with the same condition (both male or both female faces) and ones everywhere else, which capture the hypothesis that trials should have a smaller distance when they are of the same condition (0) than when they are of a different condition (1).</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Create this face-gender RDM and store it in a variable named <tt>rdm_fg</tt>, an $N \times N$ numpy array. Do not use any external functions for this. 
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_rdm_fg</span>
<span class="n">test_rdm_fg</span><span class="p">(</span><span class="n">face_gen</span><span class="p">,</span> <span class="n">rdm_fg</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Technically, to create this categorical RDM (with only two levels), you can also use the <code class="docutils literal notranslate"><span class="pre">pairwise_distances</span></code> function with the “manhattan” metric (the sum of <em>absolute</em> distances):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note the np.newaxis, which is needed because pairwise_distances</span>
<span class="c1"># assumes that the input is 2D</span>
<span class="n">rdm_fg_pd</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">face_gen</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;manhattan&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rdm_fg_pd</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">colorbar</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Categorical RDM&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/741ecc2398a1c94b7c847f2d41f75cb9b37935eb3edbf810a630cce8552122df.png" src="../../_images/741ecc2398a1c94b7c847f2d41f75cb9b37935eb3edbf810a630cce8552122df.png" />
</div>
</div>
</div>
<div class="section" id="continuous-computational-rdms">
<h2>Continuous/computational RDMs<a class="headerlink" href="#continuous-computational-rdms" title="Permalink to this heading">#</a></h2>
<p>The categorical RDMs discussed in the previous section are the most simple implementation of feature RDMs, based on only a single categorical feature. RSA really shines, though, when relating more complex feature sets (sometimes called “feature spaces”) consisting of multiple (continuous) variables.</p>
<p>For example, for our data, we have subject-specific ratings of dominance, trustworthiness, and attractiveness for all of the faces shown to (the same) subjects. If we’d want to investigate whether a particular brain region represents these face properties (you might call them “<a class="reference external" href="https://www.sciencedirect.com/science/article/abs/pii/S0959438813000147">social judgements</a>), we could create a feature RDM base on these three features; in fact, we’ll do that below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sj</span> <span class="o">=</span> <span class="n">events_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="p">[</span><span class="s1">&#39;subject_dominance&#39;</span><span class="p">,</span> <span class="s1">&#39;subject_trustworthiness&#39;</span><span class="p">,</span> <span class="s1">&#39;subject_attractiveness&#39;</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
<span class="n">rdm_sj</span> <span class="o">=</span> <span class="n">pairwise_distances</span><span class="p">(</span><span class="n">sj</span><span class="p">,</span> <span class="n">metric</span><span class="o">=</span><span class="s1">&#39;euclidean&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">rdm_sj</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Social judgements RDM&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/c4b877057edbc0c4b9d76939249b5afc0a47c84f99b3d26aaba90ef959cbf6e3.png" src="../../_images/c4b877057edbc0c4b9d76939249b5afc0a47c84f99b3d26aaba90ef959cbf6e3.png" />
</div>
</div>
<p>Note though, that all information about the individual features (attractiveness, trustworthiness, and dominance) is lost in this RDM! The feature RDM should represent the geometry of the entire feature space, not the effects of the individual features on brain activity (although we discuss a technique that allows for this type of inference in the next section).</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 point): Note that as long as you can formalize your hypothesis into a feature matrix ($N \times P$), you can create an RDM from it (and test it with RSA)! Suppose that I believe that social judgements are not represented in a bipolar fashion (from very unattractive to very attractive, very untrustworthy to very trustworthy, etc.; like we assumed before) but in an unipolar fashion relative from the mean rating. For example, this would mean that a face with an attractiveness/trusworthiness/dominance rating of -4 would be represented in the same way as a face with a rating of 4 (assuming a mean rating of 0) Moreover, suppose I believe that this representation is quadratic, not linear. For example, a face with an attractiveness rating of 2 is four times as attractive as a face with an attractiveness rating of 1. Using the social judgement data (i.e., the <tt>sj</tt> variable), create an RDM that represents this hypothesis.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement the ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_rdm_sj2</span>
<span class="n">test_rdm_sj2</span><span class="p">(</span><span class="n">sj</span><span class="p">,</span> <span class="n">rdm_sj2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>RSA also lends itself very well for testing computational models, i.e., models that yield a (set of) feature(s) that were directly computed from the data. For example, in vision science, there are many computational models that yield a set of (visual) feature that are computed from the image directly (i.e., from the pixels). Again, as long as you can specify a set of features that embody your hypothesis, you can create an RDM from it!</p>
<p>In the next ToDo, you’re going to practice a bit to get into this “computational mindset” by applying a very simple (and theoretically meaningless) computational model to the face stimuli. In the current directory there is a subfolder <code class="docutils literal notranslate"><span class="pre">stim</span></code>, which contains all the stimuli from the first run:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">imgs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="s1">&#39;stims&#39;</span><span class="p">,</span> <span class="s1">&#39;*.jpg&#39;</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;stims/00STIM137smiling.jpg&#39;, &#39;stims/01STIM070neutral.jpg&#39;, &#39;stims/02STIM044smiling.jpg&#39;, &#39;stims/03STIM042neutral.jpg&#39;, &#39;stims/04STIM062neutral.jpg&#39;, &#39;stims/05STIM082neutral.jpg&#39;, &#39;stims/06STIM044neutral.jpg&#39;, &#39;stims/07STIM006neutral.jpg&#39;, &#39;stims/08STIM033smiling.jpg&#39;, &#39;stims/09STIM039smiling.jpg&#39;, &#39;stims/10STIM087smiling.jpg&#39;, &#39;stims/11STIM030smiling.jpg&#39;, &#39;stims/12STIM011smiling.jpg&#39;, &#39;stims/13STIM099neutral.jpg&#39;, &#39;stims/14STIM099smiling.jpg&#39;, &#39;stims/15STIM130neutral.jpg&#39;, &#39;stims/16STIM126neutral.jpg&#39;, &#39;stims/17STIM012smiling.jpg&#39;, &#39;stims/18STIM036neutral.jpg&#39;, &#39;stims/19STIM117smiling.jpg&#39;, &#39;stims/20STIM018neutral.jpg&#39;, &#39;stims/21STIM042smiling.jpg&#39;, &#39;stims/22STIM038smiling.jpg&#39;, &#39;stims/23STIM061neutral.jpg&#39;, &#39;stims/24STIM100neutral.jpg&#39;, &#39;stims/25STIM061smiling.jpg&#39;, &#39;stims/26STIM117neutral.jpg&#39;, &#39;stims/27STIM018smiling.jpg&#39;, &#39;stims/28STIM038neutral.jpg&#39;, &#39;stims/29STIM126smiling.jpg&#39;, &#39;stims/30STIM034smiling.jpg&#39;, &#39;stims/31STIM136smiling.jpg&#39;, &#39;stims/32STIM009smiling.jpg&#39;, &#39;stims/33STIM101smiling.jpg&#39;, &#39;stims/34STIM030neutral.jpg&#39;, &#39;stims/35STIM130smiling.jpg&#39;, &#39;stims/36STIM141neutral.jpg&#39;, &#39;stims/37STIM144neutral.jpg&#39;, &#39;stims/38STIM066neutral.jpg&#39;, &#39;stims/39STIM027neutral.jpg&#39;]
</pre></div>
</div>
</div>
</div>
<p>To load an image as a numpy array, we can use the <code class="docutils literal notranslate"><span class="pre">imageio</span></code> library. Note that the function returns a 3D numpy array, where the first two dimensions represent width and height, and the third dimension represents the three color channels (red, green, and blue).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imageio</span>
<span class="n">example_stim</span> <span class="o">=</span> <span class="n">imageio</span><span class="o">.</span><span class="n">v2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">imgs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of image data:&quot;</span><span class="p">,</span> <span class="n">example_stim</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of image data: (1350, 1350, 3)
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): Suppose that I have a very naive theory about color representation in the brain. Specifically, suppose that I think that a particular brain area simply represents stimuli according to their average redness, greenness, and blueness. In other words, I believe that stimuli with similar average red/green/blue values have similar brain patterns. For the forty stimuli from run 1, construct an RDM that represents this hypothesis and store it in a variable named <tt>rdm_rgb</tt> (a $40\times 40$ array). Use a Euclidean distance metric. Hint: before constructing your RDM, your feature matrix should be of shape $40 \times 3$.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_rdm_rgb</span>    
<span class="n">test_rdm_rgb</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">rdm_rgb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Just by eye, it’s difficult to judge whether the neural RDM contains a similar representational geometry as the feature RDMs we created earlier. Fortunately, we have statistics!</p>
</div>
<div class="section" id="testing-rdms">
<h2>Testing RDMs<a class="headerlink" href="#testing-rdms" title="Permalink to this heading">#</a></h2>
<p>In this section, we’ll discuss how to evaluate the “fit” of feature RDMs.</p>
<div class="section" id="correlation-based-tests">
<h3>Correlation-based tests<a class="headerlink" href="#correlation-based-tests" title="Permalink to this heading">#</a></h3>
<p>Alright, so now we got two RDMs: the feature RDM and the neural RDM. To evaluate to what extent the two RDMs share the same representational geometry, we can simply correlate them! Before doing so, we have to do one more thing: extract the lower (or upper) triangle of the RDM. This is because RDMs are symmetric: the values above and below the diagonal are exactly the same. If we used the entire (flattened) RDM, we’d “artifically” create twice as many datapoints (i.e. the pairwise dissimilarities) than there really are, which will inflate the significance of the correlation between the RDMs because of increased sample size. So, instead of using all <span class="math notranslate nohighlight">\(N\cdot N\)</span> pairwise differences from the RDM, we need to extract only the flattened <span class="math notranslate nohighlight">\(N\times (N-1)/2\)</span> pairwise dissimilarity values, the “representational dissimilarity vector” (RDV) if you will. This means that we do not include the diagonal!</p>
<p>Fortunately, there is a function that easily extracts the lower triangle of a square distance matrix: <code class="docutils literal notranslate"><span class="pre">squareform</span></code> (from the <code class="docutils literal notranslate"><span class="pre">scipy.spatial.distance</span></code> module):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.spatial.distance</span> <span class="kn">import</span> <span class="n">squareform</span>

<span class="c1"># Let&#39;s extract the RDV from our neural RDM</span>
<span class="n">rdv_R</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">rdm_R</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">5</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape rdv_R:&quot;</span><span class="p">,</span> <span class="n">rdv_R</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape rdv_R: (780,)
</pre></div>
</div>
</div>
</div>
<div class='alert alert-success'>
    <b>Tip</b>: Sometimes, an RDM might not be <em>exactly</em> symmetric due to floating point inaccuracies, which will give an error my trying to extract the lower triangle using <tt>squareform</tt>. To circumvent this, you can round the RDM values to, e.g., 5 decimals using the <tt>.round(decimals)</tt> array method.
</div><p>As you can see, the shape of the <code class="docutils literal notranslate"><span class="pre">rdv_R</span></code> is as expected: <span class="math notranslate nohighlight">\(40 \times (40-1) / 2 = 780\)</span>. Let’s do the same for the face-gender RDM we created earlier (<code class="docutils literal notranslate"><span class="pre">rdm_fg_pd</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdv_fg</span> <span class="o">=</span> <span class="n">squareform</span><span class="p">(</span><span class="n">rdm_fg_pd</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape rdv_fg:&quot;</span><span class="p">,</span> <span class="n">rdv_fg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape rdv_fg: (780,)
</pre></div>
</div>
</div>
</div>
<p>Importantly, the correlation between feature and neural RDMs is often evaluated using a rank-based correlation metric. For continuous feature RDMs, this is usually the Spearman correlation, but for categorical feature RDMs (such as our face-gender RDM), often the “Kendall Tau <span class="math notranslate nohighlight">\(\alpha\)</span>” correlation is used, as it deals properly with tied ranks. Implementations of both correlations are available from the <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> module. Here, we’ll use Kendall’s Tau <span class="math notranslate nohighlight">\(\alpha\)</span>, because our face-gender RDM is categorical:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">kendalltau</span>
<span class="n">rdm_corr</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">kendalltau</span><span class="p">(</span><span class="n">rdv_fg</span><span class="p">,</span> <span class="n">rdv_R</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Correlation between RDMs (p-value): </span><span class="si">%.3f</span><span class="s2"> (</span><span class="si">%.3f</span><span class="s2">)&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">rdm_corr</span><span class="p">,</span> <span class="n">pval</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation between RDMs (p-value): 0.022 (0.448)
</pre></div>
</div>
</div>
</div>
<p>Given the slighly positive correlation between our face-gender RDM and the FFA RDM, this means that patterns related to trials with the same face gender are slightly less dissimilar than patterns related to trials with a different face gender!</p>
</div>
<div class="section" id="reweighting-rdvs">
<h3>Reweighting RDVs<a class="headerlink" href="#reweighting-rdvs" title="Permalink to this heading">#</a></h3>
<p>One more advanced RSA technique is “reweighting”. This technique allows you to use multiple feature RDVs to explain your neural RDV. Essentially, you assume that the neural RDV can be approximated as a linear weighted sum of different feature RDVs. For example, for two feature RDVs (<span class="math notranslate nohighlight">\(\mathrm{RDV}_{S_{1}}\)</span> and <span class="math notranslate nohighlight">\(\mathrm{RDV}_{S_{2}}\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-b7229afc-1d97-4cb5-8e72-d40f03979b82">
<span class="eqno">(102)<a class="headerlink" href="#equation-b7229afc-1d97-4cb5-8e72-d40f03979b82" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{RDV}_{R} = \beta_{0} + \mathrm{RDV}_{S_{1}}\beta_{1} + \mathrm{RDV}_{S_{2}}\beta_{2} + \epsilon
\end{align}\]</div>
<p>You might recognize this formulation as a linear model (GLM) with the neural RDV as dependent variable and the feature RDVs as independent variables. Here, the parameters (<span class="math notranslate nohighlight">\(\beta\)</span>) represent the “reweighting” factors. This technique is very useful to disentangle the contributions of different (possibly correlated) feature spaces. Note that, often, a variant of ordinary least squares (OLS) is used to determine the parameters: non-negative least squares (NNLS), which forces the parameters to be positive (for details about why NNLS should be used, see <a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003915">this article</a>, and more information about reweighting in general, see <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0028393215301998#bib5">this article</a>).</p>
<p>After the reweighted RDV (<span class="math notranslate nohighlight">\(\mathrm{RDV}_{S}\hat{\beta}\)</span>) is computed, it can again be evaluated using a (rank-based) correlation: <span class="math notranslate nohighlight">\(r(\mathrm{RDV}_{S}\hat{\beta}, \mathrm{RDV}_{R})\)</span>.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): Previously, we defined two different feature RDMs: one based on face-gender (<tt>rdm_fg</tt>) and another one based on social judgements (<tt>rdm_sj</tt>). While theoretically meaningless, perform a reweighting analysis with the two feature RDVs as independent variables (in addition to an intercept!) and the neural RDV (based on <tt>rdm_R</tt>) as dependent variable. You can use the <tt>nnls</tt> implementation from <tt>scipy.optimize</tt> to perform NNLS. Note that the <tt>nnls</tt> function returns two things &mdash; the first object is the array with parameters, and it takes two arguments: the design matrix (independent variables) and the dependent variable. Compute the Spearman correlation between the reweighted RDV and the neural RDV and store the result in a variable named <tt>corr_reweighted_analysis</tt>.
</div> <div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">spearmanr</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">nnls</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_3</span> <span class="kn">import</span> <span class="n">test_reweighting_todo</span>    
<span class="n">test_reweighting_todo</span><span class="p">(</span><span class="n">rdm_fg</span><span class="p">,</span> <span class="n">rdm_sj</span><span class="p">,</span> <span class="n">rdm_R</span><span class="p">,</span> <span class="n">corr_reweighted_analysis</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (2 points): Suppose that you have a very high-dimensional experimental feature space (e.g., $P=10,000$) and you decide, instead of using a single feature RDM, to use an individual RDM for each feature and analyze the neural RDM in with a reweighted analysis. Explain why, while this would guarantee amazing results, this is probably not a good idea and propose a practical solution.  
</div><p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="group-level-analyses">
<h3>Group-level analyses<a class="headerlink" href="#group-level-analyses" title="Permalink to this heading">#</a></h3>
<p>So far, we only analyzed a single subject. Often, you might want to analyze multiple subjects and perform inference on the group level. Just like we did with single-subject decoding model performance scores, we can test whether results are significant by testing them against chance-level (i.e., 0 when using correlations). For example, suppose I have the following subject-specific RDV correlations:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rdv_corrs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.03</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.02</span><span class="p">,</span> <span class="mf">0.00</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.07</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">,</span> <span class="mf">0.12</span><span class="p">,</span> <span class="mf">0.08</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.07</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.02</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>Just like we evaluated single-subject RDV correlations using a non-parameteric rank-based correlation (Spearman or Kendall’s Tau), it is common to use a non-parametric test for group-level analyses: the Wilcoxon signed-rank test:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">wilcoxon</span>
<span class="n">stat</span><span class="p">,</span> <span class="n">pval</span> <span class="o">=</span> <span class="n">wilcoxon</span><span class="p">(</span><span class="n">rdv_corrs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;P-value:&quot;</span><span class="p">,</span> <span class="n">pval</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>P-value: 0.08235221505280667
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (4 points): In this ToDo, you'll implement an RSA analysis from start to end (on 10 subjects) in which you investigate whether facial expression (smiling vs. neutral) is represented in the right temporal occipital fusiform. In the end, you should have 10 RDV correlations (stored in the pre-allocated <tt>rdv_corrs</tt> variable). We have written the start of the for-loop for you already. Within the loop, do the following:
<ul class="simple">
<li><p>Load in the events file as a DataFrame, extract the facial expression information (column: “expression”), convert it to a numeric format, and compute the corresponding feature RDM (using the manhattan distance);</p></li>
<li><p>Load in the patterns and apply the previously defined rTOF mask (the variable <tt>rTOF_roi_resamp</tt>);</p></li>
<li><p>Compute the neural RDM (using the Euclidean distance)</p></li>
<li><p>Compute the Kendall Tau correlation between the feature RDV and neural RDV and store this in the <tt>rdv_corrs</tt> array;</p></li>
<li><p>After the loop, compute the associated group-level p-value using the Wilcoxon signed-rank test and store this in a variable named <tt>pval</tt>.</p></li>
</ul>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading patterns for all subjects (+- 820 MB) ...&quot;</span><span class="p">)</span>
<span class="o">!</span>aws<span class="w"> </span>s3<span class="w"> </span>sync<span class="w"> </span>--no-sign-request<span class="w"> </span>s3://openneuro.org/ds003965<span class="w"> </span><span class="o">{</span>data_dir<span class="o">}</span><span class="w"> </span>--exclude<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;derivatives/pattern_estimation/sub*/ses-1/*task-face*run-1*space-MNI*&quot;</span>
<span class="o">!</span>aws<span class="w"> </span>s3<span class="w"> </span>sync<span class="w"> </span>--no-sign-request<span class="w"> </span>s3://openneuro.org/ds003965<span class="w"> </span><span class="o">{</span>data_dir<span class="o">}</span><span class="w"> </span>--exclude<span class="w"> </span><span class="s2">&quot;*&quot;</span><span class="w"> </span>--include<span class="w"> </span><span class="s2">&quot;derivatives/pattern_estimation/sub*/ses-1/*task-face*run-1*.tsv&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading patterns for all subjects (+- 820 MB) ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement the ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># We&#39;ll only analyze the first 10 subjects</span>
<span class="n">subs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">d</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span>
               <span class="n">glob</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span> <span class="s1">&#39;pattern_estimation&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-*&#39;</span><span class="p">))])</span>
<span class="n">subs</span> <span class="o">=</span> <span class="n">subs</span><span class="p">[:</span><span class="mi">10</span><span class="p">]</span>

<span class="c1"># Pre-allocate the correlation vector</span>
<span class="n">rdv_corrs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">subs</span><span class="p">))</span>

<span class="n">pattern_est_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span> <span class="s1">&#39;pattern_estimation&#39;</span><span class="p">)</span>

<span class="c1"># Iterate over subjects (i = 0:9)</span>
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">sub</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">subs</span><span class="p">):</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Processing </span><span class="si">%s</span><span class="s2"> ...&quot;</span> <span class="o">%</span> <span class="n">sub</span><span class="p">)</span>
    <span class="n">events_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pattern_est_dir</span><span class="p">,</span> <span class="n">sub</span><span class="p">,</span> <span class="s1">&#39;ses-1&#39;</span><span class="p">,</span> <span class="s1">&#39;patterns&#39;</span><span class="p">,</span> <span class="n">sub</span> <span class="o">+</span> <span class="s1">&#39;_ses-1_task-face_run-1_events.tsv&#39;</span><span class="p">)</span>
    <span class="n">patterns</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pattern_est_dir</span><span class="p">,</span> <span class="n">sub</span><span class="p">,</span> <span class="s1">&#39;ses-1&#39;</span><span class="p">,</span> <span class="s1">&#39;patterns&#39;</span><span class="p">,</span> <span class="n">sub</span> <span class="o">+</span> <span class="s1">&#39;_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz&#39;</span><span class="p">)</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo (part 1). &#39;&#39;&#39;</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span>
    <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span> <span class="mf">0.01328101</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01517032</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01950736</span><span class="p">,</span>  <span class="mf">0.01904201</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.0036204</span> <span class="p">,</span>
              <span class="o">-</span><span class="mf">0.01989825</span><span class="p">,</span>  <span class="mf">0.03360738</span><span class="p">,</span>  <span class="mf">0.02309053</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.00340634</span><span class="p">,</span>  <span class="mf">0.01325309</span><span class="p">]),</span>
    <span class="n">rdv_corrs</span><span class="p">,</span>
    <span class="n">decimal</span><span class="o">=</span><span class="mi">4</span>
<span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo (part 1). &#39;&#39;&#39;</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">pval</span><span class="p">,</span> <span class="mf">0.6953125</span><span class="p">,</span> <span class="n">decimal</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This notebook discussed the basics of representational similarity analysis. There are many more topics that we didn’t discuss (such as cross-validated distance metrics, noise ceilings, and comparing different feature RDMs).</p>
<p>For a more in-depth technical overview of RSA, we recommend the following article:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1003553">Nili, H., Wingfield, C., Walther, A., Su, L., Marslen-Wilson, W., &amp; Kriegeskorte, N. (2014). A toolbox for representational similarity analysis. PLoS computational biology, 10(4).</a></p></li>
</ul>
<p>(Note that the paper introduces a MATLAB toolbox for RSA; while in development, the authors recently rewrote the toolbox as a <a class="reference external" href="https://github.com/rsagroup/pyrsa">Python package</a>; if you want to do RSA in Python, I would recommend this package!)</p>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./fMRI-pattern-analysis/week_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="../week_2/decoding_analyses.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Machine learning (“decoding”) analyses</p>
      </div>
    </a>
    <a class="right-next"
       href="../../misc/bibliography.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Bibliography</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#loading-in-the-data">Loading in the data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#preprocessing">Preprocessing</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#multivariate-noise-normalization">Multivariate noise normalization</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#neural-rdms">Neural RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exploratory-analysis-using-mds">Exploratory analysis using MDS</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#categorical-rdms">Categorical RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#continuous-computational-rdms">Continuous/computational RDMs</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#testing-rdms">Testing RDMs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#correlation-based-tests">Correlation-based tests</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#reweighting-rdvs">Reweighting RDVs</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#group-level-analyses">Group-level analyses</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <div class="bd-footer-content__inner">
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Lukas Snoek
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2021.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div></div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=12da95d707ffb74b382d"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=12da95d707ffb74b382d"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>