
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Machine learning (“decoding”) analyses &#8212; NI-edu</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet" />
  <link href="../../_static/css/index.c5995385ac14fb8791e8eb36b4908be2.css" rel="stylesheet" />

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.1c5a1a01449ed65a7b51.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.12a9622fbb08dcb3a2a40b2c02b83a57.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.0/dist/embed-amd.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script async="async" src="https://unpkg.com/thebe@0.5.1/lib/index.js"></script>
    <script>
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Representational Similarity Analysis" href="../week_3/rsa.html" />
    <link rel="prev" title="Experimental design and pattern estimation" href="../week_1/design_and_pattern_estimation.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/fmri.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NI-edu</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../index.html">
   Welcome to NI-edu
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../getting_started/about.html">
   About this course
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../getting_started/installation.html">
   Installation
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  fMRI-introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/1_python.html">
   Python for (f)MRI analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../other/python_recap.html">
     Python recap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_1/python_for_mri.html">
     Working with MRI data in Python (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/2_glm.html">
   Using the GLM to model fMRI data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_2/glm_part1_estimation.html">
     The GLM: estimation (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_3/glm_part2_inference.html">
     The GLM: inference (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/3_design_of_experiments_T.html">
   Design of experiments
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_3/design_of_experiments.html">
     Design of experiments (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_3/neurodesign.html">
     Neurodesign (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/4_preprocessing.html">
   Preprocessing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_4/temporal_preprocessing.html">
     Temporal preprocessing (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_4/spatial_preprocessing.html">
     Spatial preprocessing (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_4/fmriprep.html">
     Fmriprep (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/5_multilevel.html">
   First &amp; run-level analyses
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_5/linux_and_the_command_line.html">
     Linux and the CMD (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_5/first_level_analyses.html">
     First level analyses (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_5/run_level_analyses.html">
     Run-level analyses (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/6_grouplevel.html">
   Group-level analyses
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_6/group_level_analyses.html">
     Group-level analyses (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_6/MCC.html">
     Multiple comparison correction (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_6/ROI_analysis.html">
     ROI analysis (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/7_nilearn.html">
   Introduction to Nilearn
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_7/nilearn.html">
     Introduction to Nilearn (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../fMRI-introduction/week_7/nilearn_stats.html">
     Statistics with Nilearn (T)
    </a>
   </li>
  </ul>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  fMRI-pattern-analysis
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../week_1/design_and_pattern_estimation.html">
   Design and pattern estimation (T)
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Machine learning/decoding (T)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../week_3/rsa.html">
   Representational Similarity Analysis (T)
  </a>
 </li>
</ul>
<p class="caption" role="heading">
 <span class="caption-text">
  Misc
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/for_educators.html">
   For educators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/CONTRIBUTING.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/CONDUCT.html">
   Code of Conduct
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/fMRI-pattern-analysis/week_2/decoding_analyses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/lukassnoek/NI-edu"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/lukassnoek/NI-edu/issues/new?title=Issue%20on%20page%20%2FfMRI-pattern-analysis/week_2/decoding_analyses.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/lukassnoek/NI-edu/edit/master/NI-edu/fMRI-pattern-analysis/week_2/decoding_analyses.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/lukassnoek/NI-edu/master?urlpath=tree/NI-edu/fMRI-pattern-analysis/week_2/decoding_analyses.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        <a class="jupyterhub-button" href="https://neuroimaging.lukas-snoek.com/hub/user-redirect/git-pull?repo=https://github.com/lukassnoek/NI-edu&urlpath=tree/NI-edu/NI-edu/fMRI-pattern-analysis/week_2/decoding_analyses.ipynb&branch=master"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch JupyterHub" data-toggle="tooltip"
                data-placement="left"><img class="jupyterhub-button-logo"
                    src="../../_static/images/logo_jupyterhub.svg"
                    alt="Interact on JupyterHub">JupyterHub</button></a>
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#data-representation">
   Data representation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#standardization">
   Standardization
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#fitting-models">
   Fitting models
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#model-evaluation">
   Model evaluation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics-for-discrete-predictions">
     Metrics for discrete predictions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#metrics-for-probabilistic-predictions">
     Metrics for probabilistic predictions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#cross-validation">
   Cross-validation
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sidenote-scikit-learn-pipelines">
     Sidenote: scikit-learn
     <code class="docutils literal notranslate">
      <span class="pre">
       Pipelines
      </span>
     </code>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#class-imbalance-and-model-performance-revisited">
   Class imbalance and model performance revisited
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#feature-selection-extraction">
   Feature selection/extraction
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#roi-selection">
     ROI selection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#pca">
     PCA
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#region-averaging">
     Region averaging
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#searchlight-analysis">
     Searchlight analysis
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#significance-tests-and-permutation-testing">
   Significance tests and permutation testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-your-observed-performance-score">
     Getting your
     <em>
      observed
     </em>
     performance score
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#getting-your-permuted-performance-distribution">
     Getting your
     <em>
      permuted
     </em>
     performance distribution
    </a>
   </li>
  </ul>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="machine-learning-decoding-analyses">
<h1>Machine learning (“decoding”) analyses<a class="headerlink" href="#machine-learning-decoding-analyses" title="Permalink to this headline">¶</a></h1>
<p>This week’s tutorial is about how to implement “decoding” analyses in Python!</p>
<p>The term “decoding” is often used to denote analyses that aim to predict a single experimental feature (which can be either within-subject or between-subject) based on patterns of neuroimaging data. Some more advanced techniques make it possible to predict more than one experimental feature at once (with <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0896627309006850">Bayesian “reconstruction” techniques</a> and <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S0896627315006352">“inverted encoding models”</a>), but these are beyond the scope of this course. Here, we’ll focus on machine learning/statistical models and techniques that allow you to predict a single experimental feature.</p>
<p>We’ll make heavy use of the awesome <a class="reference external" href="http://scikit-learn.org/stable/">scikit-learn</a> library — the go-to library for machine learning in Python.</p>
<p><strong>What you’ll learn</strong>: at the end of this tutorial, you will be able to:</p>
<ul class="simple">
<li><p>use and implement feature-selection/extraction methods;</p></li>
<li><p>fit machine learning models and predict (new) samples;</p></li>
<li><p>implement cross-validation routines;</p></li>
<li><p>statistically evaluate model performance estimates;</p></li>
</ul>
<p><strong>Estimated time needed to complete</strong>: 8-12 hours<br>
<strong>Credits</strong>: if you use scikit-learn in your research, please cite the corresponding <a class="reference external" href="http://www.jmlr.org/papers/v12/pedregosa11a">paper</a></p>
<div class="section" id="data-representation">
<h2>Data representation<a class="headerlink" href="#data-representation" title="Permalink to this headline">¶</a></h2>
<p>Decoding analyses always need two sets of data: the brain patterns, which we’ll refer to as <span class="math notranslate nohighlight">\(\mathbf{R}\)</span> (for <strong>R</strong>esponse), and a single experimental feature that we want to predict, which we’ll refer to as <span class="math notranslate nohighlight">\(\mathbf{S}\)</span> (which traditionally refers to <strong>S</strong>timulus). Note that <span class="math notranslate nohighlight">\(\mathbf{s}\)</span> could be a within-subject experimental factor (such as stimulus or response-related factors) or a between-subject variable (such as age or depressed vs. healthy control). Moreover, the to-be-predicted variable* can be either continuous (e.g., reaction time) or categorical (e.g., object category), which are associated with different types of models, regression and classification models respectively (more about this later). Note that “direction” of analysis is the exact opposite of what is done in enconding analyses. In encoding analyses, we try to predict the brain data (dependent variable) using experimental features (independent variables), while in decoding analyses we try to predict an experimental feature (dependent variable) using a a set of brain patterns (independent variables)! But essentially, encoding and decoding models are mathematically the same (they just use different inputs).</p>
<p>In the first part of this lab, we’ll work with simulated data. For now, we’ll assume that our data is from a simple face perception experiment in which participants viewed images with either male (condition: “M”) or female faces (condition: “F”) across four different fMRI runs. So, our experimental feature of interest is a categorical variable with two levels (“M” and “F”), making this a classification analysis (which is more common than regression in the context of cognitive neuroscience). Each run, participants saw fourty images (twenty for each condition) presented in a random order.</p>
<p>We’ll simulate the patterns (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) and experimental feature (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span>, “M” vs. “F”) below. For now, we’ll generate random data (with some autocorrelation), for reasons that will become clear later. We’ll assume that we are restricting our analysis to a single region-of-interest containing a 1000 voxels.</p>
<hr class="docutils" />
<p>* Often, the to-be-predicted variable is called the “target” or “dependent variable”. Here, we’ll use the term “target”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">toeplitz</span>
<span class="kn">from</span> <span class="nn">niedu.utils.nipa</span> <span class="kn">import</span> <span class="n">generate_labels</span>

<span class="n">N_per_run</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">M</span> <span class="o">=</span> <span class="mi">4</span>  <span class="c1"># nr of runs</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">1000</span>  <span class="c1"># nr of voxels</span>

<span class="c1"># Generate random data drawn for a multivariate normal</span>
<span class="c1"># distribution with AR1 noise (with phi = 0.85) to</span>
<span class="c1"># simulate autocorrelated noise in the estimated patterns,</span>
<span class="c1"># which is plausible for designs with relatively short ISIs</span>
<span class="n">mu</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N_per_run</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="mf">0.85</span> <span class="o">**</span> <span class="n">toeplitz</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N_per_run</span><span class="p">))</span>

<span class="c1"># R_runs is a list of M arrays of shape N_per_run x K</span>
<span class="n">R_runs</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mu</span><span class="p">,</span> <span class="n">V</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">K</span><span class="p">)</span><span class="o">.</span><span class="n">T</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>

<span class="c1"># S_runs is a list of M arrays of shape N_per_run</span>
<span class="c1"># The custom generate_label function creates slightly correlated</span>
<span class="c1"># labels</span>
<span class="n">S_runs</span> <span class="o">=</span> <span class="p">[</span><span class="n">generate_labels</span><span class="p">([</span><span class="s1">&#39;M&#39;</span><span class="p">,</span> <span class="s1">&#39;F&#39;</span><span class="p">],</span> <span class="n">N_per_run</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">])</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Example of patterns for run 1:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">R_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Example of target for run 1:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">S_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Example of patterns for run 1:
 [[-1.37770011 -0.93361294 -0.11706339 ...  0.15131107  1.08584822
  -0.0024457 ]
 [-1.3258714  -0.56701812  0.30351148 ...  0.3083146   0.9502878
  -0.17276412]
 [-1.30013967 -0.20775572  0.31051847 ...  0.62518616  0.84463005
  -0.52389025]
 ...
 [ 1.67724045 -0.61859348 -0.53365188 ... -0.057661   -0.58117398
  -0.24297167]
 [ 0.75211781 -0.76350046 -0.54972731 ...  0.02910283  0.55138275
   0.11788449]
 [ 0.58037108 -0.33404973 -1.21667738 ...  0.52356051  1.29515506
  -1.60036337]]

Example of target for run 1:
 [&#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;M&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;F&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;, &#39;M&#39;]
</pre></div>
</div>
</div>
</div>
<p>Alright, technically, we have everything we need for a decoding analysis. However, machine learning (ML) and statistical models often require all data to be represented numerically, so we need to convert our target (containing the values “M” and “F”) into a numeric format.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (optional; 0 points): If you want to practice your Python skills, try converting the string labels of run 1 (the <tt>S_run1</tt> variable below) to numeric labels. Specifically, use the integer 0 for trials of condition "F" and the integer 1 for trials of condition "M". Store the result in a new variable called <tt>S_run1_num</tt>; make sure it's a numpy array. (To convert a list to a numpy array, you can do: <tt>np.array(your_list)</tt> ).
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">S_run1</span> <span class="o">=</span> <span class="n">S_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_lab2num</span>
<span class="n">test_lab2num</span><span class="p">(</span><span class="n">S_run1</span><span class="p">,</span> <span class="n">S_run1_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>While converting labels to numeric values can be done quite easily using standard Python, it gives us with a nice excuse to introduce some scikit-learn functionality. Specifically, the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> class, which allows you to <em>encode</em> your target <em>labels</em> into a numeric format. Let’s start with importing it (from the <code class="docutils literal notranslate"><span class="pre">preprocessing</span></code> module):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>
</pre></div>
</div>
</div>
</div>
<p>The way <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> is used is similar to some of the Nilearn and Nistats functionality you’ve seen. In short, you first need to initialize the object (with, optionally, some parameters), after which you can give it data to <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code>. This pattern is something we’ll encounter a lot in this lab when working with scikit-learn.</p>
<p>Let’s initialize a <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> object below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># LabelEncoder objects are not initialized with any parameters</span>
<span class="n">lab_enc</span> <span class="o">=</span> <span class="n">LabelEncoder</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>Now, let’s “fit” it on the labels of our first run:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lab_enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">S_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LabelEncoder()
</pre></div>
</div>
</div>
</div>
<p>Notice that the <code class="docutils literal notranslate"><span class="pre">fit</span></code> function doesn’t <em>return</em> anything useful (well, technically, it returns it<em>self</em>). Instead, when calling <code class="docutils literal notranslate"><span class="pre">fit</span></code>, it stores some parameters in the object itself as <em>attributes</em> which are used when calling the transform. For the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> specifically, it stores the unique conditions (often called <em>classes</em> in machine learning) in an attribute called <code class="docutils literal notranslate"><span class="pre">classes_</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">lab_enc</span><span class="o">.</span><span class="n">classes_</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;F&#39; &#39;M&#39;]
</pre></div>
</div>
</div>
</div>
<p>In general, most “things” that are inferred or computed in the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method of scikit-learn objects (and are needed later when calling <code class="docutils literal notranslate"><span class="pre">transform</span></code>) are stored in attributes with a trailing underscore (like <code class="docutils literal notranslate"><span class="pre">classes_</span></code>). We know, this all sounds incredibly trivial, but explaning these things in detail will give you a better understanding of how scikit-learn works (which is going to help a lot when dealing with more complicated functionality).</p>
<p>Finally, after fitting the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> object, we can call the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method to actually transform the labels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">S_run1_num</span> <span class="o">=</span> <span class="n">lab_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">S_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">S_run1_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1
 1 1 1]
</pre></div>
</div>
</div>
</div>
<p>Note that, unlike the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method, the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method actually returns something, i.e., the transformed labels. Also note that the numeric labels are assigned alphabetically (i.e., “F” gets assigned 0, “M” gets assigned 1).</p>
<p>Like you’ve seen in the Nilearn notebook, we can often call <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> at once using the <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">S_run1_num</span> <span class="o">=</span> <span class="n">lab_enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">S_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">S_run1_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 0 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 1
 1 1 1]
</pre></div>
</div>
</div>
</div>
<p>Also, after the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> has been fit, it can be reused on other data, i.e., you can call the <code class="docutils literal notranslate"><span class="pre">transform</span></code> method on new arrays. This is how many classes in scikit-learn are actually used (i.e., fit on a particular subset of data and then apply to another subset), as it allows for efficient <em>cross-validation</em> &amp;mdash a topic that will discuss in detail later.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): We just converted the labels from the first run only. For this ToDo, convert the labels from <em>all</em> runs (i.e., the <tt>S_runs</tt> variable) using the <tt>LabelEncoder</tt>. Store the results in a new variable named <tt>S_runs_num</tt>, which should be a list (of length four, i.e., four runs) of arrays with ones and zeros (instead of "M" and "F"). 
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here . &#39;&#39;&#39;</span>
<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_lab2num_all_runs</span>   
<span class="n">test_lab2num_all_runs</span><span class="p">(</span><span class="n">S_runs</span><span class="p">,</span> <span class="n">lab_enc</span><span class="p">,</span> <span class="n">S_runs_num</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alright, now we have everything we need to start building our decoding pipeline!</p>
</div>
<div class="section" id="standardization">
<h2>Standardization<a class="headerlink" href="#standardization" title="Permalink to this headline">¶</a></h2>
<p>In addition to the “preprocessing” steps for pattern analyses discussed in last week’s lab, when doing decoding, you additionally need to standardize your brain features (i.e., the columns in your pattern matrix) on which you fit your model. With “standardization”, we mean making sure each feature (<span class="math notranslate nohighlight">\(\mathbf{R}_{j}\)</span> for column <span class="math notranslate nohighlight">\(j\)</span>) in your pattern matrix has 0 zero mean and unit (1) standard deviation, which can be achieved as follows for each feature <span class="math notranslate nohighlight">\(j\)</span>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f245a669-0dd1-41e8-9020-b8b1ae8bc14e">
<span class="eqno">(92)<a class="headerlink" href="#equation-f245a669-0dd1-41e8-9020-b8b1ae8bc14e" title="Permalink to this equation">¶</a></span>\[\begin{align}
\mathbf{R}_{j, norm} = \frac{\mathbf{R}_{j} - \bar{\mathbf{R}}_{j}}{\hat{\sigma}(\mathbf{R}_{j})}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{\mathbf{R}_{j}}\)</span> represents the <em>mean</em> of <span class="math notranslate nohighlight">\(\mathbf{R}_{j}\)</span> and <span class="math notranslate nohighlight">\(\hat{\sigma}(\mathbf{R}_{j})\)</span> represents the standard deviation of <span class="math notranslate nohighlight">\(\mathbf{R}_{j}\)</span>. In other words, for each value in <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>, you subtract the mean from the column it belongs to and subsequently you divide the result by the standard deviation of the column it belongs to. This process is also known as <em>z-scoring</em>.</p>
<p>This standardization process is done for each brain feature (column) separately. Standardization is important for most ML/statistical models because it makes sure that each brain feature has the same <em>scale</em>, which often helps in efficiently estimating model parameters.</p>
<p>Importantly, when you have patterns from multiple runs (as is often the case in fMRI decoding), these patterns should also be independently standardized, even if you want to pool these patterns later on (see <a class="reference external" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0207083">Lee &amp; Kable, 2018</a>). This is because some runs may yield patterns with a relatively higher mean or standard deviation across samples (for example, because participants start moving more towards the end of the experiment, leading to more noisy pattern estimates).</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): In this ToDo, you have to standardize the data from run 1 (the <tt>R_run1</tt> variable below) using Numpy (afterwards, we'll show you how to do this using scikit-learn). Store the results (which should have columns with mean zero and unit standard deviation) in a new variable called <tt>R_run1_norm</tt>. Importantly, this can be done efficiently (without a for-loop) using broadcasting!
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="n">R_run1</span> <span class="o">=</span> <span class="n">R_runs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the ToDo above. &#39;&#39;&#39;</span>
<span class="c1"># ToThink: do you understand how we&#39;re testing your answer here?</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">R_run1_norm</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">R_run1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">R_run1_norm</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">R_run1</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We can do this similarly using the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> class from scikit-learn, which has the same <code class="docutils literal notranslate"><span class="pre">fit</span></code>/<code class="docutils literal notranslate"><span class="pre">transform</span></code> interface:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">R_run1_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">R_run1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>In the fitting process, the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> computed the feature-wise mean and standard deviation, which it stores in the <code class="docutils literal notranslate"><span class="pre">mean_</span></code> and <code class="docutils literal notranslate"><span class="pre">_scale</span></code> attributes:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">mean_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scaler</span><span class="o">.</span><span class="n">scale_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(1000,)
(1000,)
</pre></div>
</div>
</div>
</div>
<p>For the initial run-wise standardization, we usually don’t want to cross-validate our standardization process (i.e., to for example fit the <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> on run 1 and subsequently transform the other runs) for reasons discussed before. As such, we need to call fit and transform on each run separately:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Below, we use a &quot;list comprehension&quot; to loop across our runs</span>
<span class="c1"># to standardize each run separately!</span>
<span class="n">R_runs_norm</span> <span class="o">=</span> <span class="p">[</span><span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">this_R</span><span class="p">)</span> <span class="k">for</span> <span class="n">this_R</span> <span class="ow">in</span> <span class="n">R_runs</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>We’re almost ready to start fitting models. Before we do so, we are going to concatenate our data (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span> and <span class="math notranslate nohighlight">\(S\)</span>) across runs because we want to give our model as much data as possible!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Load S_runs_num if you didn&#39;t manage to do the last ToDo</span>
<span class="n">S_runs_num</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;S_runs_num.npy&#39;</span><span class="p">)</span>

<span class="n">R_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">(</span><span class="n">R_runs_norm</span><span class="p">)</span>  <span class="c1"># stack vertically</span>
<span class="n">S_all</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">S_runs_num</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape R_all:&quot;</span><span class="p">,</span> <span class="n">R_all</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape S_all:&quot;</span><span class="p">,</span> <span class="n">S_all</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape R_all: (160, 1000)
Shape S_all: (160,)
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="fitting-models">
<h2>Fitting models<a class="headerlink" href="#fitting-models" title="Permalink to this headline">¶</a></h2>
<p>When fitting decoding models, we assume that we can approximate our target variable (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span>) as a function of the input data (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>):</p>
<div class="amsmath math notranslate nohighlight" id="equation-d271ea25-60fe-4028-826e-d21e48ba7c6f">
<span class="eqno">(93)<a class="headerlink" href="#equation-d271ea25-60fe-4028-826e-d21e48ba7c6f" title="Permalink to this equation">¶</a></span>\[\begin{align}
\hat{\mathbf{S}} \approx f(\mathbf{R})
\end{align}\]</div>
<p>Usually, the models used in pattern analyses assume linear functions (especially with relatively little data), i.e., functions that approximate the target using a linear combination of input variables (<span class="math notranslate nohighlight">\(\mathbf{R}_{j}\)</span>) weighted by parameters (<span class="math notranslate nohighlight">\(\beta\)</span>). Note that the univariate GLM often used in encoding models is such a linear model. The process of model fitting is estimating parameters that minize the discrepancy (error) between the predicted values (<span class="math notranslate nohighlight">\(\hat{\mathbf{S}}\)</span>) and the actual values (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span>) of the target variable, both for regression (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span> is continuous) and classification (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span> is categorical) models. Different models differ in how they exactly estimate their parameters, but the general process is the same (minimizing error between predictions and target). In this course, we won’t go much into the differences across models (partly because in practice, we found that performance doesn’t differ that much between models).</p>
<p>Alright, let’s get to it. Below, we import the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html">LogisticRegression</a> class, a particular linear <em>classification</em> model (unlike the name suggests).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
</pre></div>
</div>
</div>
</div>
<p>We are many “options” (often called “hyperparameters”) we can set upon initialization of a <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> object, but for now, we will only set the “solver” (for no other reason that this will get rid of a warning during the fitting process):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># clf = CLassiFier</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, the fitting process using this model (or actually, <em>any</em> model in scikit-learn) is as simple as, guess what, calling the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method! Unlike the <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> and <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code> that we discussed before, models in scikit-learn (including <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>) require two arguments when calling their <code class="docutils literal notranslate"><span class="pre">fit</span></code> method: <code class="docutils literal notranslate"><span class="pre">X</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code>, which represent the input data (in our case: <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) and the target variable (in our case: <span class="math notranslate nohighlight">\(\mathbf{S}\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The text in the output cell is there because the</span>
<span class="c1"># fit model returns &quot;itself&quot; (you can just ignore this)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_all</span><span class="p">,</span> <span class="n">S_all</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression()
</pre></div>
</div>
</div>
</div>
<p>After fitting, the model stores the estimated parameters (<span class="math notranslate nohighlight">\(\beta\)</span>) as an araay in the <code class="docutils literal notranslate"><span class="pre">coef_</span></code> (“coefficients”, another term for parameters) attribute:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of coef_:&quot;</span><span class="p">,</span> <span class="n">clf</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of coef_: (1, 1000)
</pre></div>
</div>
</div>
</div>
<p>As you can see, the model estimated one parameter for each brain feature (column in <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>). Now, unlike the previously discussed <code class="docutils literal notranslate"><span class="pre">LabelEncoder</span></code> and <code class="docutils literal notranslate"><span class="pre">StandardScaler</span></code>, scikit-learn models do not have a <code class="docutils literal notranslate"><span class="pre">transform</span></code> method; instead, they have a <code class="docutils literal notranslate"><span class="pre">predict</span></code> method, which takes a single input (a 2D array with observations) and generates discrete* predictions for this input. For now, we’ll call <code class="docutils literal notranslate"><span class="pre">predict</span></code> on the same data we’ve fit the model on:</p>
<hr class="docutils" />
<p>* Some models, including the <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> model, have an additional method called <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> which returns probabilistic instead of discrete predictions.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_all</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictions for samples in R_all:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictions for samples in R_all:
 [0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0
 0 0 0 1 1 0 0 1 1 0 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1
 1 1 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 0 1 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1
 1 0 0 1 0 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0 0 0 0 0 0 0]
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="model-evaluation">
<h2>Model evaluation<a class="headerlink" href="#model-evaluation" title="Permalink to this headline">¶</a></h2>
<p>Alright, we have some preditions for our data! But how do we evaluate these predictions? This actually depends on whether you have a classification model (with categorical predictions) or a regression model (with continuous predictions). Because classification analyses are most popular in cognitive neuroscience (and our example data is categorical) and you are already familiar with some regression metrics such as <span class="math notranslate nohighlight">\(R^2\)</span> (discussed in the previous course), we’ll focus on model evaluation metrics for classification here.</p>
<div class="section" id="metrics-for-discrete-predictions">
<h3>Metrics for discrete predictions<a class="headerlink" href="#metrics-for-discrete-predictions" title="Permalink to this headline">¶</a></h3>
<p>There are many different metrics to evaluate the predictions of classification models. The most well known (but not necessarily always appropriate) metric for <em>discrete</em> predictions is <em>accuracy</em>, which is defined as follows:</p>
<div class="amsmath math notranslate nohighlight" id="equation-ea22bd72-f2df-40f8-a716-182013c3af10">
<span class="eqno">(94)<a class="headerlink" href="#equation-ea22bd72-f2df-40f8-a716-182013c3af10" title="Permalink to this equation">¶</a></span>\[\begin{align}
\mathrm{accuracy} = \frac{\mathrm{number\ of\ correct\ predictions}}{\mathrm{total\ number\ of\ predictions}}
\end{align}\]</div>
<p>For accuracy, the best possible score is 1 (predict all samples correctly) and “chance level” performance (i.e., the expected score when randomly guessing) is, in general, <span class="math notranslate nohighlight">\(\frac{1}{\mathrm{Number\ of\ classes}}\)</span>, so for our example with two classes (“M” and “F”), it is 0.5.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Using the predictions (the <tt>preds</tt> variable) and the true labels (the <tt>S_all</tt> variable), compute the associated accuracy and store this in a variable <tt>acc</tt>. Note: there is no need for a for-loop! You can use the fact that boolean values, <tt>True</tt> and <tt>False</tt>, evaluate to 1 and 0, respectively, in Python... 
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_acc</span>
<span class="n">test_acc</span><span class="p">(</span><span class="n">preds</span><span class="p">,</span> <span class="n">S_all</span><span class="p">,</span> <span class="n">acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="metrics-for-probabilistic-predictions">
<h3>Metrics for probabilistic predictions<a class="headerlink" href="#metrics-for-probabilistic-predictions" title="Permalink to this headline">¶</a></h3>
<p>Some classifiers allow for <em>probabilistic</em> (instead of discrete) predictions. For those classifiers, an additional method called <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> exists, which outputs a probability for each class. So, in a two-class classification setting, the <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> method will not give a single discrete prediction (i.e., either <code class="docutils literal notranslate"><span class="pre">0</span></code> or <code class="docutils literal notranslate"><span class="pre">1</span></code>) but a probability distribution over classes (e.g., 0.92 for class <code class="docutils literal notranslate"><span class="pre">0</span></code> and 0.08 for class <code class="docutils literal notranslate"><span class="pre">1</span></code>).</p>
<p>The <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> model from scikit-learn actually allows for probabilistic prediction. In general, if we’ll give it all <span class="math notranslate nohighlight">\(N\)</span> trials for a target variable with <span class="math notranslate nohighlight">\(M\)</span> classes, it will output a <span class="math notranslate nohighlight">\(N \times M\)</span> array with probabilities:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probas</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">R_all</span><span class="p">)</span>
<span class="c1"># let&#39;s print the first five trials</span>
<span class="nb">print</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">probas</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:],</span> <span class="mi">3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[[0.998 0.002]
 [0.997 0.003]
 [0.999 0.001]
 [0.979 0.021]
 [0.017 0.983]]
</pre></div>
</div>
</div>
</div>
<p>One often-used performance metric for probabilistic predictions is the “Area Under the ROC curve” (often abbreviated as <em>AUROC</em> or just <em>AUC</em>). Fortunately, the scikit-learn library contains implementations of many performance metrics, including AUROC (called <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code> in scikit-learn), which can be imported from the <code class="docutils literal notranslate"><span class="pre">metrics</span></code> module:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>
</pre></div>
</div>
</div>
</div>
<p>AUROC is an excellent metric to use for probabilistic predictions, but there’s one caveat: when evaluating probabilistic predictions (formatted as a <span class="math notranslate nohighlight">\(N \times M\)</span> matrxi), it needs the <em>true</em> target values (dependent variable) in a <em>one-hot-encoded</em> format. One-hot-encoding (OHE) is a technique that transforms a <span class="math notranslate nohighlight">\(N \times 1\)</span> vector with <span class="math notranslate nohighlight">\(M\)</span> classes into a <span class="math notranslate nohighlight">\(N \times M\)</span> binary matrix:</p>
<div class="amsmath math notranslate nohighlight" id="equation-809f8c74-cb6a-4eb1-bce7-a6a05b7a679b">
<span class="eqno">(95)<a class="headerlink" href="#equation-809f8c74-cb6a-4eb1-bce7-a6a05b7a679b" title="Permalink to this equation">¶</a></span>\[\begin{align}
S = \begin{bmatrix}
1 \\
2 \\
1 \\
3 \\
2 \\
4
\end{bmatrix}
\underset{\Longrightarrow}{\mathrm{OHE}} \begin{bmatrix}
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
1 &amp; 0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 1 &amp; 0 \\
0 &amp; 1 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 &amp; 1
\end{bmatrix}
\end{align}\]</div>
<p>You might know this technique under the name “dummy (en)coding”.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (optional): Complete the <tt>one_hot_encode</tt> function below that takes in a 1D vector representing a target variable with any number of classes and observations and outputs a one-hot-encoded version of that target variable.  
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement the optional ToDo here. &#39;&#39;&#39;</span>

<span class="k">def</span> <span class="nf">one_hot_encode</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; One-hot-encodes a 1D target vector. </span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    y : numpy array</span>
<span class="sd">        1D target vector with N observations and M classes</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    An NxM numpy array</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="c1"># Test 1</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

<span class="c1"># Test 2</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]])</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

<span class="c1"># Test 3</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">one_hot_encode</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">ans</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rot90</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">3</span><span class="p">))</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_equal</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">out</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>While the above ToDo was a nice way to practice your Python skills, we nonethless recommend using the <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> class from scikit-learn to one-hot-encode your target vector. It uses the <code class="docutils literal notranslate"><span class="pre">fit</span></code>-<code class="docutils literal notranslate"><span class="pre">transform</span></code> syntax you are familiar with by now. Importantly, as the <code class="docutils literal notranslate"><span class="pre">OneHotEncoder</span></code> is, in practice, often used to one-hot-encoded predictors (independent variables), it expects a 2D array (not a 1D vector). So, when one-hot-encoding a 1D target variable, you can add a singleton axis (with <code class="docutils literal notranslate"><span class="pre">np.newaxis</span></code>) to make it work:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">OneHotEncoder</span>
<span class="n">ohe</span> <span class="o">=</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">sparse</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>  <span class="c1"># we don&#39;t want a &quot;sparse&quot; output</span>
<span class="n">S_all_ohe</span> <span class="o">=</span> <span class="n">ohe</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">S_all</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">S_all_ohe</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(160, 2)
</pre></div>
</div>
</div>
</div>
<p>Finally, we can use the <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code> function to compute our model performance. Like any metric implementation in scikit-learn, it is called as follows:</p>
<div class="highlight-Python notranslate"><div class="highlight"><pre><span></span><span class="n">score</span> <span class="o">=</span> <span class="n">metric</span><span class="p">(</span><span class="n">true_labels</span><span class="p">,</span> <span class="n">predicted_labels</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="docutils literal notranslate"><span class="pre">true_labels</span></code> and <code class="docutils literal notranslate"><span class="pre">predicted_labels</span></code> are either 1D vectors of length <span class="math notranslate nohighlight">\(N\)</span> (in case of discrete predictions) or 2D <span class="math notranslate nohighlight">\(N \times M\)</span> arrays (in case of probabilistic predictions). Note that by default these metrics output a single score (often the average of the class-specific scores); some (but not all) metrics (including the <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code>) allow the function to return a class-specific score by setting the optional argument <code class="docutils literal notranslate"><span class="pre">average</span></code> to <code class="docutils literal notranslate"><span class="pre">None</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Omit average=None to get a single (average) score</span>
<span class="n">scores</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">S_all_ohe</span><span class="p">,</span> <span class="n">probas</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[1. 1.]
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (optional, quite difficult!): Another class of classification metrics are "pseudo $R^2$" scores. These metrics are similar to $R^2$ in regression models in the sense that they are bounded between 0 (chance performance) and 1 (perfect performance). They often assume probabilistic predictions. 
<p>One of these pseudo <span class="math notranslate nohighlight">\(R^2\)</span> metrics is “Tjur’s pseudo <span class="math notranslate nohighlight">\(R^2\)</span>” which is defined as the difference between the average (across observations) probability of a particular class and the average probability of the other class(es) for a given label. So, suppose we’re dealing with a two-class classification problem (with class 0 and class 1), and the average probability for class 1 of trials belonging to class 1 is 0.9, while the average probability for class 1 of trials belonging to class 0 is 0.3, then the Tjur’s pseudo <span class="math notranslate nohighlight">\(R^2\)</span> score for class 1 is <span class="math notranslate nohighlight">\(0.9-0.3=0.6\)</span>. Formally, the Tjur’s pseudo <span class="math notranslate nohighlight">\(R^2\)</span> score for class <span class="math notranslate nohighlight">\(m\)</span> is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c1ec4575-1659-42de-85c9-de4b037f503e">
<span class="eqno">(96)<a class="headerlink" href="#equation-c1ec4575-1659-42de-85c9-de4b037f503e" title="Permalink to this equation">¶</a></span>\[\begin{align}
R^2_{m} = \frac{1}{N}\sum_{i=1}^{N}p(\hat{s}^{m}_{i}) - \frac{1}{N}\sum_{i=1}^{N}p(\hat{s}^{\neg m}_{i})
\end{align}\]</div>
<p>for any set of trials belonging to class 1 (<span class="math notranslate nohighlight">\(p^{m}_{i}\)</span>) and complementary set of trials <em>not</em> beloning to class 1 (<span class="math notranslate nohighlight">\(p^{\neg m}_{i}\)</span>).</p>
<p>Complete the function <tt>tjur_r2</tt> below that takes two arguments — <tt>target</tt> (a 1D array with target labels) and <tt>probas</tt> (a 2D array with probabilities) — and should output an array of length <span class="math notranslate nohighlight">\(M\)</span> with Tjur’s pseudo <span class="math notranslate nohighlight">\(R^2\)</span> scores for the <span class="math notranslate nohighlight">\(M\)</span> classes in the target array.</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="k">def</span> <span class="nf">tjur_r2</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">probas</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Computes Tjur&#39;s R2 score for all classes in `target`.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : numpy array</span>
<span class="sd">        A 1D array with numerical targets</span>
<span class="sd">    probas : numpy array</span>
<span class="sd">        A 2D array with target probabilities</span>
<span class="sd">    </span>
<span class="sd">    Outputs</span>
<span class="sd">    -------</span>
<span class="sd">    A numpy array of length M with R2 scores for all M classes</span>
<span class="sd">    &#39;&#39;&#39;</span>
    
    <span class="c1"># YOUR CODE HERE</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the ToDo above. &#39;&#39;&#39;</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">0.05</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">]])</span>
<span class="n">ans</span> <span class="o">=</span> <span class="n">tjur_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.575</span><span class="p">,</span> <span class="mf">0.575</span><span class="p">]))</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.4</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.6</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
<span class="n">ans</span> <span class="o">=</span> <span class="n">tjur_r2</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">ans</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.4</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-block alert-success'>
    <b>Tip</b>: <a href="https://www.biorxiv.org/content/10.1101/743138v1.abstract">This article</a> by Dinga and colleagues (2019) argues against "accuracy" as a performance metric for classification models and reviews several (often probabilistic) alternatives; a highly recommended read!
</div></div>
</div>
<div class="section" id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this headline">¶</a></h2>
<p>If you did the previous ToDos correctly, you should have found that the accuracy was 1 (the maximum possible score)! Amazing! But wait, how is this possible? We generated <em>random</em> data, right?</p>
<p>So, what is the issue here? Well, we fitted the model on the same data that we want to generate predictions for! While this is common practice in many statistical models in psychology and neuroscience (including standard univariate “activation-based” fMRI models), this is not advisable for decoding models. The reason for this is that our decoding models often have many more predictors (i.e., brain features) than observations (i.e., trials). The consequence is that the model has a hard time figuring out what is “signal” and what is “noise”, which will often cause your model to capitalize on spurious correlations between your data (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) and the target (<span class="math notranslate nohighlight">\(\mathbf{S}\)</span>). The result is that your model will be <em>overfitted</em> and your model performance estimate will be overly optimistic estimate of generalization performance.</p>
<p>One possible solution, common in decoding analyses, is to <em>cross-validate</em> your analysis. Cross-validation is, in it’s broadest definition, the process of estimating analysis parameters on a different subset of your data than the data you want to generate predictions for. With “analysis parameters”, we do not only mean the parameters of your statistical model (<span class="math notranslate nohighlight">\(\hat{\beta}\)</span>), but this may also involve parameters estimated during preprocessing and feature transformations (which we’ll talk about later). Importantly, cross-validation (if done properly) allows you to derive an unbiased estimate of generalization performance, i.e., how well your analysis would generalize to a new dataset.</p>
<p>Usually, the subset of data you use to fit your analysis parameters on is called the <em>train</em> set and the subset you evaluate your model predictions on is often called the <em>test</em> set. Assuming that each observation (i.e., row in <span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) is independent from all other observations, any spurious correlation that is capitalized upon in the train set will not generalize to the test set!</p>
<p>There are different cross-validation schemes (i.e., how you partition your data in a train and set set). For the example in the next cell, we’ll use a simple <em>hold-out</em> scheme, in which we’ll reserve 50% of the data for the test set (note that this could have been a different percentage). (We’ll discuss more intricate cross-validation schemes such as K-fold in the next section).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_train</span> <span class="o">=</span> <span class="n">R_all</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># all even samples</span>
<span class="n">S_train</span> <span class="o">=</span> <span class="n">S_all</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

<span class="n">R_test</span> <span class="o">=</span> <span class="n">R_all</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>  <span class="c1"># all odd samples</span>
<span class="n">S_test</span> <span class="o">=</span> <span class="n">S_all</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>After splitting the data into a train and test set, we have introduced a “problem” however: the features within the train and test set may not have 0 mean and unit (1) variance anymore! Given that the features were properly standardized across <em>all</em> samples in our simulated fMRI dataset, this is unlikely to be a problem for our classifier. It is still good practice to make sure your <em>train set</em> is properly standardized. So, before fitting our classifier, let’s standardize the train set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_train_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">R_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we can fit our model on the standardized train set …</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train_norm</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LogisticRegression()
</pre></div>
</div>
</div>
</div>
<p>Before predicting the test set, however, we need to decide whether we want to independently standardize the test set or whether to <em>cross-validate</em> our previously estimated standardized parameters (the feature-wise mean and standard deviation). Although opinions differ on this topic (see e.g. <a class="reference external" href="https://jamanetwork.com/journals/jamapsychiatry/article-abstract/2756204">this excellent article</a>), if we want a truly unbiased estimate of generalization, we should also cross-validate our standardization procedure in addition to cross-validation of our model. So, to cross-validate our standardization procedure, we do the following for each feature <span class="math notranslate nohighlight">\(j\)</span> of our test set:</p>
<div class="amsmath math notranslate nohighlight" id="equation-2333e5d2-cff7-41fb-b915-b2fdba533086">
<span class="eqno">(97)<a class="headerlink" href="#equation-2333e5d2-cff7-41fb-b915-b2fdba533086" title="Permalink to this equation">¶</a></span>\[\begin{align}
\mathbf{R}_{j, norm}^{\mathrm{test}} = \frac{\mathbf{R}_{j}^{\mathrm{test}} - \bar{\mathbf{R}}_{j}^{\mathrm{train}}}{\hat{\sigma}(\mathbf{R}_{j}^{\mathrm{train}})}
\end{align}\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Note that we&#39;re *not* calling fit on the test set, i.e.,</span>
<span class="c1"># we&#39;re cross-validating our standardization procedure!</span>
<span class="n">R_test_norm</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>So, now we can cross-validate our model and derive predictions for our test set:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">preds</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test_norm</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Predictions for our test set samples:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Predictions for our test set samples:
 [0 1 0 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1
 1 1 1 0 0 1 1 1 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0
 0 0 0 0 0 0]
</pre></div>
</div>
</div>
</div>
<p>These predictions (<code class="docutils literal notranslate"><span class="pre">preds</span></code>) are made independently from the fitting process. Now, let’s evaluate the model performance on these predictions, this time we’re going to be lazy and use the <code class="docutils literal notranslate"><span class="pre">accuracy_score</span></code> from the <code class="docutils literal notranslate"><span class="pre">metrics</span></code> module in scikit-learn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="n">acc_cv</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cross-validated accuracy:&quot;</span><span class="p">,</span> <span class="n">acc_cv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Cross-validated accuracy: 0.675
</pre></div>
</div>
</div>
</div>
<p>As you can see, accuracy is not perfect (1.0) anymore, but it is still much higher than you’d expect on random data (for which chance-level performance would be 0.5).</p>
<p>In hold-out cross-validation (which we demonstrated previously), you use your train set <em>only</em> for fitting and your test set <em>only</em> to evaluate model predictions. In other words, you only fit and predict once, but on different subsets of your data. If you have a big dataset (i.e., many samples), your test set can be relatively large, and thus cross-validated accuracy on the test set will probably be a good estimate of how well our model will generalize to future/other data. However, if you have a relatively small dataset, you will probably have a relatively small test-set. If you then estimate cross-validated accuracy on this test-set, the chance of just getting a relatively good (or bad) score by coincidence is quite high (see e.g. <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S105381191630595X#s0055">Varoquaux et al., 2017</a>)! In other words, the estimate of cross-validation accuracy is not really robust. Fortunately, there are ways to increase robustness of cross-validation accuracy estimates; one of them is by using K-fold cross-validation instead of hold-out cross-validation, in which you divide your dataset into <span class="math notranslate nohighlight">\(K\)</span> folds, which you iteratively use as train and test set.</p>
<div class='alert alert-info'>
<b>ToThink</b> (1 point)<br>
Can you think of a (practical) reason to prefer hold-out cross-validation over K-fold cross-validation?
</div><p>YOUR ANSWER HERE</p>
<p>As fMRI data-sets often contain few samples (trials/subjects), K-fold cross-validation is often used. Instead of writing our own K-fold cross-validation scheme, we’ll use some of scikit-learn’s functionality. Specifically, we are going to use the <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html">StratifiedKFold</a> class from scikit-learn’s <code class="docutils literal notranslate"><span class="pre">model_selection</span></code> module. Click the highlighted link above and read through the manual to see how it works.</p>
<p>Importantly, if you’re dealing with a classification analysis, always use <strong>Stratified</strong>KFold (instead of the regular <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html">KFold</a>), because this version makes sure that each fold contains the same proportion of the different classes (here: 0 and 1).</p>
<p>Anyway, enough talking. Let’s initialize a <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> object with, let’s say, 5 folds:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span>

<span class="c1"># They call folds &#39;splits&#39; in scikit-learn</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alright, we have a <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> object now, but not yet any indices for our folds (i.e. indices to split our <span class="math notranslate nohighlight">\(\mathbf{R}\)</span> and <span class="math notranslate nohighlight">\(S\)</span> into different subsets). To do that, we need to call the <code class="docutils literal notranslate"><span class="pre">split</span></code> method, which takes two inputs: the data (<span class="math notranslate nohighlight">\(\mathbf{R}\)</span>) and the target (<span class="math notranslate nohighlight">\(S\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">folds</span> <span class="o">=</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">R_all</span><span class="p">,</span> <span class="n">S_all</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, we created the variable <code class="docutils literal notranslate"><span class="pre">folds</span></code> which is, technically, a <a class="reference external" href="https://wiki.python.org/moin/Generators">generator</a> object, but just think of it as a type of list (with indices) which is specialized for looping over it. Each entry in <code class="docutils literal notranslate"><span class="pre">folds</span></code> is a tuple with two elements: an array with train indices and an array with test indices. Let’s demonstrate that*:</p>
<hr class="docutils" />
<p>* Note that you can only run the cell below once. After running it, the <code class="docutils literal notranslate"><span class="pre">folds</span></code> generator object is “exhausted”, and you’ll need to call <code class="docutils literal notranslate"><span class="pre">skf.split(R_all,</span> <span class="pre">S_all)</span></code> again in the above cell.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">fold</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">folds</span><span class="p">):</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Processing fold </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
    <span class="c1"># Here, we unpack fold (a tuple) to get the train and test indices</span>
    <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="o">=</span> <span class="n">fold</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Train indices:&quot;</span><span class="p">,</span> <span class="n">train_idx</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test indices:&quot;</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">,</span> <span class="n">end</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Processing fold 1
Train indices: [ 24  26  27  28  36  37  38  39  40  41  42  43  44  45  46  47  48  49
  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67
  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82  83  84  85
  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103
 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
 158 159]
Test indices: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23
 25 29 30 31 32 33 34 35]

Processing fold 2
Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  25  29  30  31  32  33  34  35  62  64  65  66
  67  68  69  70  72  73  74  75  76  77  78  79  80  81  82  83  84  85
  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103
 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
 158 159]
Test indices: [24 26 27 28 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55
 56 57 58 59 60 61 63 71]

Processing fold 3
Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  63  71  93  94  95  99 100 101 102 103
 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121
 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139
 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
 158 159]
Test indices: [62 64 65 66 67 68 69 70 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87
 88 89 90 91 92 96 97 98]

Processing fold 4
Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  96  97  98 126 129 130 131 132 133 134 135 136 137 138 139
 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157
 158 159]
Test indices: [ 93  94  95  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113
 114 115 116 117 118 119 120 121 122 123 124 125 127 128]

Processing fold 5
Train indices: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17
  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35
  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53
  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71
  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89
  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107
 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125
 127 128]
Test indices: [126 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145
 146 147 148 149 150 151 152 153 154 155 156 157 158 159]
</pre></div>
</div>
</div>
</div>
<p>In a proper analysis, you would fit a model on the train set, predict the labels for the test set, and compute the cross-validated accuracy for all <span class="math notranslate nohighlight">\(K\)</span> folds separately. Note that, in the case of K-fold cross-validation, you technically estimating <span class="math notranslate nohighlight">\(K\)</span> different models (i.e., the estimated model parameters are likely slightly different across folds). For most decoding purposes, this is not necessarily a problem, as we’re often not interested in the model <em>parameters</em>, but the (cross-validated) model <em>performance</em>. As such, people usually compute the fold-wise model performance and subsequently average these values to get an average model score — which is exactly what you’re going to do in the next ToDo.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): In the code cell below, initialize a <tt>StratifiedKFold</tt> object with 4 folds and write a for-loop that iterates across the 4 folds. Use the following additional parameters when initializing the <tt>StratifiedKFold</tt> object: <tt>random_state=42</tt> (this is to be able to test your implementation) and <tt>shuffle=True</tt> (which will draw random folds). Store this object in a variable named <tt>skf_4f</tt>.
<p>In every iteration, divide the data into a train and test set, apply (cross-validated) standardization, fit the  model (you can reuse the <tt>LogisticRegression</tt> object from before) on the train set, predict the test set, and compute the accuracy. Store the accuracy for each iteration. After the loop, you should have 4 cross-validated accuracy scores. Average these and store the result (a single number) in a variable named <tt>acc_cv_average</tt>.</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement the ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_skf_loop_with_seed</span>    
<span class="n">test_skf_loop_with_seed</span><span class="p">(</span><span class="n">R_all</span><span class="p">,</span> <span class="n">S_all</span><span class="p">,</span> <span class="n">scaler</span><span class="p">,</span> <span class="n">clf</span><span class="p">,</span> <span class="n">skf_4f</span><span class="p">,</span> <span class="n">acc_cv_average</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-success'>
    <b>Tip</b>: you might wonder how many folds you should choose. It is tempting to choose as many folds as possible, i.e. to make your train set as big as possible, such that your model has as much data as possible to train on. The flip side, however, is that your test set becomes smaller with larger train sets, which tends to lead to highly variable cross-validated model performance estimates (e.g., 0.9 in one fold, but 0.35 in the other fold). It has been recommended to use a test set size of about 10%-20% of the size of your entire dataset (i.e., using 5-10 folds; see <a href="https://www.sciencedirect.com/science/article/pii/S105381191630595X#s0055">this article</a>). 
</div><div class="section" id="sidenote-scikit-learn-pipelines">
<h3>Sidenote: scikit-learn <code class="docutils literal notranslate"><span class="pre">Pipelines</span></code><a class="headerlink" href="#sidenote-scikit-learn-pipelines" title="Permalink to this headline">¶</a></h3>
<p>As you might have noticed in the previous ToDo, it takes quite some lines of code to fully cross-validate your standardization step and model: fit your scaler on the train set, transform the train set, transform the test set, fit your model on the train set, and finally predict your test set. This cross-validation routine will only become more complicated and cumbersome when you add extra preprocessing or transformation procedures to it (as we’ll do in the next section). As such, let us introduce one of the most amazing features of scikit-learn: <code class="docutils literal notranslate"><span class="pre">Pipelines</span></code>.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (0 points): Read through the documentation of the <a href="https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">Pipeline class</a>.
</div><p>Scikit-learn <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>s allow you to “bundle together” a sequence of analysis steps (which may include preprocessing and feature transformation operations) that usually ends in a model (e.g., a <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> object). Then, you can fit all steps on a particular subset of data by calling the <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>’s <code class="docutils literal notranslate"><span class="pre">fit</span></code> method and subsequently call the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method on another subset of data, which will <em>automatically cross-validate every step in your analysis pipeline</em>. Instead of initializing <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code> objects directly, we’ll use the convenience function <code class="docutils literal notranslate"><span class="pre">make_pipeline</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
</pre></div>
</div>
</div>
</div>
<p>Now, the <code class="docutils literal notranslate"><span class="pre">make_pipeline</span></code> function accepts an arbitrary number of arguments which should all be either preprocessing or feature transformation objects (i.e., so-called <a class="reference external" href="https://scikit-learn.org/stable/data_transforms.html">transformator</a> objects) or model objects (i.e., so-called <code class="docutils literal notranslate"><span class="pre">estimator</span></code> objects), such as a <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> object. Note that you can only have a single model object in your pipeline, which should be the <em>last</em> step in your pipeline.</p>
<p>Let’s create a very simple pipeline that involves standardization and a logistic regression model (like you implemented in the previous ToDo):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We re-initialize these objects for clarity</span>
<span class="n">scaler</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>

<span class="c1"># The make_pipeline function returns a Pipeline object</span>
<span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">clf</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">pipe</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pipeline(steps=[(&#39;standardscaler&#39;, StandardScaler()),
                (&#39;logisticregression&#39;, LogisticRegression())])
</pre></div>
</div>
</div>
</div>
<p>Now, let’s use the data from the simple hold-out split from before to demonstrate the fiting and cross-validation of our complete pipeline. Just like a normal model, we can call the <code class="docutils literal notranslate"><span class="pre">fit</span></code> and <code class="docutils literal notranslate"><span class="pre">predict</span></code> methods to do so:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R_train</span> <span class="o">=</span> <span class="n">R_all</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">R_test</span> <span class="o">=</span> <span class="n">R_all</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">S_train</span> <span class="o">=</span> <span class="n">S_all</span><span class="p">[</span><span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>
<span class="n">S_test</span> <span class="o">=</span> <span class="n">S_all</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># First, let&#39;s fit *all* the steps</span>
<span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>

<span class="c1"># And now cross-validate *all* the steps</span>
<span class="n">preds</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Awesome, right? Using pipelines saves you many lines of code and allows you to easily cross-validate entire pipelines. You’ll practice with pipelines in the upcoming ToDo.</p>
<p>Now, back to cross-validation routines. One notable variant of K-fold cross-validation is <em>repeated</em> stratified K-fold cross-validation, in which the cross-validation loop is repeated several times with different (random) folds. This way, the cross-validated model performance estimates usually become more stable (i.e., less variance). (Of course, scikit-learn contains a <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold">RepeatedStratifiedKFold</a> class.)</p>
<p>Another notable cross-validation scheme, especially for fMRI-based decoding analyses, is group-based cross-validation, in which folds are created based on a particular grouping variable. In fMRI-based decoding analyses, this type of cross-validation is often applied to cross-validate models across runs. Specifically, the leave-one-run-out technique is often used, in which a model is fit on all trials except the trials from a single run (the train set) and is cross-validated to the trials of the left-out run (the test set).</p>
<p>This functionality is implemented in the <code class="docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code> class in scikit-learn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneGroupOut</span>
<span class="n">logo</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<p>This cross-validation object is very similar to the other objects (e.g., <code class="docutils literal notranslate"><span class="pre">StratifiedKfold</span></code>) you have seen, except that when calling the <code class="docutils literal notranslate"><span class="pre">split</span></code> method, you need to provide an additional parameter <code class="docutils literal notranslate"><span class="pre">groups</span></code>, which should be an array/list with integers denoting the different groups:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">folds</span> <span class="o">=</span> <span class="n">logo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">target</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
</pre></div>
</div>
<p>For our dataset, we can create a groups-variable based on the different runs as follows:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">groups</span> <span class="o">=</span>  <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">N_per_run</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">M</span><span class="p">)])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">groups</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3
 3 3 3 3 3 3 3 3 3 3 3 3]
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (3 points): In this ToDo, you'll practice with both the Pipeline class as well as leave-on-group-out cross-validation. For this ToDo, you're going to create a new pipeline with a variant of the <tt>StandardScaler</tt> class &mdash; the <tt>RobustScaler</tt> class &mdash; and another model &mdash; the <tt>RidgeClassifier</tt> class (also from the <tt>linear_model</tt> module).
<ol class="simple">
<li><p>Create a new <tt>Pipeline</tt> object with the aforementioned <tt>RobustScaler</tt> and <tt>RidgeClassifier</tt> objects (which you have to import yourself) using the <tt>make_pipeline</tt> function;</p></li>
<li><p>Use the previously defined <tt>logo</tt> object to create a loop across folds, in which you should cross-validate your entire pipeline and compute each fold’s cross-validated accuracy.</p></li>
<li><p>After the loop, average the four accuracy values and store this in a variable named <tt>acc_cv_logo</tt>.</p></li>
</ol>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_logo_loop</span>    
<span class="n">test_logo_loop</span><span class="p">(</span><span class="n">R_all</span><span class="p">,</span> <span class="n">S_all</span><span class="p">,</span> <span class="n">logo</span><span class="p">,</span> <span class="n">groups</span><span class="p">,</span> <span class="n">acc_cv_logo</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): The average performance for the leave-one-run-out cross-validation analysis is, unlike the previous stratified K-fold results (which should be considerably above chance), near chance-level, as you would expect for random noise data. Explain why run-wise cross-validation solves the bias that we observed when ignoring the trial structure across runs. Hint: look at the way we simulated data (which reflects how real data may look like).
</div><p>YOUR ANSWER HERE</p>
</div>
</div>
<div class="section" id="class-imbalance-and-model-performance-revisited">
<h2>Class imbalance and model performance revisited<a class="headerlink" href="#class-imbalance-and-model-performance-revisited" title="Permalink to this headline">¶</a></h2>
<p>Before moving on to more exciting aspects of decoding pipelines, let’s discuss class imbalance. Class imbalance, the situation in which not all classes within your target variable have the same number of samples, can have a big impact on your classification model (note: this is not relevant for regression models, as they don’t have <em>classes</em>!). This is not uncommon in decoding models, especially when you don’t have control over the feature of interest, such as response-based features (e.g., whether the participant pressed left or right) or between-subjects variables (e.g., when dealing with clinical populations, which cannot always be perfectly balanced due to practical reasons).</p>
<p>To illustrate this, let’s look at what happens with random data and a imbalanced target variable. We’ll simulate some random data (like our previously used data, this contains no “signal” at all: you’d expect 50% accuracy) a couple of times and we’ll calculate the cross-validated accuracy.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Simulate random (there is no effect!) data</span>
<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>  <span class="c1"># samples</span>
<span class="n">K</span> <span class="o">=</span> <span class="mi">3</span>  <span class="c1"># brain features</span>
<span class="n">ratio01</span> <span class="o">=</span> <span class="mf">0.8</span>  <span class="c1"># ratio class 0 / class 1</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">)</span>

<span class="n">iters</span> <span class="o">=</span> <span class="mi">10</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
    <span class="n">R_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

    <span class="c1"># Simulate random target with prespecified imbalance (&#39;ratio01&#39;)</span>
    <span class="n">S0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">ratio01</span><span class="p">)))</span>  <span class="c1"># 80% is class 0</span>
    <span class="n">S1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ratio01</span><span class="p">))))</span> <span class="c1"># 20% is class 1</span>
    <span class="n">S_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">S0</span><span class="p">,</span> <span class="n">S1</span><span class="p">))</span>

    <span class="c1"># Now, let&#39;s split it in a train- test-set</span>
    <span class="n">R_train</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">R_test</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">S_train</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">S_test</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
    <span class="n">S_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
    <span class="n">this_acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">S_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">this_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.72
Accuracy: 0.76
Accuracy: 0.80
Accuracy: 0.74
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.74
Accuracy: 0.80
Accuracy: 0.80
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.80
Accuracy: 0.80
Accuracy: 0.80
</pre></div>
</div>
</div>
</div>
<p>When running the cell above, you should find that the models is able to consistently yield strong above-chance performance, which shouldn’t happen because the data that we simulated is just random noise!</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (0 points): Try setting the <tt>ratio01</tt> variable to other numbers (in between 0.1 - 1), for example 0.9, 0.2, or 0.5, and see what happens with the cross-validated accuracy score!
</div><div class='alert alert-info'>
<b>ToThink</b> (1 point): Suppose that you have a dataset with a binary target variable ($S = \{0, 1\}$) a train set in which 80% of the samples are of class 0 and a test set in which 80% of the samples are of class 1. Assuming similar parameters ($N$, $K$, type of classifier, etc.) as used in the previous simulation, what do you think will be the (cross-validated) accuracy on the test set? Why?
</div><p>YOUR ANSWER HERE</p>
<p>As you can see, the model “learns” to just predict the majority class (the class with the most samples)! In a way, class imbalance also provides the classifier with a source of “information” that it can use to derive accurate (but theoretically meaningless) predictions.</p>
<p>Therefore, imbalanced datasets therefore need a different evaluation metric than accuracy. Fortunately, scikit-learn has many more performance metrics you can use, including metrics that “correct” for the (potential) bias due to class imbalance (including <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score">f1-score</a>, <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score">ROC-AUC-score</a>, <a class="reference external" href="http://scikit-learn.org/dev/modules/generated/sklearn.metrics.balanced_accuracy_score.html">balanced-accuracy score</a>, and <a class="reference external" href="http://scikit-learn.org/stable/modules/generated/sklearn.metrics.cohen_kappa_score.html#sklearn.metrics.cohen_kappa_score">Cohen’s Kappa</a>).</p>
<p>Let’s check out what happens with our performance estimate if we use a different (‘class-imbalance-aware’) metric, the “ROC-AUC-score” we discussed previously, which should take care of the bias induced by imbalance.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
    <span class="n">R_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

    <span class="c1"># Simulate random target with prespecified imbalance (&#39;ratio01&#39;)</span>
    <span class="n">S0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">ratio01</span><span class="p">)))</span>  <span class="c1"># 80% is class 0</span>
    <span class="n">S1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ratio01</span><span class="p">))))</span> <span class="c1"># 20% is class 1</span>
    <span class="n">S_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">S0</span><span class="p">,</span> <span class="n">S1</span><span class="p">))</span>

    <span class="c1"># Now, let&#39;s split it in a train- test-set</span>
    <span class="n">R_train</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">R_test</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">S_train</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">S_test</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
    <span class="n">S_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
    <span class="n">this_acc</span> <span class="o">=</span> <span class="n">roc_auc_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">S_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">this_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.50
Accuracy: 0.50
Accuracy: 0.50
Accuracy: 0.47
Accuracy: 0.49
Accuracy: 0.51
Accuracy: 0.50
Accuracy: 0.50
Accuracy: 0.54
Accuracy: 0.50
</pre></div>
</div>
</div>
</div>
<p>Much better! In addition to <code class="docutils literal notranslate"><span class="pre">roc_auc_score</span></code>, there are other metrics (such as <code class="docutils literal notranslate"><span class="pre">balanced_accuracy</span></code> and <code class="docutils literal notranslate"><span class="pre">f1_score</span></code>) that deal appropriately with class imbalance.</p>
<p>However, using class-imbalance-aware metrics only makes sure that the model performance estimate is unbiased (i.e., is not affected by class imbalance), but it doesn’t prevent the model from actually “learning” the useless “information” related to class imbalance (instead of learning the true/useful signal in the data)! In our previous examples which used completely random (null) data, this is not a problem, but it <em>is</em> a problem when the data actually contains some effect. One way to counter this is by using the <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> parameter that is available in mode scikit-learn models. Setting the parameter to “balanced” will weigh samples from the minority class more strongly than samples from the majority class, forcing the model to learn information that is independent from class frequency. Below, we initialize a logistic regression model with this setting enabled and show that it effectively reduces the influence of class imbalance:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
    <span class="n">R_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">K</span><span class="p">))</span>

    <span class="c1"># Simulate random target with prespecified imbalance (&#39;ratio01&#39;)</span>
    <span class="n">S0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="n">ratio01</span><span class="p">)))</span>  <span class="c1"># 80% is class 0</span>
    <span class="n">S1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ratio01</span><span class="p">))))</span> <span class="c1"># 20% is class 1</span>
    <span class="n">S_random</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">((</span><span class="n">S0</span><span class="p">,</span> <span class="n">S1</span><span class="p">))</span>

    <span class="c1"># Now, let&#39;s split it in a train- test-set</span>
    <span class="n">R_train</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">R_test</span> <span class="o">=</span> <span class="n">R_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">S_train</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[::</span><span class="mi">2</span><span class="p">]</span>
    <span class="n">S_test</span> <span class="o">=</span> <span class="n">S_random</span><span class="p">[</span><span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span>

    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
    <span class="n">S_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
    <span class="n">this_acc</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">S_pred</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy: </span><span class="si">%.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">this_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy: 0.64
Accuracy: 0.52
Accuracy: 0.58
Accuracy: 0.60
Accuracy: 0.50
Accuracy: 0.50
Accuracy: 0.48
Accuracy: 0.48
Accuracy: 0.52
Accuracy: 0.52
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Running this will remove all numpy arrays up to this point</span>
<span class="c1"># from memory</span>
<span class="o">%</span><span class="k">reset</span> -f array
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="feature-selection-extraction">
<h2>Feature selection/extraction<a class="headerlink" href="#feature-selection-extraction" title="Permalink to this headline">¶</a></h2>
<p>Now that we’ve dicussed cross-validation, which allows you to report an unbiased estimate of generalization performance. However, especially when your data contains many brain features (e.g., voxels), your model might still perform poorly simply because it has a hard time distinguishing signal from noise. One way to “help” our model a little is to apply feature selection and/or extraction techniques, which are meant to reduce the number of features to a smaller subset which, hopefully, contain more signal (and less noise).</p>
<p>Feature reduction can be achieved in two principled ways:</p>
<ul class="simple">
<li><p>feature extraction: transform your features into a set of lower-dimensional components;</p></li>
<li><p>feature selection: select a subset of features</p></li>
</ul>
<p>Examples of feature extraction are PCA (i.e. transform voxels to orthogonal components) and averaging features within brain regions from an atlas.</p>
<p>Examples of feature selection are ROI-analysis (i.e. restricting your patterns to a specific ROI in the brain) and “univariate feature selection” (UFS). This latter method is an often-used data-driven method to select features based upon their univariate difference, which is basically like using a traditional whole-brain mass-univariate analysis to select potentially useful features!</p>
<div class='alert alert-info'>
<b>ToThink</b> (1 point): Suppose a researcher wants to decode gratings with two different orientations from V1. To delineate V1, the subject underwent a retinotopy session in a <em>different</em> fMRI run. The data from this retinotopy session was subsequently used to extract ("mask") V1 by excluding non-significant voxels; the significant voxels were in turn used to base the orientation decoding analysis on. Is masking V1 using the retinotopy data a form of <em>feature selection</em> or <em>feature extraction</em>? Why? 
</div><p>YOUR ANSWER HERE</p>
<p>Fortunately, scikit-learn has a bunch of feature selection/extraction objects for us to use. These objects (“transformers” in scikit-learn lingo) work similarly to models (“estimators”): they also have a <code class="docutils literal notranslate"><span class="pre">fit(R,</span> <span class="pre">S)</span></code> method, in which for example the univariate differences (in UFS) or PCA-components (in PCA-driven feature extraction) are computed. Then, instead of having a <code class="docutils literal notranslate"><span class="pre">predict(R)</span></code> method, transformers have a <code class="docutils literal notranslate"><span class="pre">transform(R)</span></code> method.</p>
<p>Before going on, let’s actually load in some <em>real</em> data. We’ll use the data from a single “face” run from subject 03. We already estimated the single-trial patterns on Fmriprep-preprocessed data for you using Nilearn (you can check out the code <a class="reference external" href="https://github.com/lukassnoek/NI-edu-data/blob/master/code/nipa/estimate_patterns.py">here</a>). Let’s download these patterns:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">data_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">expanduser</span><span class="p">(</span><span class="s1">&#39;~&#39;</span><span class="p">),</span> <span class="s1">&#39;NI-edu-data&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Downloading patterns from sub-03, ses-1, run 1 (+- ... MB) ...&quot;</span><span class="p">)</span>
<span class="o">!</span>aws s3 sync --no-sign-request s3://openneuro.org/ds003477 <span class="o">{</span>data_dir<span class="o">}</span> --exclude <span class="s2">&quot;*&quot;</span> --include <span class="s2">&quot;derivatives/pattern_estimation/sub-03/ses-1/*task-face*run-1*&quot;</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">Done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Downloading patterns from sub-03, ses-1, run 1 (+- ... MB) ...
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 136.8 KiB/286.0 MiB (993.6 KiB/s) with 8 file(s) remaining
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/figures/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_corr.png to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/figures/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_corr.png
Completed 136.8 KiB/286.0 MiB (993.6 KiB/s) with 7 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 295.7 KiB/286.0 MiB (1.8 MiB/s) with 7 file(s) remaining  
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_matrix.tsv to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_matrix.tsv
Completed 295.7 KiB/286.0 MiB (1.8 MiB/s) with 6 file(s) remaining
Completed 302.9 KiB/286.0 MiB (1.8 MiB/s) with 6 file(s) remaining
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_events.tsv to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_events.tsv
Completed 302.9 KiB/286.0 MiB (1.8 MiB/s) with 5 file(s) remaining
Completed 411.7 KiB/286.0 MiB (2.1 MiB/s) with 5 file(s) remaining
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/figures/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_matrix.png to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/figures/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-design_matrix.png
Completed 411.7 KiB/286.0 MiB (2.1 MiB/s) with 4 file(s) remaining
Completed 667.7 KiB/286.0 MiB (3.4 MiB/s) with 4 file(s) remaining
Completed 923.7 KiB/286.0 MiB (4.5 MiB/s) with 4 file(s) remaining
Completed 1.1 MiB/286.0 MiB (5.6 MiB/s) with 4 file(s) remaining  
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-model_r2.nii.gz to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-model_r2.nii.gz
Completed 1.1 MiB/286.0 MiB (5.6 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 1.4 MiB/286.0 MiB (5.3 MiB/s) with 3 file(s) remaining
Completed 1.6 MiB/286.0 MiB (6.1 MiB/s) with 3 file(s) remaining
Completed 1.9 MiB/286.0 MiB (7.0 MiB/s) with 3 file(s) remaining
Completed 2.1 MiB/286.0 MiB (7.9 MiB/s) with 3 file(s) remaining
Completed 2.4 MiB/286.0 MiB (8.7 MiB/s) with 3 file(s) remaining
Completed 2.6 MiB/286.0 MiB (9.5 MiB/s) with 3 file(s) remaining
Completed 2.9 MiB/286.0 MiB (10.3 MiB/s) with 3 file(s) remaining
Completed 3.1 MiB/286.0 MiB (11.2 MiB/s) with 3 file(s) remaining
Completed 3.4 MiB/286.0 MiB (11.9 MiB/s) with 3 file(s) remaining
Completed 3.6 MiB/286.0 MiB (12.7 MiB/s) with 3 file(s) remaining
Completed 3.9 MiB/286.0 MiB (13.6 MiB/s) with 3 file(s) remaining
Completed 4.1 MiB/286.0 MiB (14.3 MiB/s) with 3 file(s) remaining
Completed 4.4 MiB/286.0 MiB (15.2 MiB/s) with 3 file(s) remaining
Completed 4.6 MiB/286.0 MiB (15.9 MiB/s) with 3 file(s) remaining
Completed 4.9 MiB/286.0 MiB (16.7 MiB/s) with 3 file(s) remaining
Completed 5.1 MiB/286.0 MiB (17.4 MiB/s) with 3 file(s) remaining
Completed 5.4 MiB/286.0 MiB (18.1 MiB/s) with 3 file(s) remaining
Completed 5.6 MiB/286.0 MiB (18.9 MiB/s) with 3 file(s) remaining
Completed 5.9 MiB/286.0 MiB (19.6 MiB/s) with 3 file(s) remaining
Completed 6.1 MiB/286.0 MiB (20.4 MiB/s) with 3 file(s) remaining
Completed 6.4 MiB/286.0 MiB (20.9 MiB/s) with 3 file(s) remaining
Completed 6.6 MiB/286.0 MiB (21.7 MiB/s) with 3 file(s) remaining
Completed 6.9 MiB/286.0 MiB (22.4 MiB/s) with 3 file(s) remaining
Completed 7.1 MiB/286.0 MiB (23.1 MiB/s) with 3 file(s) remaining
Completed 7.4 MiB/286.0 MiB (23.7 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 7.6 MiB/286.0 MiB (24.4 MiB/s) with 3 file(s) remaining
Completed 7.9 MiB/286.0 MiB (24.9 MiB/s) with 3 file(s) remaining
Completed 8.1 MiB/286.0 MiB (25.5 MiB/s) with 3 file(s) remaining
Completed 8.4 MiB/286.0 MiB (26.1 MiB/s) with 3 file(s) remaining
Completed 8.6 MiB/286.0 MiB (26.7 MiB/s) with 3 file(s) remaining
Completed 8.9 MiB/286.0 MiB (27.5 MiB/s) with 3 file(s) remaining
Completed 9.1 MiB/286.0 MiB (28.2 MiB/s) with 3 file(s) remaining
Completed 9.4 MiB/286.0 MiB (28.8 MiB/s) with 3 file(s) remaining
Completed 9.6 MiB/286.0 MiB (29.6 MiB/s) with 3 file(s) remaining
Completed 9.9 MiB/286.0 MiB (30.2 MiB/s) with 3 file(s) remaining
Completed 10.1 MiB/286.0 MiB (30.9 MiB/s) with 3 file(s) remaining
Completed 10.4 MiB/286.0 MiB (31.6 MiB/s) with 3 file(s) remaining
Completed 10.6 MiB/286.0 MiB (32.3 MiB/s) with 3 file(s) remaining
Completed 10.9 MiB/286.0 MiB (32.5 MiB/s) with 3 file(s) remaining
Completed 11.1 MiB/286.0 MiB (32.9 MiB/s) with 3 file(s) remaining
Completed 11.4 MiB/286.0 MiB (33.5 MiB/s) with 3 file(s) remaining
Completed 11.6 MiB/286.0 MiB (33.8 MiB/s) with 3 file(s) remaining
Completed 11.9 MiB/286.0 MiB (34.4 MiB/s) with 3 file(s) remaining
Completed 12.1 MiB/286.0 MiB (35.0 MiB/s) with 3 file(s) remaining
Completed 12.4 MiB/286.0 MiB (35.6 MiB/s) with 3 file(s) remaining
Completed 12.6 MiB/286.0 MiB (36.3 MiB/s) with 3 file(s) remaining
Completed 12.9 MiB/286.0 MiB (36.8 MiB/s) with 3 file(s) remaining
Completed 13.1 MiB/286.0 MiB (37.3 MiB/s) with 3 file(s) remaining
Completed 13.4 MiB/286.0 MiB (37.9 MiB/s) with 3 file(s) remaining
Completed 13.6 MiB/286.0 MiB (38.5 MiB/s) with 3 file(s) remaining
Completed 13.9 MiB/286.0 MiB (39.2 MiB/s) with 3 file(s) remaining
Completed 14.1 MiB/286.0 MiB (39.8 MiB/s) with 3 file(s) remaining
Completed 14.4 MiB/286.0 MiB (40.3 MiB/s) with 3 file(s) remaining
Completed 14.6 MiB/286.0 MiB (40.9 MiB/s) with 3 file(s) remaining
Completed 14.9 MiB/286.0 MiB (41.5 MiB/s) with 3 file(s) remaining
Completed 15.1 MiB/286.0 MiB (42.1 MiB/s) with 3 file(s) remaining
Completed 15.4 MiB/286.0 MiB (42.7 MiB/s) with 3 file(s) remaining
Completed 15.6 MiB/286.0 MiB (43.1 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 15.9 MiB/286.0 MiB (43.7 MiB/s) with 3 file(s) remaining
Completed 16.1 MiB/286.0 MiB (43.8 MiB/s) with 3 file(s) remaining
Completed 16.4 MiB/286.0 MiB (44.4 MiB/s) with 3 file(s) remaining
Completed 16.6 MiB/286.0 MiB (44.9 MiB/s) with 3 file(s) remaining
Completed 16.9 MiB/286.0 MiB (45.4 MiB/s) with 3 file(s) remaining
Completed 17.1 MiB/286.0 MiB (45.7 MiB/s) with 3 file(s) remaining
Completed 17.4 MiB/286.0 MiB (46.3 MiB/s) with 3 file(s) remaining
Completed 17.6 MiB/286.0 MiB (46.8 MiB/s) with 3 file(s) remaining
Completed 17.9 MiB/286.0 MiB (47.4 MiB/s) with 3 file(s) remaining
Completed 18.1 MiB/286.0 MiB (48.0 MiB/s) with 3 file(s) remaining
Completed 18.4 MiB/286.0 MiB (48.5 MiB/s) with 3 file(s) remaining
Completed 18.6 MiB/286.0 MiB (49.0 MiB/s) with 3 file(s) remaining
Completed 18.9 MiB/286.0 MiB (49.5 MiB/s) with 3 file(s) remaining
Completed 19.1 MiB/286.0 MiB (50.0 MiB/s) with 3 file(s) remaining
Completed 19.4 MiB/286.0 MiB (50.6 MiB/s) with 3 file(s) remaining
Completed 19.6 MiB/286.0 MiB (51.0 MiB/s) with 3 file(s) remaining
Completed 19.9 MiB/286.0 MiB (51.5 MiB/s) with 3 file(s) remaining
Completed 20.1 MiB/286.0 MiB (52.1 MiB/s) with 3 file(s) remaining
Completed 20.4 MiB/286.0 MiB (52.6 MiB/s) with 3 file(s) remaining
Completed 20.6 MiB/286.0 MiB (53.2 MiB/s) with 3 file(s) remaining
Completed 20.9 MiB/286.0 MiB (53.6 MiB/s) with 3 file(s) remaining
Completed 21.1 MiB/286.0 MiB (54.1 MiB/s) with 3 file(s) remaining
Completed 21.4 MiB/286.0 MiB (54.5 MiB/s) with 3 file(s) remaining
Completed 21.6 MiB/286.0 MiB (55.1 MiB/s) with 3 file(s) remaining
Completed 21.9 MiB/286.0 MiB (55.6 MiB/s) with 3 file(s) remaining
Completed 22.1 MiB/286.0 MiB (56.1 MiB/s) with 3 file(s) remaining
Completed 22.4 MiB/286.0 MiB (56.6 MiB/s) with 3 file(s) remaining
Completed 22.6 MiB/286.0 MiB (57.0 MiB/s) with 3 file(s) remaining
Completed 22.9 MiB/286.0 MiB (57.5 MiB/s) with 3 file(s) remaining
Completed 23.1 MiB/286.0 MiB (58.0 MiB/s) with 3 file(s) remaining
Completed 23.4 MiB/286.0 MiB (58.5 MiB/s) with 3 file(s) remaining
Completed 23.6 MiB/286.0 MiB (58.9 MiB/s) with 3 file(s) remaining
Completed 23.9 MiB/286.0 MiB (59.2 MiB/s) with 3 file(s) remaining
Completed 24.1 MiB/286.0 MiB (59.7 MiB/s) with 3 file(s) remaining
Completed 24.4 MiB/286.0 MiB (60.3 MiB/s) with 3 file(s) remaining
Completed 24.6 MiB/286.0 MiB (60.8 MiB/s) with 3 file(s) remaining
Completed 24.8 MiB/286.0 MiB (61.1 MiB/s) with 3 file(s) remaining
Completed 25.1 MiB/286.0 MiB (61.3 MiB/s) with 3 file(s) remaining
Completed 25.3 MiB/286.0 MiB (61.8 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 25.6 MiB/286.0 MiB (62.2 MiB/s) with 3 file(s) remaining
Completed 25.8 MiB/286.0 MiB (62.7 MiB/s) with 3 file(s) remaining
Completed 26.1 MiB/286.0 MiB (63.3 MiB/s) with 3 file(s) remaining
Completed 26.3 MiB/286.0 MiB (63.5 MiB/s) with 3 file(s) remaining
Completed 26.6 MiB/286.0 MiB (64.0 MiB/s) with 3 file(s) remaining
Completed 26.8 MiB/286.0 MiB (64.5 MiB/s) with 3 file(s) remaining
Completed 27.1 MiB/286.0 MiB (64.8 MiB/s) with 3 file(s) remaining
Completed 27.3 MiB/286.0 MiB (65.3 MiB/s) with 3 file(s) remaining
Completed 27.6 MiB/286.0 MiB (65.7 MiB/s) with 3 file(s) remaining
Completed 27.8 MiB/286.0 MiB (66.1 MiB/s) with 3 file(s) remaining
Completed 28.1 MiB/286.0 MiB (66.6 MiB/s) with 3 file(s) remaining
Completed 28.3 MiB/286.0 MiB (66.8 MiB/s) with 3 file(s) remaining
Completed 28.6 MiB/286.0 MiB (67.2 MiB/s) with 3 file(s) remaining
Completed 28.8 MiB/286.0 MiB (67.8 MiB/s) with 3 file(s) remaining
Completed 29.1 MiB/286.0 MiB (68.2 MiB/s) with 3 file(s) remaining
Completed 29.3 MiB/286.0 MiB (68.6 MiB/s) with 3 file(s) remaining
Completed 29.6 MiB/286.0 MiB (69.1 MiB/s) with 3 file(s) remaining
Completed 29.8 MiB/286.0 MiB (69.5 MiB/s) with 3 file(s) remaining
Completed 30.1 MiB/286.0 MiB (70.0 MiB/s) with 3 file(s) remaining
Completed 30.3 MiB/286.0 MiB (70.4 MiB/s) with 3 file(s) remaining
Completed 30.6 MiB/286.0 MiB (70.8 MiB/s) with 3 file(s) remaining
Completed 30.8 MiB/286.0 MiB (71.0 MiB/s) with 3 file(s) remaining
Completed 31.1 MiB/286.0 MiB (71.4 MiB/s) with 3 file(s) remaining
Completed 31.3 MiB/286.0 MiB (71.7 MiB/s) with 3 file(s) remaining
Completed 31.6 MiB/286.0 MiB (72.3 MiB/s) with 3 file(s) remaining
Completed 31.6 MiB/286.0 MiB (72.3 MiB/s) with 3 file(s) remaining
Completed 31.9 MiB/286.0 MiB (72.4 MiB/s) with 3 file(s) remaining
Completed 32.1 MiB/286.0 MiB (72.9 MiB/s) with 3 file(s) remaining
Completed 32.4 MiB/286.0 MiB (73.4 MiB/s) with 3 file(s) remaining
Completed 32.6 MiB/286.0 MiB (73.6 MiB/s) with 3 file(s) remaining
Completed 32.9 MiB/286.0 MiB (74.1 MiB/s) with 3 file(s) remaining
Completed 33.1 MiB/286.0 MiB (74.4 MiB/s) with 3 file(s) remaining
Completed 33.4 MiB/286.0 MiB (74.9 MiB/s) with 3 file(s) remaining
Completed 33.6 MiB/286.0 MiB (75.2 MiB/s) with 3 file(s) remaining
Completed 33.9 MiB/286.0 MiB (75.7 MiB/s) with 3 file(s) remaining
Completed 34.1 MiB/286.0 MiB (76.2 MiB/s) with 3 file(s) remaining
Completed 34.4 MiB/286.0 MiB (76.6 MiB/s) with 3 file(s) remaining
Completed 34.6 MiB/286.0 MiB (77.1 MiB/s) with 3 file(s) remaining
Completed 34.9 MiB/286.0 MiB (77.5 MiB/s) with 3 file(s) remaining
Completed 35.1 MiB/286.0 MiB (77.8 MiB/s) with 3 file(s) remaining
Completed 35.4 MiB/286.0 MiB (78.3 MiB/s) with 3 file(s) remaining
Completed 35.6 MiB/286.0 MiB (78.7 MiB/s) with 3 file(s) remaining
Completed 35.9 MiB/286.0 MiB (78.8 MiB/s) with 3 file(s) remaining
Completed 36.1 MiB/286.0 MiB (79.2 MiB/s) with 3 file(s) remaining
Completed 36.4 MiB/286.0 MiB (79.6 MiB/s) with 3 file(s) remaining
Completed 36.6 MiB/286.0 MiB (80.1 MiB/s) with 3 file(s) remaining
Completed 36.9 MiB/286.0 MiB (80.2 MiB/s) with 3 file(s) remaining
Completed 37.1 MiB/286.0 MiB (80.4 MiB/s) with 3 file(s) remaining
Completed 37.4 MiB/286.0 MiB (80.7 MiB/s) with 3 file(s) remaining
Completed 37.6 MiB/286.0 MiB (81.2 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 37.9 MiB/286.0 MiB (81.5 MiB/s) with 3 file(s) remaining
Completed 38.1 MiB/286.0 MiB (81.7 MiB/s) with 3 file(s) remaining
Completed 38.4 MiB/286.0 MiB (81.4 MiB/s) with 3 file(s) remaining
Completed 38.6 MiB/286.0 MiB (81.8 MiB/s) with 3 file(s) remaining
Completed 38.9 MiB/286.0 MiB (81.7 MiB/s) with 3 file(s) remaining
Completed 39.1 MiB/286.0 MiB (82.1 MiB/s) with 3 file(s) remaining
Completed 39.4 MiB/286.0 MiB (82.4 MiB/s) with 3 file(s) remaining
Completed 39.6 MiB/286.0 MiB (82.7 MiB/s) with 3 file(s) remaining
Completed 39.9 MiB/286.0 MiB (83.2 MiB/s) with 3 file(s) remaining
Completed 40.1 MiB/286.0 MiB (83.6 MiB/s) with 3 file(s) remaining
Completed 40.4 MiB/286.0 MiB (83.9 MiB/s) with 3 file(s) remaining
Completed 40.6 MiB/286.0 MiB (84.3 MiB/s) with 3 file(s) remaining
Completed 40.9 MiB/286.0 MiB (84.4 MiB/s) with 3 file(s) remaining
Completed 41.1 MiB/286.0 MiB (84.8 MiB/s) with 3 file(s) remaining
Completed 41.4 MiB/286.0 MiB (85.2 MiB/s) with 3 file(s) remaining
Completed 41.6 MiB/286.0 MiB (85.4 MiB/s) with 3 file(s) remaining
Completed 41.9 MiB/286.0 MiB (85.9 MiB/s) with 3 file(s) remaining
Completed 42.1 MiB/286.0 MiB (86.3 MiB/s) with 3 file(s) remaining
Completed 42.4 MiB/286.0 MiB (86.6 MiB/s) with 3 file(s) remaining
Completed 42.6 MiB/286.0 MiB (86.9 MiB/s) with 3 file(s) remaining
Completed 42.9 MiB/286.0 MiB (87.3 MiB/s) with 3 file(s) remaining
Completed 43.1 MiB/286.0 MiB (87.6 MiB/s) with 3 file(s) remaining
Completed 43.4 MiB/286.0 MiB (87.8 MiB/s) with 3 file(s) remaining
Completed 43.6 MiB/286.0 MiB (88.1 MiB/s) with 3 file(s) remaining
Completed 43.9 MiB/286.0 MiB (88.5 MiB/s) with 3 file(s) remaining
Completed 44.1 MiB/286.0 MiB (88.7 MiB/s) with 3 file(s) remaining
Completed 44.4 MiB/286.0 MiB (89.1 MiB/s) with 3 file(s) remaining
Completed 44.6 MiB/286.0 MiB (89.4 MiB/s) with 3 file(s) remaining
Completed 44.9 MiB/286.0 MiB (89.8 MiB/s) with 3 file(s) remaining
Completed 45.1 MiB/286.0 MiB (90.2 MiB/s) with 3 file(s) remaining
Completed 45.4 MiB/286.0 MiB (90.5 MiB/s) with 3 file(s) remaining
Completed 45.6 MiB/286.0 MiB (90.8 MiB/s) with 3 file(s) remaining
Completed 45.9 MiB/286.0 MiB (91.2 MiB/s) with 3 file(s) remaining
Completed 46.1 MiB/286.0 MiB (91.4 MiB/s) with 3 file(s) remaining
Completed 46.4 MiB/286.0 MiB (91.7 MiB/s) with 3 file(s) remaining
Completed 46.6 MiB/286.0 MiB (92.0 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 46.9 MiB/286.0 MiB (92.3 MiB/s) with 3 file(s) remaining
Completed 47.1 MiB/286.0 MiB (92.7 MiB/s) with 3 file(s) remaining
Completed 47.4 MiB/286.0 MiB (89.7 MiB/s) with 3 file(s) remaining
Completed 47.6 MiB/286.0 MiB (90.1 MiB/s) with 3 file(s) remaining
Completed 47.9 MiB/286.0 MiB (90.5 MiB/s) with 3 file(s) remaining
Completed 48.1 MiB/286.0 MiB (90.9 MiB/s) with 3 file(s) remaining
Completed 48.4 MiB/286.0 MiB (91.1 MiB/s) with 3 file(s) remaining
Completed 48.6 MiB/286.0 MiB (91.5 MiB/s) with 3 file(s) remaining
Completed 48.9 MiB/286.0 MiB (91.9 MiB/s) with 3 file(s) remaining
Completed 49.1 MiB/286.0 MiB (92.3 MiB/s) with 3 file(s) remaining
Completed 49.4 MiB/286.0 MiB (92.4 MiB/s) with 3 file(s) remaining
Completed 49.6 MiB/286.0 MiB (92.7 MiB/s) with 3 file(s) remaining
Completed 49.9 MiB/286.0 MiB (93.1 MiB/s) with 3 file(s) remaining
Completed 50.1 MiB/286.0 MiB (93.5 MiB/s) with 3 file(s) remaining
Completed 50.4 MiB/286.0 MiB (93.8 MiB/s) with 3 file(s) remaining
Completed 50.6 MiB/286.0 MiB (94.2 MiB/s) with 3 file(s) remaining
Completed 50.9 MiB/286.0 MiB (94.4 MiB/s) with 3 file(s) remaining
Completed 51.1 MiB/286.0 MiB (94.8 MiB/s) with 3 file(s) remaining
Completed 51.4 MiB/286.0 MiB (95.2 MiB/s) with 3 file(s) remaining
Completed 51.6 MiB/286.0 MiB (95.5 MiB/s) with 3 file(s) remaining
Completed 51.9 MiB/286.0 MiB (95.8 MiB/s) with 3 file(s) remaining
Completed 52.1 MiB/286.0 MiB (96.1 MiB/s) with 3 file(s) remaining
Completed 52.4 MiB/286.0 MiB (96.4 MiB/s) with 3 file(s) remaining
Completed 52.6 MiB/286.0 MiB (96.7 MiB/s) with 3 file(s) remaining
Completed 52.9 MiB/286.0 MiB (97.1 MiB/s) with 3 file(s) remaining
Completed 53.1 MiB/286.0 MiB (97.0 MiB/s) with 3 file(s) remaining
Completed 53.4 MiB/286.0 MiB (97.4 MiB/s) with 3 file(s) remaining
Completed 53.6 MiB/286.0 MiB (97.7 MiB/s) with 3 file(s) remaining
Completed 53.9 MiB/286.0 MiB (97.8 MiB/s) with 3 file(s) remaining
Completed 54.1 MiB/286.0 MiB (98.1 MiB/s) with 3 file(s) remaining
Completed 54.4 MiB/286.0 MiB (98.6 MiB/s) with 3 file(s) remaining
Completed 54.6 MiB/286.0 MiB (98.9 MiB/s) with 3 file(s) remaining
Completed 54.9 MiB/286.0 MiB (99.3 MiB/s) with 3 file(s) remaining
Completed 55.1 MiB/286.0 MiB (99.7 MiB/s) with 3 file(s) remaining
Completed 55.4 MiB/286.0 MiB (99.7 MiB/s) with 3 file(s) remaining
Completed 55.6 MiB/286.0 MiB (100.0 MiB/s) with 3 file(s) remaining
Completed 55.9 MiB/286.0 MiB (100.3 MiB/s) with 3 file(s) remaining
Completed 56.1 MiB/286.0 MiB (100.7 MiB/s) with 3 file(s) remaining
Completed 56.4 MiB/286.0 MiB (100.9 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 56.6 MiB/286.0 MiB (101.3 MiB/s) with 3 file(s) remaining
Completed 56.9 MiB/286.0 MiB (101.6 MiB/s) with 3 file(s) remaining
Completed 57.1 MiB/286.0 MiB (101.9 MiB/s) with 3 file(s) remaining
Completed 57.4 MiB/286.0 MiB (102.2 MiB/s) with 3 file(s) remaining
Completed 57.6 MiB/286.0 MiB (102.5 MiB/s) with 3 file(s) remaining
Completed 57.9 MiB/286.0 MiB (102.9 MiB/s) with 3 file(s) remaining
Completed 58.1 MiB/286.0 MiB (103.3 MiB/s) with 3 file(s) remaining
Completed 58.4 MiB/286.0 MiB (103.6 MiB/s) with 3 file(s) remaining
Completed 58.6 MiB/286.0 MiB (103.9 MiB/s) with 3 file(s) remaining
Completed 58.9 MiB/286.0 MiB (104.2 MiB/s) with 3 file(s) remaining
Completed 59.1 MiB/286.0 MiB (104.5 MiB/s) with 3 file(s) remaining
Completed 59.4 MiB/286.0 MiB (104.8 MiB/s) with 3 file(s) remaining
Completed 59.6 MiB/286.0 MiB (105.1 MiB/s) with 3 file(s) remaining
Completed 59.9 MiB/286.0 MiB (105.5 MiB/s) with 3 file(s) remaining
Completed 60.1 MiB/286.0 MiB (105.8 MiB/s) with 3 file(s) remaining
Completed 60.4 MiB/286.0 MiB (105.9 MiB/s) with 3 file(s) remaining
Completed 60.6 MiB/286.0 MiB (106.2 MiB/s) with 3 file(s) remaining
Completed 60.9 MiB/286.0 MiB (106.5 MiB/s) with 3 file(s) remaining
Completed 61.1 MiB/286.0 MiB (106.9 MiB/s) with 3 file(s) remaining
Completed 61.4 MiB/286.0 MiB (107.1 MiB/s) with 3 file(s) remaining
Completed 61.6 MiB/286.0 MiB (107.1 MiB/s) with 3 file(s) remaining
Completed 61.9 MiB/286.0 MiB (107.5 MiB/s) with 3 file(s) remaining
Completed 62.1 MiB/286.0 MiB (107.8 MiB/s) with 3 file(s) remaining
Completed 62.4 MiB/286.0 MiB (107.9 MiB/s) with 3 file(s) remaining
Completed 62.6 MiB/286.0 MiB (108.3 MiB/s) with 3 file(s) remaining
Completed 62.9 MiB/286.0 MiB (108.6 MiB/s) with 3 file(s) remaining
Completed 63.1 MiB/286.0 MiB (108.9 MiB/s) with 3 file(s) remaining
Completed 63.4 MiB/286.0 MiB (109.2 MiB/s) with 3 file(s) remaining
Completed 63.6 MiB/286.0 MiB (109.4 MiB/s) with 3 file(s) remaining
Completed 63.9 MiB/286.0 MiB (109.8 MiB/s) with 3 file(s) remaining
Completed 64.1 MiB/286.0 MiB (110.1 MiB/s) with 3 file(s) remaining
Completed 64.4 MiB/286.0 MiB (110.1 MiB/s) with 3 file(s) remaining
Completed 64.6 MiB/286.0 MiB (110.4 MiB/s) with 3 file(s) remaining
Completed 64.9 MiB/286.0 MiB (110.8 MiB/s) with 3 file(s) remaining
Completed 65.1 MiB/286.0 MiB (111.1 MiB/s) with 3 file(s) remaining
Completed 65.4 MiB/286.0 MiB (111.4 MiB/s) with 3 file(s) remaining
Completed 65.6 MiB/286.0 MiB (111.6 MiB/s) with 3 file(s) remaining
Completed 65.9 MiB/286.0 MiB (111.8 MiB/s) with 3 file(s) remaining
Completed 66.1 MiB/286.0 MiB (112.2 MiB/s) with 3 file(s) remaining
Completed 66.4 MiB/286.0 MiB (112.5 MiB/s) with 3 file(s) remaining
Completed 66.6 MiB/286.0 MiB (112.5 MiB/s) with 3 file(s) remaining
Completed 66.9 MiB/286.0 MiB (112.8 MiB/s) with 3 file(s) remaining
Completed 67.1 MiB/286.0 MiB (113.2 MiB/s) with 3 file(s) remaining
Completed 67.4 MiB/286.0 MiB (113.3 MiB/s) with 3 file(s) remaining
Completed 67.6 MiB/286.0 MiB (113.7 MiB/s) with 3 file(s) remaining
Completed 67.9 MiB/286.0 MiB (113.9 MiB/s) with 3 file(s) remaining
Completed 68.1 MiB/286.0 MiB (114.2 MiB/s) with 3 file(s) remaining
Completed 68.4 MiB/286.0 MiB (114.5 MiB/s) with 3 file(s) remaining
Completed 68.6 MiB/286.0 MiB (114.6 MiB/s) with 3 file(s) remaining
Completed 68.9 MiB/286.0 MiB (114.9 MiB/s) with 3 file(s) remaining
Completed 69.1 MiB/286.0 MiB (115.2 MiB/s) with 3 file(s) remaining
Completed 69.4 MiB/286.0 MiB (115.5 MiB/s) with 3 file(s) remaining
Completed 69.6 MiB/286.0 MiB (115.6 MiB/s) with 3 file(s) remaining
Completed 69.9 MiB/286.0 MiB (115.6 MiB/s) with 3 file(s) remaining
Completed 70.1 MiB/286.0 MiB (116.0 MiB/s) with 3 file(s) remaining
Completed 70.4 MiB/286.0 MiB (116.3 MiB/s) with 3 file(s) remaining
Completed 70.6 MiB/286.0 MiB (116.4 MiB/s) with 3 file(s) remaining
Completed 70.9 MiB/286.0 MiB (116.6 MiB/s) with 3 file(s) remaining
Completed 71.1 MiB/286.0 MiB (117.0 MiB/s) with 3 file(s) remaining
Completed 71.4 MiB/286.0 MiB (116.9 MiB/s) with 3 file(s) remaining
Completed 71.6 MiB/286.0 MiB (117.2 MiB/s) with 3 file(s) remaining
Completed 71.9 MiB/286.0 MiB (117.4 MiB/s) with 3 file(s) remaining
Completed 72.1 MiB/286.0 MiB (117.6 MiB/s) with 3 file(s) remaining
Completed 72.4 MiB/286.0 MiB (117.9 MiB/s) with 3 file(s) remaining
Completed 72.6 MiB/286.0 MiB (118.3 MiB/s) with 3 file(s) remaining
Completed 72.9 MiB/286.0 MiB (118.2 MiB/s) with 3 file(s) remaining
Completed 73.1 MiB/286.0 MiB (118.4 MiB/s) with 3 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 73.4 MiB/286.0 MiB (118.2 MiB/s) with 3 file(s) remaining
Completed 73.6 MiB/286.0 MiB (118.6 MiB/s) with 3 file(s) remaining
Completed 73.9 MiB/286.0 MiB (118.9 MiB/s) with 3 file(s) remaining
Completed 74.1 MiB/286.0 MiB (119.0 MiB/s) with 3 file(s) remaining
Completed 74.4 MiB/286.0 MiB (119.3 MiB/s) with 3 file(s) remaining
Completed 74.6 MiB/286.0 MiB (119.6 MiB/s) with 3 file(s) remaining
Completed 74.9 MiB/286.0 MiB (119.9 MiB/s) with 3 file(s) remaining
Completed 75.1 MiB/286.0 MiB (120.1 MiB/s) with 3 file(s) remaining
Completed 75.4 MiB/286.0 MiB (120.0 MiB/s) with 3 file(s) remaining
Completed 75.6 MiB/286.0 MiB (120.2 MiB/s) with 3 file(s) remaining
Completed 75.9 MiB/286.0 MiB (120.5 MiB/s) with 3 file(s) remaining
Completed 76.1 MiB/286.0 MiB (120.7 MiB/s) with 3 file(s) remaining
Completed 76.4 MiB/286.0 MiB (120.8 MiB/s) with 3 file(s) remaining
Completed 76.6 MiB/286.0 MiB (121.0 MiB/s) with 3 file(s) remaining
Completed 76.9 MiB/286.0 MiB (121.1 MiB/s) with 3 file(s) remaining
Completed 77.1 MiB/286.0 MiB (121.4 MiB/s) with 3 file(s) remaining
Completed 77.4 MiB/286.0 MiB (121.5 MiB/s) with 3 file(s) remaining
Completed 77.6 MiB/286.0 MiB (121.7 MiB/s) with 3 file(s) remaining
Completed 77.9 MiB/286.0 MiB (121.9 MiB/s) with 3 file(s) remaining
Completed 78.1 MiB/286.0 MiB (121.2 MiB/s) with 3 file(s) remaining
Completed 78.4 MiB/286.0 MiB (121.4 MiB/s) with 3 file(s) remaining
Completed 78.6 MiB/286.0 MiB (121.6 MiB/s) with 3 file(s) remaining
Completed 78.9 MiB/286.0 MiB (121.8 MiB/s) with 3 file(s) remaining
Completed 79.1 MiB/286.0 MiB (122.0 MiB/s) with 3 file(s) remaining
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_varbeta.nii.gz to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_varbeta.nii.gz
Completed 79.1 MiB/286.0 MiB (122.0 MiB/s) with 2 file(s) remaining
download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/patterns/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz
Completed 79.1 MiB/286.0 MiB (122.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 79.4 MiB/286.0 MiB (117.5 MiB/s) with 1 file(s) remaining
Completed 79.6 MiB/286.0 MiB (117.5 MiB/s) with 1 file(s) remaining
Completed 79.9 MiB/286.0 MiB (117.5 MiB/s) with 1 file(s) remaining
Completed 80.1 MiB/286.0 MiB (117.6 MiB/s) with 1 file(s) remaining
Completed 80.4 MiB/286.0 MiB (117.8 MiB/s) with 1 file(s) remaining
Completed 80.6 MiB/286.0 MiB (118.0 MiB/s) with 1 file(s) remaining
Completed 80.9 MiB/286.0 MiB (118.1 MiB/s) with 1 file(s) remaining
Completed 81.1 MiB/286.0 MiB (118.1 MiB/s) with 1 file(s) remaining
Completed 81.4 MiB/286.0 MiB (118.3 MiB/s) with 1 file(s) remaining
Completed 81.6 MiB/286.0 MiB (118.4 MiB/s) with 1 file(s) remaining
Completed 81.9 MiB/286.0 MiB (118.5 MiB/s) with 1 file(s) remaining
Completed 82.1 MiB/286.0 MiB (118.6 MiB/s) with 1 file(s) remaining
Completed 82.4 MiB/286.0 MiB (118.5 MiB/s) with 1 file(s) remaining
Completed 82.6 MiB/286.0 MiB (118.5 MiB/s) with 1 file(s) remaining
Completed 82.9 MiB/286.0 MiB (118.6 MiB/s) with 1 file(s) remaining
Completed 83.1 MiB/286.0 MiB (118.8 MiB/s) with 1 file(s) remaining
Completed 83.4 MiB/286.0 MiB (118.8 MiB/s) with 1 file(s) remaining
Completed 83.6 MiB/286.0 MiB (118.9 MiB/s) with 1 file(s) remaining
Completed 83.9 MiB/286.0 MiB (118.6 MiB/s) with 1 file(s) remaining
Completed 84.1 MiB/286.0 MiB (118.7 MiB/s) with 1 file(s) remaining
Completed 84.4 MiB/286.0 MiB (118.8 MiB/s) with 1 file(s) remaining
Completed 84.6 MiB/286.0 MiB (118.3 MiB/s) with 1 file(s) remaining
Completed 84.9 MiB/286.0 MiB (118.4 MiB/s) with 1 file(s) remaining
Completed 85.1 MiB/286.0 MiB (117.8 MiB/s) with 1 file(s) remaining
Completed 85.4 MiB/286.0 MiB (118.1 MiB/s) with 1 file(s) remaining
Completed 85.6 MiB/286.0 MiB (118.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 85.9 MiB/286.0 MiB (117.9 MiB/s) with 1 file(s) remaining
Completed 86.1 MiB/286.0 MiB (117.8 MiB/s) with 1 file(s) remaining
Completed 86.4 MiB/286.0 MiB (118.1 MiB/s) with 1 file(s) remaining
Completed 86.6 MiB/286.0 MiB (117.9 MiB/s) with 1 file(s) remaining
Completed 86.9 MiB/286.0 MiB (117.7 MiB/s) with 1 file(s) remaining
Completed 87.1 MiB/286.0 MiB (117.9 MiB/s) with 1 file(s) remaining
Completed 87.4 MiB/286.0 MiB (118.1 MiB/s) with 1 file(s) remaining
Completed 87.6 MiB/286.0 MiB (118.2 MiB/s) with 1 file(s) remaining
Completed 87.9 MiB/286.0 MiB (118.2 MiB/s) with 1 file(s) remaining
Completed 88.1 MiB/286.0 MiB (118.3 MiB/s) with 1 file(s) remaining
Completed 88.4 MiB/286.0 MiB (118.5 MiB/s) with 1 file(s) remaining
Completed 88.6 MiB/286.0 MiB (118.5 MiB/s) with 1 file(s) remaining
Completed 88.9 MiB/286.0 MiB (118.6 MiB/s) with 1 file(s) remaining
Completed 89.1 MiB/286.0 MiB (118.8 MiB/s) with 1 file(s) remaining
Completed 89.4 MiB/286.0 MiB (119.1 MiB/s) with 1 file(s) remaining
Completed 89.6 MiB/286.0 MiB (119.1 MiB/s) with 1 file(s) remaining
Completed 89.9 MiB/286.0 MiB (119.4 MiB/s) with 1 file(s) remaining
Completed 90.1 MiB/286.0 MiB (119.4 MiB/s) with 1 file(s) remaining
Completed 90.4 MiB/286.0 MiB (119.6 MiB/s) with 1 file(s) remaining
Completed 90.6 MiB/286.0 MiB (119.7 MiB/s) with 1 file(s) remaining
Completed 90.9 MiB/286.0 MiB (119.8 MiB/s) with 1 file(s) remaining
Completed 91.1 MiB/286.0 MiB (120.0 MiB/s) with 1 file(s) remaining
Completed 91.4 MiB/286.0 MiB (120.2 MiB/s) with 1 file(s) remaining
Completed 91.6 MiB/286.0 MiB (120.3 MiB/s) with 1 file(s) remaining
Completed 91.9 MiB/286.0 MiB (120.4 MiB/s) with 1 file(s) remaining
Completed 92.1 MiB/286.0 MiB (120.4 MiB/s) with 1 file(s) remaining
Completed 92.4 MiB/286.0 MiB (120.7 MiB/s) with 1 file(s) remaining
Completed 92.6 MiB/286.0 MiB (120.8 MiB/s) with 1 file(s) remaining
Completed 92.9 MiB/286.0 MiB (120.9 MiB/s) with 1 file(s) remaining
Completed 93.1 MiB/286.0 MiB (121.1 MiB/s) with 1 file(s) remaining
Completed 93.4 MiB/286.0 MiB (121.2 MiB/s) with 1 file(s) remaining
Completed 93.6 MiB/286.0 MiB (121.4 MiB/s) with 1 file(s) remaining
Completed 93.9 MiB/286.0 MiB (121.7 MiB/s) with 1 file(s) remaining
Completed 94.1 MiB/286.0 MiB (121.7 MiB/s) with 1 file(s) remaining
Completed 94.4 MiB/286.0 MiB (121.9 MiB/s) with 1 file(s) remaining
Completed 94.6 MiB/286.0 MiB (122.2 MiB/s) with 1 file(s) remaining
Completed 94.9 MiB/286.0 MiB (122.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 95.1 MiB/286.0 MiB (122.2 MiB/s) with 1 file(s) remaining
Completed 95.4 MiB/286.0 MiB (122.1 MiB/s) with 1 file(s) remaining
Completed 95.6 MiB/286.0 MiB (122.1 MiB/s) with 1 file(s) remaining
Completed 95.9 MiB/286.0 MiB (122.4 MiB/s) with 1 file(s) remaining
Completed 96.1 MiB/286.0 MiB (122.7 MiB/s) with 1 file(s) remaining
Completed 96.4 MiB/286.0 MiB (122.4 MiB/s) with 1 file(s) remaining
Completed 96.6 MiB/286.0 MiB (122.6 MiB/s) with 1 file(s) remaining
Completed 96.9 MiB/286.0 MiB (122.8 MiB/s) with 1 file(s) remaining
Completed 97.1 MiB/286.0 MiB (123.1 MiB/s) with 1 file(s) remaining
Completed 97.4 MiB/286.0 MiB (123.2 MiB/s) with 1 file(s) remaining
Completed 97.6 MiB/286.0 MiB (123.4 MiB/s) with 1 file(s) remaining
Completed 97.9 MiB/286.0 MiB (123.7 MiB/s) with 1 file(s) remaining
Completed 98.1 MiB/286.0 MiB (123.6 MiB/s) with 1 file(s) remaining
Completed 98.4 MiB/286.0 MiB (123.8 MiB/s) with 1 file(s) remaining
Completed 98.6 MiB/286.0 MiB (124.0 MiB/s) with 1 file(s) remaining
Completed 98.9 MiB/286.0 MiB (124.2 MiB/s) with 1 file(s) remaining
Completed 99.1 MiB/286.0 MiB (124.3 MiB/s) with 1 file(s) remaining
Completed 99.4 MiB/286.0 MiB (124.6 MiB/s) with 1 file(s) remaining
Completed 99.6 MiB/286.0 MiB (124.8 MiB/s) with 1 file(s) remaining
Completed 99.9 MiB/286.0 MiB (124.8 MiB/s) with 1 file(s) remaining
Completed 100.1 MiB/286.0 MiB (124.8 MiB/s) with 1 file(s) remaining
Completed 100.4 MiB/286.0 MiB (125.0 MiB/s) with 1 file(s) remaining
Completed 100.6 MiB/286.0 MiB (125.2 MiB/s) with 1 file(s) remaining
Completed 100.9 MiB/286.0 MiB (125.4 MiB/s) with 1 file(s) remaining
Completed 101.1 MiB/286.0 MiB (125.6 MiB/s) with 1 file(s) remaining
Completed 101.4 MiB/286.0 MiB (125.8 MiB/s) with 1 file(s) remaining
Completed 101.6 MiB/286.0 MiB (125.9 MiB/s) with 1 file(s) remaining
Completed 101.9 MiB/286.0 MiB (125.8 MiB/s) with 1 file(s) remaining
Completed 102.1 MiB/286.0 MiB (125.8 MiB/s) with 1 file(s) remaining
Completed 102.4 MiB/286.0 MiB (126.0 MiB/s) with 1 file(s) remaining
Completed 102.6 MiB/286.0 MiB (126.3 MiB/s) with 1 file(s) remaining
Completed 102.9 MiB/286.0 MiB (126.5 MiB/s) with 1 file(s) remaining
Completed 103.1 MiB/286.0 MiB (126.5 MiB/s) with 1 file(s) remaining
Completed 103.4 MiB/286.0 MiB (126.5 MiB/s) with 1 file(s) remaining
Completed 103.6 MiB/286.0 MiB (126.7 MiB/s) with 1 file(s) remaining
Completed 103.9 MiB/286.0 MiB (126.9 MiB/s) with 1 file(s) remaining
Completed 104.1 MiB/286.0 MiB (127.1 MiB/s) with 1 file(s) remaining
Completed 104.4 MiB/286.0 MiB (127.3 MiB/s) with 1 file(s) remaining
Completed 104.6 MiB/286.0 MiB (127.5 MiB/s) with 1 file(s) remaining
Completed 104.9 MiB/286.0 MiB (127.8 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 105.1 MiB/286.0 MiB (127.9 MiB/s) with 1 file(s) remaining
Completed 105.4 MiB/286.0 MiB (128.1 MiB/s) with 1 file(s) remaining
Completed 105.6 MiB/286.0 MiB (128.3 MiB/s) with 1 file(s) remaining
Completed 105.9 MiB/286.0 MiB (128.5 MiB/s) with 1 file(s) remaining
Completed 106.1 MiB/286.0 MiB (128.6 MiB/s) with 1 file(s) remaining
Completed 106.4 MiB/286.0 MiB (128.9 MiB/s) with 1 file(s) remaining
Completed 106.6 MiB/286.0 MiB (129.0 MiB/s) with 1 file(s) remaining
Completed 106.9 MiB/286.0 MiB (129.2 MiB/s) with 1 file(s) remaining
Completed 107.1 MiB/286.0 MiB (129.5 MiB/s) with 1 file(s) remaining
Completed 107.4 MiB/286.0 MiB (129.4 MiB/s) with 1 file(s) remaining
Completed 107.6 MiB/286.0 MiB (129.5 MiB/s) with 1 file(s) remaining
Completed 107.9 MiB/286.0 MiB (129.6 MiB/s) with 1 file(s) remaining
Completed 108.1 MiB/286.0 MiB (129.8 MiB/s) with 1 file(s) remaining
Completed 108.4 MiB/286.0 MiB (130.0 MiB/s) with 1 file(s) remaining
Completed 108.6 MiB/286.0 MiB (130.2 MiB/s) with 1 file(s) remaining
Completed 108.9 MiB/286.0 MiB (130.3 MiB/s) with 1 file(s) remaining
Completed 109.1 MiB/286.0 MiB (130.3 MiB/s) with 1 file(s) remaining
Completed 109.4 MiB/286.0 MiB (130.5 MiB/s) with 1 file(s) remaining
Completed 109.6 MiB/286.0 MiB (130.8 MiB/s) with 1 file(s) remaining
Completed 109.9 MiB/286.0 MiB (131.0 MiB/s) with 1 file(s) remaining
Completed 110.1 MiB/286.0 MiB (131.1 MiB/s) with 1 file(s) remaining
Completed 110.4 MiB/286.0 MiB (131.3 MiB/s) with 1 file(s) remaining
Completed 110.6 MiB/286.0 MiB (131.4 MiB/s) with 1 file(s) remaining
Completed 110.9 MiB/286.0 MiB (131.4 MiB/s) with 1 file(s) remaining
Completed 111.1 MiB/286.0 MiB (131.6 MiB/s) with 1 file(s) remaining
Completed 111.4 MiB/286.0 MiB (131.8 MiB/s) with 1 file(s) remaining
Completed 111.6 MiB/286.0 MiB (132.0 MiB/s) with 1 file(s) remaining
Completed 111.9 MiB/286.0 MiB (132.0 MiB/s) with 1 file(s) remaining
Completed 112.1 MiB/286.0 MiB (132.1 MiB/s) with 1 file(s) remaining
Completed 112.4 MiB/286.0 MiB (132.3 MiB/s) with 1 file(s) remaining
Completed 112.6 MiB/286.0 MiB (132.5 MiB/s) with 1 file(s) remaining
Completed 112.9 MiB/286.0 MiB (132.7 MiB/s) with 1 file(s) remaining
Completed 113.1 MiB/286.0 MiB (132.8 MiB/s) with 1 file(s) remaining
Completed 113.4 MiB/286.0 MiB (132.8 MiB/s) with 1 file(s) remaining
Completed 113.6 MiB/286.0 MiB (133.0 MiB/s) with 1 file(s) remaining
Completed 113.9 MiB/286.0 MiB (133.2 MiB/s) with 1 file(s) remaining
Completed 114.1 MiB/286.0 MiB (133.4 MiB/s) with 1 file(s) remaining
Completed 114.4 MiB/286.0 MiB (133.5 MiB/s) with 1 file(s) remaining
Completed 114.6 MiB/286.0 MiB (133.7 MiB/s) with 1 file(s) remaining
Completed 114.9 MiB/286.0 MiB (133.5 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 115.1 MiB/286.0 MiB (133.7 MiB/s) with 1 file(s) remaining
Completed 115.4 MiB/286.0 MiB (133.7 MiB/s) with 1 file(s) remaining
Completed 115.6 MiB/286.0 MiB (133.7 MiB/s) with 1 file(s) remaining
Completed 115.9 MiB/286.0 MiB (133.7 MiB/s) with 1 file(s) remaining
Completed 116.1 MiB/286.0 MiB (133.9 MiB/s) with 1 file(s) remaining
Completed 116.4 MiB/286.0 MiB (134.1 MiB/s) with 1 file(s) remaining
Completed 116.6 MiB/286.0 MiB (134.3 MiB/s) with 1 file(s) remaining
Completed 116.9 MiB/286.0 MiB (134.5 MiB/s) with 1 file(s) remaining
Completed 117.1 MiB/286.0 MiB (134.7 MiB/s) with 1 file(s) remaining
Completed 117.4 MiB/286.0 MiB (134.8 MiB/s) with 1 file(s) remaining
Completed 117.6 MiB/286.0 MiB (135.0 MiB/s) with 1 file(s) remaining
Completed 117.9 MiB/286.0 MiB (135.2 MiB/s) with 1 file(s) remaining
Completed 118.1 MiB/286.0 MiB (135.4 MiB/s) with 1 file(s) remaining
Completed 118.4 MiB/286.0 MiB (135.5 MiB/s) with 1 file(s) remaining
Completed 118.6 MiB/286.0 MiB (135.7 MiB/s) with 1 file(s) remaining
Completed 118.9 MiB/286.0 MiB (135.9 MiB/s) with 1 file(s) remaining
Completed 119.1 MiB/286.0 MiB (136.0 MiB/s) with 1 file(s) remaining
Completed 119.4 MiB/286.0 MiB (136.2 MiB/s) with 1 file(s) remaining
Completed 119.6 MiB/286.0 MiB (136.4 MiB/s) with 1 file(s) remaining
Completed 119.9 MiB/286.0 MiB (136.6 MiB/s) with 1 file(s) remaining
Completed 120.1 MiB/286.0 MiB (136.8 MiB/s) with 1 file(s) remaining
Completed 120.4 MiB/286.0 MiB (137.0 MiB/s) with 1 file(s) remaining
Completed 120.6 MiB/286.0 MiB (137.2 MiB/s) with 1 file(s) remaining
Completed 120.9 MiB/286.0 MiB (137.5 MiB/s) with 1 file(s) remaining
Completed 121.1 MiB/286.0 MiB (137.6 MiB/s) with 1 file(s) remaining
Completed 121.4 MiB/286.0 MiB (137.9 MiB/s) with 1 file(s) remaining
Completed 121.6 MiB/286.0 MiB (137.6 MiB/s) with 1 file(s) remaining
Completed 121.9 MiB/286.0 MiB (137.1 MiB/s) with 1 file(s) remaining
Completed 122.1 MiB/286.0 MiB (137.3 MiB/s) with 1 file(s) remaining
Completed 122.4 MiB/286.0 MiB (137.2 MiB/s) with 1 file(s) remaining
Completed 122.6 MiB/286.0 MiB (137.2 MiB/s) with 1 file(s) remaining
Completed 122.9 MiB/286.0 MiB (137.4 MiB/s) with 1 file(s) remaining
Completed 123.1 MiB/286.0 MiB (137.7 MiB/s) with 1 file(s) remaining
Completed 123.4 MiB/286.0 MiB (137.8 MiB/s) with 1 file(s) remaining
Completed 123.6 MiB/286.0 MiB (137.9 MiB/s) with 1 file(s) remaining
Completed 123.9 MiB/286.0 MiB (138.1 MiB/s) with 1 file(s) remaining
Completed 124.1 MiB/286.0 MiB (138.2 MiB/s) with 1 file(s) remaining
Completed 124.4 MiB/286.0 MiB (138.4 MiB/s) with 1 file(s) remaining
Completed 124.6 MiB/286.0 MiB (138.5 MiB/s) with 1 file(s) remaining
Completed 124.9 MiB/286.0 MiB (138.8 MiB/s) with 1 file(s) remaining
Completed 125.1 MiB/286.0 MiB (138.9 MiB/s) with 1 file(s) remaining
Completed 125.4 MiB/286.0 MiB (139.1 MiB/s) with 1 file(s) remaining
Completed 125.6 MiB/286.0 MiB (139.2 MiB/s) with 1 file(s) remaining
Completed 125.9 MiB/286.0 MiB (139.3 MiB/s) with 1 file(s) remaining
Completed 126.1 MiB/286.0 MiB (139.5 MiB/s) with 1 file(s) remaining
Completed 126.4 MiB/286.0 MiB (139.7 MiB/s) with 1 file(s) remaining
Completed 126.6 MiB/286.0 MiB (139.8 MiB/s) with 1 file(s) remaining
Completed 126.9 MiB/286.0 MiB (140.0 MiB/s) with 1 file(s) remaining
Completed 127.1 MiB/286.0 MiB (140.1 MiB/s) with 1 file(s) remaining
Completed 127.4 MiB/286.0 MiB (140.3 MiB/s) with 1 file(s) remaining
Completed 127.6 MiB/286.0 MiB (140.5 MiB/s) with 1 file(s) remaining
Completed 127.9 MiB/286.0 MiB (140.4 MiB/s) with 1 file(s) remaining
Completed 128.1 MiB/286.0 MiB (140.6 MiB/s) with 1 file(s) remaining
Completed 128.4 MiB/286.0 MiB (140.7 MiB/s) with 1 file(s) remaining
Completed 128.6 MiB/286.0 MiB (140.8 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 128.9 MiB/286.0 MiB (141.0 MiB/s) with 1 file(s) remaining
Completed 129.1 MiB/286.0 MiB (141.2 MiB/s) with 1 file(s) remaining
Completed 129.4 MiB/286.0 MiB (141.4 MiB/s) with 1 file(s) remaining
Completed 129.6 MiB/286.0 MiB (141.5 MiB/s) with 1 file(s) remaining
Completed 129.9 MiB/286.0 MiB (141.7 MiB/s) with 1 file(s) remaining
Completed 130.1 MiB/286.0 MiB (141.9 MiB/s) with 1 file(s) remaining
Completed 130.4 MiB/286.0 MiB (142.1 MiB/s) with 1 file(s) remaining
Completed 130.6 MiB/286.0 MiB (142.0 MiB/s) with 1 file(s) remaining
Completed 130.9 MiB/286.0 MiB (142.2 MiB/s) with 1 file(s) remaining
Completed 131.1 MiB/286.0 MiB (142.4 MiB/s) with 1 file(s) remaining
Completed 131.4 MiB/286.0 MiB (142.6 MiB/s) with 1 file(s) remaining
Completed 131.6 MiB/286.0 MiB (142.8 MiB/s) with 1 file(s) remaining
Completed 131.9 MiB/286.0 MiB (143.0 MiB/s) with 1 file(s) remaining
Completed 132.1 MiB/286.0 MiB (143.1 MiB/s) with 1 file(s) remaining
Completed 132.4 MiB/286.0 MiB (143.3 MiB/s) with 1 file(s) remaining
Completed 132.6 MiB/286.0 MiB (143.4 MiB/s) with 1 file(s) remaining
Completed 132.9 MiB/286.0 MiB (143.6 MiB/s) with 1 file(s) remaining
Completed 133.1 MiB/286.0 MiB (143.8 MiB/s) with 1 file(s) remaining
Completed 133.4 MiB/286.0 MiB (143.9 MiB/s) with 1 file(s) remaining
Completed 133.6 MiB/286.0 MiB (143.9 MiB/s) with 1 file(s) remaining
Completed 133.9 MiB/286.0 MiB (144.1 MiB/s) with 1 file(s) remaining
Completed 134.1 MiB/286.0 MiB (144.3 MiB/s) with 1 file(s) remaining
Completed 134.4 MiB/286.0 MiB (144.5 MiB/s) with 1 file(s) remaining
Completed 134.6 MiB/286.0 MiB (144.7 MiB/s) with 1 file(s) remaining
Completed 134.9 MiB/286.0 MiB (144.9 MiB/s) with 1 file(s) remaining
Completed 135.1 MiB/286.0 MiB (145.1 MiB/s) with 1 file(s) remaining
Completed 135.4 MiB/286.0 MiB (145.3 MiB/s) with 1 file(s) remaining
Completed 135.6 MiB/286.0 MiB (145.4 MiB/s) with 1 file(s) remaining
Completed 135.9 MiB/286.0 MiB (145.2 MiB/s) with 1 file(s) remaining
Completed 136.1 MiB/286.0 MiB (145.3 MiB/s) with 1 file(s) remaining
Completed 136.4 MiB/286.0 MiB (145.4 MiB/s) with 1 file(s) remaining
Completed 136.6 MiB/286.0 MiB (145.7 MiB/s) with 1 file(s) remaining
Completed 136.9 MiB/286.0 MiB (145.8 MiB/s) with 1 file(s) remaining
Completed 137.1 MiB/286.0 MiB (146.0 MiB/s) with 1 file(s) remaining
Completed 137.4 MiB/286.0 MiB (146.2 MiB/s) with 1 file(s) remaining
Completed 137.6 MiB/286.0 MiB (146.3 MiB/s) with 1 file(s) remaining
Completed 137.9 MiB/286.0 MiB (146.5 MiB/s) with 1 file(s) remaining
Completed 138.1 MiB/286.0 MiB (146.6 MiB/s) with 1 file(s) remaining
Completed 138.4 MiB/286.0 MiB (146.8 MiB/s) with 1 file(s) remaining
Completed 138.6 MiB/286.0 MiB (146.9 MiB/s) with 1 file(s) remaining
Completed 138.9 MiB/286.0 MiB (147.1 MiB/s) with 1 file(s) remaining
Completed 139.1 MiB/286.0 MiB (147.3 MiB/s) with 1 file(s) remaining
Completed 139.4 MiB/286.0 MiB (147.4 MiB/s) with 1 file(s) remaining
Completed 139.6 MiB/286.0 MiB (147.6 MiB/s) with 1 file(s) remaining
Completed 139.9 MiB/286.0 MiB (147.8 MiB/s) with 1 file(s) remaining
Completed 140.1 MiB/286.0 MiB (148.0 MiB/s) with 1 file(s) remaining
Completed 140.4 MiB/286.0 MiB (147.9 MiB/s) with 1 file(s) remaining
Completed 140.6 MiB/286.0 MiB (148.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 140.9 MiB/286.0 MiB (148.2 MiB/s) with 1 file(s) remaining
Completed 141.1 MiB/286.0 MiB (148.2 MiB/s) with 1 file(s) remaining
Completed 141.4 MiB/286.0 MiB (148.4 MiB/s) with 1 file(s) remaining
Completed 141.6 MiB/286.0 MiB (148.6 MiB/s) with 1 file(s) remaining
Completed 141.9 MiB/286.0 MiB (148.7 MiB/s) with 1 file(s) remaining
Completed 142.1 MiB/286.0 MiB (148.9 MiB/s) with 1 file(s) remaining
Completed 142.4 MiB/286.0 MiB (149.0 MiB/s) with 1 file(s) remaining
Completed 142.6 MiB/286.0 MiB (149.2 MiB/s) with 1 file(s) remaining
Completed 142.9 MiB/286.0 MiB (149.4 MiB/s) with 1 file(s) remaining
Completed 143.1 MiB/286.0 MiB (149.6 MiB/s) with 1 file(s) remaining
Completed 143.4 MiB/286.0 MiB (149.7 MiB/s) with 1 file(s) remaining
Completed 143.6 MiB/286.0 MiB (149.8 MiB/s) with 1 file(s) remaining
Completed 143.9 MiB/286.0 MiB (150.0 MiB/s) with 1 file(s) remaining
Completed 144.1 MiB/286.0 MiB (150.2 MiB/s) with 1 file(s) remaining
Completed 144.4 MiB/286.0 MiB (150.2 MiB/s) with 1 file(s) remaining
Completed 144.6 MiB/286.0 MiB (150.4 MiB/s) with 1 file(s) remaining
Completed 144.9 MiB/286.0 MiB (150.3 MiB/s) with 1 file(s) remaining
Completed 145.1 MiB/286.0 MiB (150.5 MiB/s) with 1 file(s) remaining
Completed 145.4 MiB/286.0 MiB (150.7 MiB/s) with 1 file(s) remaining
Completed 145.6 MiB/286.0 MiB (150.8 MiB/s) with 1 file(s) remaining
Completed 145.9 MiB/286.0 MiB (151.0 MiB/s) with 1 file(s) remaining
Completed 146.1 MiB/286.0 MiB (151.2 MiB/s) with 1 file(s) remaining
Completed 146.4 MiB/286.0 MiB (151.4 MiB/s) with 1 file(s) remaining
Completed 146.6 MiB/286.0 MiB (151.5 MiB/s) with 1 file(s) remaining
Completed 146.9 MiB/286.0 MiB (151.6 MiB/s) with 1 file(s) remaining
Completed 147.1 MiB/286.0 MiB (151.8 MiB/s) with 1 file(s) remaining
Completed 147.4 MiB/286.0 MiB (152.0 MiB/s) with 1 file(s) remaining
Completed 147.6 MiB/286.0 MiB (152.0 MiB/s) with 1 file(s) remaining
Completed 147.9 MiB/286.0 MiB (152.2 MiB/s) with 1 file(s) remaining
Completed 148.1 MiB/286.0 MiB (152.3 MiB/s) with 1 file(s) remaining
Completed 148.4 MiB/286.0 MiB (152.5 MiB/s) with 1 file(s) remaining
Completed 148.6 MiB/286.0 MiB (152.6 MiB/s) with 1 file(s) remaining
Completed 148.9 MiB/286.0 MiB (152.8 MiB/s) with 1 file(s) remaining
Completed 149.1 MiB/286.0 MiB (152.8 MiB/s) with 1 file(s) remaining
Completed 149.4 MiB/286.0 MiB (153.0 MiB/s) with 1 file(s) remaining
Completed 149.6 MiB/286.0 MiB (153.0 MiB/s) with 1 file(s) remaining
Completed 149.9 MiB/286.0 MiB (153.0 MiB/s) with 1 file(s) remaining
Completed 150.1 MiB/286.0 MiB (153.1 MiB/s) with 1 file(s) remaining
Completed 150.4 MiB/286.0 MiB (153.2 MiB/s) with 1 file(s) remaining
Completed 150.6 MiB/286.0 MiB (153.4 MiB/s) with 1 file(s) remaining
Completed 150.9 MiB/286.0 MiB (153.3 MiB/s) with 1 file(s) remaining
Completed 151.1 MiB/286.0 MiB (153.1 MiB/s) with 1 file(s) remaining
Completed 151.4 MiB/286.0 MiB (153.2 MiB/s) with 1 file(s) remaining
Completed 151.6 MiB/286.0 MiB (153.4 MiB/s) with 1 file(s) remaining
Completed 151.9 MiB/286.0 MiB (153.3 MiB/s) with 1 file(s) remaining
Completed 152.1 MiB/286.0 MiB (153.3 MiB/s) with 1 file(s) remaining
Completed 152.4 MiB/286.0 MiB (153.2 MiB/s) with 1 file(s) remaining
Completed 152.6 MiB/286.0 MiB (153.3 MiB/s) with 1 file(s) remaining
Completed 152.9 MiB/286.0 MiB (153.5 MiB/s) with 1 file(s) remaining
Completed 153.1 MiB/286.0 MiB (153.5 MiB/s) with 1 file(s) remaining
Completed 153.4 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 153.6 MiB/286.0 MiB (153.8 MiB/s) with 1 file(s) remaining
Completed 153.9 MiB/286.0 MiB (153.7 MiB/s) with 1 file(s) remaining
Completed 154.1 MiB/286.0 MiB (153.7 MiB/s) with 1 file(s) remaining
Completed 154.4 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 154.6 MiB/286.0 MiB (153.4 MiB/s) with 1 file(s) remaining
Completed 154.9 MiB/286.0 MiB (153.3 MiB/s) with 1 file(s) remaining
Completed 155.1 MiB/286.0 MiB (153.5 MiB/s) with 1 file(s) remaining
Completed 155.4 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 155.6 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 155.9 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 156.1 MiB/286.0 MiB (153.4 MiB/s) with 1 file(s) remaining
Completed 156.4 MiB/286.0 MiB (153.5 MiB/s) with 1 file(s) remaining
Completed 156.6 MiB/286.0 MiB (153.4 MiB/s) with 1 file(s) remaining
Completed 156.9 MiB/286.0 MiB (153.6 MiB/s) with 1 file(s) remaining
Completed 157.1 MiB/286.0 MiB (153.5 MiB/s) with 1 file(s) remaining
Completed 157.4 MiB/286.0 MiB (153.7 MiB/s) with 1 file(s) remaining
Completed 157.6 MiB/286.0 MiB (153.9 MiB/s) with 1 file(s) remaining
Completed 157.9 MiB/286.0 MiB (154.0 MiB/s) with 1 file(s) remaining
Completed 158.1 MiB/286.0 MiB (153.9 MiB/s) with 1 file(s) remaining
Completed 158.4 MiB/286.0 MiB (154.0 MiB/s) with 1 file(s) remaining
Completed 158.6 MiB/286.0 MiB (154.1 MiB/s) with 1 file(s) remaining
Completed 158.9 MiB/286.0 MiB (154.2 MiB/s) with 1 file(s) remaining
Completed 159.1 MiB/286.0 MiB (154.3 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 159.4 MiB/286.0 MiB (154.4 MiB/s) with 1 file(s) remaining
Completed 159.6 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 159.9 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 160.1 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 160.4 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 160.6 MiB/286.0 MiB (154.8 MiB/s) with 1 file(s) remaining
Completed 160.9 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 161.1 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 161.4 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 161.6 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 161.9 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 162.1 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 162.4 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 162.6 MiB/286.0 MiB (154.8 MiB/s) with 1 file(s) remaining
Completed 162.9 MiB/286.0 MiB (154.8 MiB/s) with 1 file(s) remaining
Completed 163.1 MiB/286.0 MiB (154.9 MiB/s) with 1 file(s) remaining
Completed 163.4 MiB/286.0 MiB (154.9 MiB/s) with 1 file(s) remaining
Completed 163.6 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 163.9 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 164.1 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 164.4 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 164.6 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 164.9 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 165.1 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 165.4 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 165.6 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 165.9 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 166.1 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 166.4 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
Completed 166.6 MiB/286.0 MiB (155.4 MiB/s) with 1 file(s) remaining
Completed 166.9 MiB/286.0 MiB (155.6 MiB/s) with 1 file(s) remaining
Completed 167.1 MiB/286.0 MiB (155.5 MiB/s) with 1 file(s) remaining
Completed 167.4 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 167.6 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 167.9 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 168.1 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 168.4 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 168.6 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 168.9 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 169.1 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 169.4 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 169.6 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 169.9 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 170.1 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
Completed 170.4 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 170.6 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
Completed 170.9 MiB/286.0 MiB (155.4 MiB/s) with 1 file(s) remaining
Completed 171.1 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 171.4 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 171.6 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
Completed 171.9 MiB/286.0 MiB (154.9 MiB/s) with 1 file(s) remaining
Completed 172.1 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 172.4 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 172.6 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 172.9 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 173.1 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 173.4 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 173.6 MiB/286.0 MiB (154.3 MiB/s) with 1 file(s) remaining
Completed 173.9 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 174.1 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 174.4 MiB/286.0 MiB (154.4 MiB/s) with 1 file(s) remaining
Completed 174.6 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 174.9 MiB/286.0 MiB (154.1 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 175.1 MiB/286.0 MiB (154.2 MiB/s) with 1 file(s) remaining
Completed 175.4 MiB/286.0 MiB (154.1 MiB/s) with 1 file(s) remaining
Completed 175.6 MiB/286.0 MiB (154.2 MiB/s) with 1 file(s) remaining
Completed 175.9 MiB/286.0 MiB (153.9 MiB/s) with 1 file(s) remaining
Completed 176.1 MiB/286.0 MiB (153.8 MiB/s) with 1 file(s) remaining
Completed 176.4 MiB/286.0 MiB (154.0 MiB/s) with 1 file(s) remaining
Completed 176.6 MiB/286.0 MiB (154.0 MiB/s) with 1 file(s) remaining
Completed 176.9 MiB/286.0 MiB (154.1 MiB/s) with 1 file(s) remaining
Completed 177.1 MiB/286.0 MiB (154.2 MiB/s) with 1 file(s) remaining
Completed 177.4 MiB/286.0 MiB (154.3 MiB/s) with 1 file(s) remaining
Completed 177.6 MiB/286.0 MiB (154.3 MiB/s) with 1 file(s) remaining
Completed 177.9 MiB/286.0 MiB (154.4 MiB/s) with 1 file(s) remaining
Completed 178.1 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 178.4 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 178.6 MiB/286.0 MiB (154.4 MiB/s) with 1 file(s) remaining
Completed 178.9 MiB/286.0 MiB (154.5 MiB/s) with 1 file(s) remaining
Completed 179.1 MiB/286.0 MiB (154.6 MiB/s) with 1 file(s) remaining
Completed 179.4 MiB/286.0 MiB (154.7 MiB/s) with 1 file(s) remaining
Completed 179.6 MiB/286.0 MiB (154.9 MiB/s) with 1 file(s) remaining
Completed 179.9 MiB/286.0 MiB (155.0 MiB/s) with 1 file(s) remaining
Completed 180.1 MiB/286.0 MiB (155.1 MiB/s) with 1 file(s) remaining
Completed 180.4 MiB/286.0 MiB (155.2 MiB/s) with 1 file(s) remaining
Completed 180.6 MiB/286.0 MiB (155.4 MiB/s) with 1 file(s) remaining
Completed 180.9 MiB/286.0 MiB (155.5 MiB/s) with 1 file(s) remaining
Completed 181.1 MiB/286.0 MiB (155.5 MiB/s) with 1 file(s) remaining
Completed 181.4 MiB/286.0 MiB (155.3 MiB/s) with 1 file(s) remaining
Completed 181.6 MiB/286.0 MiB (155.4 MiB/s) with 1 file(s) remaining
Completed 181.9 MiB/286.0 MiB (155.6 MiB/s) with 1 file(s) remaining
Completed 182.1 MiB/286.0 MiB (155.7 MiB/s) with 1 file(s) remaining
Completed 182.4 MiB/286.0 MiB (155.7 MiB/s) with 1 file(s) remaining
Completed 182.6 MiB/286.0 MiB (155.9 MiB/s) with 1 file(s) remaining
Completed 182.9 MiB/286.0 MiB (155.9 MiB/s) with 1 file(s) remaining
Completed 183.1 MiB/286.0 MiB (156.0 MiB/s) with 1 file(s) remaining
Completed 183.4 MiB/286.0 MiB (156.2 MiB/s) with 1 file(s) remaining
Completed 183.6 MiB/286.0 MiB (156.3 MiB/s) with 1 file(s) remaining
Completed 183.9 MiB/286.0 MiB (156.4 MiB/s) with 1 file(s) remaining
Completed 184.1 MiB/286.0 MiB (156.6 MiB/s) with 1 file(s) remaining
Completed 184.4 MiB/286.0 MiB (156.7 MiB/s) with 1 file(s) remaining
Completed 184.6 MiB/286.0 MiB (156.8 MiB/s) with 1 file(s) remaining
Completed 184.9 MiB/286.0 MiB (156.9 MiB/s) with 1 file(s) remaining
Completed 185.1 MiB/286.0 MiB (156.9 MiB/s) with 1 file(s) remaining
Completed 185.4 MiB/286.0 MiB (157.0 MiB/s) with 1 file(s) remaining
Completed 185.6 MiB/286.0 MiB (156.9 MiB/s) with 1 file(s) remaining
Completed 185.9 MiB/286.0 MiB (156.9 MiB/s) with 1 file(s) remaining
Completed 186.1 MiB/286.0 MiB (157.1 MiB/s) with 1 file(s) remaining
Completed 186.4 MiB/286.0 MiB (157.2 MiB/s) with 1 file(s) remaining
Completed 186.6 MiB/286.0 MiB (157.3 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 186.9 MiB/286.0 MiB (156.9 MiB/s) with 1 file(s) remaining
Completed 187.1 MiB/286.0 MiB (157.1 MiB/s) with 1 file(s) remaining
Completed 187.4 MiB/286.0 MiB (157.2 MiB/s) with 1 file(s) remaining
Completed 187.6 MiB/286.0 MiB (157.3 MiB/s) with 1 file(s) remaining
Completed 187.9 MiB/286.0 MiB (157.4 MiB/s) with 1 file(s) remaining
Completed 188.1 MiB/286.0 MiB (157.5 MiB/s) with 1 file(s) remaining
Completed 188.4 MiB/286.0 MiB (157.6 MiB/s) with 1 file(s) remaining
Completed 188.6 MiB/286.0 MiB (157.6 MiB/s) with 1 file(s) remaining
Completed 188.9 MiB/286.0 MiB (157.6 MiB/s) with 1 file(s) remaining
Completed 189.1 MiB/286.0 MiB (157.8 MiB/s) with 1 file(s) remaining
Completed 189.4 MiB/286.0 MiB (157.8 MiB/s) with 1 file(s) remaining
Completed 189.6 MiB/286.0 MiB (157.8 MiB/s) with 1 file(s) remaining
Completed 189.9 MiB/286.0 MiB (157.9 MiB/s) with 1 file(s) remaining
Completed 190.1 MiB/286.0 MiB (158.0 MiB/s) with 1 file(s) remaining
Completed 190.4 MiB/286.0 MiB (158.1 MiB/s) with 1 file(s) remaining
Completed 190.6 MiB/286.0 MiB (158.3 MiB/s) with 1 file(s) remaining
Completed 190.9 MiB/286.0 MiB (158.4 MiB/s) with 1 file(s) remaining
Completed 191.1 MiB/286.0 MiB (158.5 MiB/s) with 1 file(s) remaining
Completed 191.4 MiB/286.0 MiB (158.6 MiB/s) with 1 file(s) remaining
Completed 191.6 MiB/286.0 MiB (158.8 MiB/s) with 1 file(s) remaining
Completed 191.9 MiB/286.0 MiB (158.9 MiB/s) with 1 file(s) remaining
Completed 192.1 MiB/286.0 MiB (159.0 MiB/s) with 1 file(s) remaining
Completed 192.4 MiB/286.0 MiB (158.9 MiB/s) with 1 file(s) remaining
Completed 192.6 MiB/286.0 MiB (159.1 MiB/s) with 1 file(s) remaining
Completed 192.9 MiB/286.0 MiB (159.2 MiB/s) with 1 file(s) remaining
Completed 193.1 MiB/286.0 MiB (159.4 MiB/s) with 1 file(s) remaining
Completed 193.4 MiB/286.0 MiB (159.4 MiB/s) with 1 file(s) remaining
Completed 193.6 MiB/286.0 MiB (159.5 MiB/s) with 1 file(s) remaining
Completed 193.9 MiB/286.0 MiB (159.5 MiB/s) with 1 file(s) remaining
Completed 194.1 MiB/286.0 MiB (159.6 MiB/s) with 1 file(s) remaining
Completed 194.4 MiB/286.0 MiB (159.5 MiB/s) with 1 file(s) remaining
Completed 194.6 MiB/286.0 MiB (159.7 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 194.9 MiB/286.0 MiB (159.8 MiB/s) with 1 file(s) remaining
Completed 195.1 MiB/286.0 MiB (159.9 MiB/s) with 1 file(s) remaining
Completed 195.4 MiB/286.0 MiB (160.0 MiB/s) with 1 file(s) remaining
Completed 195.6 MiB/286.0 MiB (160.2 MiB/s) with 1 file(s) remaining
Completed 195.9 MiB/286.0 MiB (160.3 MiB/s) with 1 file(s) remaining
Completed 196.1 MiB/286.0 MiB (160.5 MiB/s) with 1 file(s) remaining
Completed 196.4 MiB/286.0 MiB (160.3 MiB/s) with 1 file(s) remaining
Completed 196.6 MiB/286.0 MiB (160.4 MiB/s) with 1 file(s) remaining
Completed 196.9 MiB/286.0 MiB (160.5 MiB/s) with 1 file(s) remaining
Completed 197.1 MiB/286.0 MiB (160.5 MiB/s) with 1 file(s) remaining
Completed 197.4 MiB/286.0 MiB (160.6 MiB/s) with 1 file(s) remaining
Completed 197.6 MiB/286.0 MiB (160.8 MiB/s) with 1 file(s) remaining
Completed 197.9 MiB/286.0 MiB (160.8 MiB/s) with 1 file(s) remaining
Completed 198.1 MiB/286.0 MiB (160.9 MiB/s) with 1 file(s) remaining
Completed 198.4 MiB/286.0 MiB (160.9 MiB/s) with 1 file(s) remaining
Completed 198.6 MiB/286.0 MiB (161.0 MiB/s) with 1 file(s) remaining
Completed 198.9 MiB/286.0 MiB (161.1 MiB/s) with 1 file(s) remaining
Completed 199.1 MiB/286.0 MiB (161.2 MiB/s) with 1 file(s) remaining
Completed 199.4 MiB/286.0 MiB (161.3 MiB/s) with 1 file(s) remaining
Completed 199.6 MiB/286.0 MiB (161.1 MiB/s) with 1 file(s) remaining
Completed 199.9 MiB/286.0 MiB (161.3 MiB/s) with 1 file(s) remaining
Completed 200.1 MiB/286.0 MiB (161.2 MiB/s) with 1 file(s) remaining
Completed 200.4 MiB/286.0 MiB (161.3 MiB/s) with 1 file(s) remaining
Completed 200.6 MiB/286.0 MiB (161.4 MiB/s) with 1 file(s) remaining
Completed 200.9 MiB/286.0 MiB (161.5 MiB/s) with 1 file(s) remaining
Completed 201.1 MiB/286.0 MiB (161.5 MiB/s) with 1 file(s) remaining
Completed 201.4 MiB/286.0 MiB (161.6 MiB/s) with 1 file(s) remaining
Completed 201.6 MiB/286.0 MiB (161.7 MiB/s) with 1 file(s) remaining
Completed 201.9 MiB/286.0 MiB (161.8 MiB/s) with 1 file(s) remaining
Completed 202.1 MiB/286.0 MiB (161.9 MiB/s) with 1 file(s) remaining
Completed 202.4 MiB/286.0 MiB (162.0 MiB/s) with 1 file(s) remaining
Completed 202.6 MiB/286.0 MiB (162.1 MiB/s) with 1 file(s) remaining
Completed 202.9 MiB/286.0 MiB (162.2 MiB/s) with 1 file(s) remaining
Completed 203.1 MiB/286.0 MiB (162.3 MiB/s) with 1 file(s) remaining
Completed 203.4 MiB/286.0 MiB (162.4 MiB/s) with 1 file(s) remaining
Completed 203.6 MiB/286.0 MiB (162.6 MiB/s) with 1 file(s) remaining
Completed 203.9 MiB/286.0 MiB (162.5 MiB/s) with 1 file(s) remaining
Completed 204.1 MiB/286.0 MiB (162.7 MiB/s) with 1 file(s) remaining
Completed 204.4 MiB/286.0 MiB (162.7 MiB/s) with 1 file(s) remaining
Completed 204.6 MiB/286.0 MiB (162.9 MiB/s) with 1 file(s) remaining
Completed 204.9 MiB/286.0 MiB (163.0 MiB/s) with 1 file(s) remaining
Completed 205.1 MiB/286.0 MiB (163.1 MiB/s) with 1 file(s) remaining
Completed 205.4 MiB/286.0 MiB (163.1 MiB/s) with 1 file(s) remaining
Completed 205.6 MiB/286.0 MiB (163.2 MiB/s) with 1 file(s) remaining
Completed 205.9 MiB/286.0 MiB (163.3 MiB/s) with 1 file(s) remaining
Completed 206.1 MiB/286.0 MiB (163.4 MiB/s) with 1 file(s) remaining
Completed 206.4 MiB/286.0 MiB (163.6 MiB/s) with 1 file(s) remaining
Completed 206.6 MiB/286.0 MiB (163.7 MiB/s) with 1 file(s) remaining
Completed 206.9 MiB/286.0 MiB (163.6 MiB/s) with 1 file(s) remaining
Completed 207.1 MiB/286.0 MiB (163.7 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 207.4 MiB/286.0 MiB (163.9 MiB/s) with 1 file(s) remaining
Completed 207.6 MiB/286.0 MiB (164.0 MiB/s) with 1 file(s) remaining
Completed 207.9 MiB/286.0 MiB (164.0 MiB/s) with 1 file(s) remaining
Completed 208.1 MiB/286.0 MiB (164.1 MiB/s) with 1 file(s) remaining
Completed 208.4 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 208.6 MiB/286.0 MiB (164.4 MiB/s) with 1 file(s) remaining
Completed 208.9 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 209.1 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 209.4 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 209.6 MiB/286.0 MiB (164.0 MiB/s) with 1 file(s) remaining
Completed 209.9 MiB/286.0 MiB (164.1 MiB/s) with 1 file(s) remaining
Completed 210.1 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 210.4 MiB/286.0 MiB (164.2 MiB/s) with 1 file(s) remaining
Completed 210.6 MiB/286.0 MiB (164.4 MiB/s) with 1 file(s) remaining
Completed 210.9 MiB/286.0 MiB (164.5 MiB/s) with 1 file(s) remaining
Completed 211.1 MiB/286.0 MiB (164.5 MiB/s) with 1 file(s) remaining
Completed 211.4 MiB/286.0 MiB (164.4 MiB/s) with 1 file(s) remaining
Completed 211.6 MiB/286.0 MiB (164.3 MiB/s) with 1 file(s) remaining
Completed 211.9 MiB/286.0 MiB (164.4 MiB/s) with 1 file(s) remaining
Completed 212.1 MiB/286.0 MiB (164.5 MiB/s) with 1 file(s) remaining
Completed 212.4 MiB/286.0 MiB (164.3 MiB/s) with 1 file(s) remaining
Completed 212.6 MiB/286.0 MiB (164.4 MiB/s) with 1 file(s) remaining
Completed 212.9 MiB/286.0 MiB (164.5 MiB/s) with 1 file(s) remaining
Completed 213.1 MiB/286.0 MiB (164.6 MiB/s) with 1 file(s) remaining
Completed 213.4 MiB/286.0 MiB (164.6 MiB/s) with 1 file(s) remaining
Completed 213.6 MiB/286.0 MiB (164.7 MiB/s) with 1 file(s) remaining
Completed 213.9 MiB/286.0 MiB (164.8 MiB/s) with 1 file(s) remaining
Completed 214.1 MiB/286.0 MiB (165.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 214.4 MiB/286.0 MiB (165.1 MiB/s) with 1 file(s) remaining
Completed 214.6 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 214.9 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 215.1 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 215.4 MiB/286.0 MiB (165.4 MiB/s) with 1 file(s) remaining
Completed 215.6 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 215.9 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 216.1 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 216.4 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 216.6 MiB/286.0 MiB (165.4 MiB/s) with 1 file(s) remaining
Completed 216.9 MiB/286.0 MiB (165.5 MiB/s) with 1 file(s) remaining
Completed 217.1 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 217.4 MiB/286.0 MiB (165.2 MiB/s) with 1 file(s) remaining
Completed 217.6 MiB/286.0 MiB (165.4 MiB/s) with 1 file(s) remaining
Completed 217.9 MiB/286.0 MiB (165.5 MiB/s) with 1 file(s) remaining
Completed 218.1 MiB/286.0 MiB (165.6 MiB/s) with 1 file(s) remaining
Completed 218.4 MiB/286.0 MiB (165.6 MiB/s) with 1 file(s) remaining
Completed 218.6 MiB/286.0 MiB (165.2 MiB/s) with 1 file(s) remaining
Completed 218.9 MiB/286.0 MiB (165.3 MiB/s) with 1 file(s) remaining
Completed 219.1 MiB/286.0 MiB (165.4 MiB/s) with 1 file(s) remaining
Completed 219.4 MiB/286.0 MiB (165.5 MiB/s) with 1 file(s) remaining
Completed 219.6 MiB/286.0 MiB (165.6 MiB/s) with 1 file(s) remaining
Completed 219.9 MiB/286.0 MiB (165.7 MiB/s) with 1 file(s) remaining
Completed 220.1 MiB/286.0 MiB (165.9 MiB/s) with 1 file(s) remaining
Completed 220.4 MiB/286.0 MiB (166.0 MiB/s) with 1 file(s) remaining
Completed 220.6 MiB/286.0 MiB (166.0 MiB/s) with 1 file(s) remaining
Completed 220.9 MiB/286.0 MiB (165.5 MiB/s) with 1 file(s) remaining
Completed 221.1 MiB/286.0 MiB (165.6 MiB/s) with 1 file(s) remaining
Completed 221.4 MiB/286.0 MiB (165.7 MiB/s) with 1 file(s) remaining
Completed 221.6 MiB/286.0 MiB (165.7 MiB/s) with 1 file(s) remaining
Completed 221.9 MiB/286.0 MiB (165.7 MiB/s) with 1 file(s) remaining
Completed 222.1 MiB/286.0 MiB (165.8 MiB/s) with 1 file(s) remaining
Completed 222.4 MiB/286.0 MiB (165.9 MiB/s) with 1 file(s) remaining
Completed 222.6 MiB/286.0 MiB (166.0 MiB/s) with 1 file(s) remaining
Completed 222.9 MiB/286.0 MiB (166.1 MiB/s) with 1 file(s) remaining
Completed 223.1 MiB/286.0 MiB (166.2 MiB/s) with 1 file(s) remaining
Completed 223.4 MiB/286.0 MiB (166.3 MiB/s) with 1 file(s) remaining
Completed 223.6 MiB/286.0 MiB (166.4 MiB/s) with 1 file(s) remaining
Completed 223.9 MiB/286.0 MiB (166.3 MiB/s) with 1 file(s) remaining
Completed 224.1 MiB/286.0 MiB (166.4 MiB/s) with 1 file(s) remaining
Completed 224.4 MiB/286.0 MiB (166.3 MiB/s) with 1 file(s) remaining
Completed 224.6 MiB/286.0 MiB (166.4 MiB/s) with 1 file(s) remaining
Completed 224.9 MiB/286.0 MiB (166.5 MiB/s) with 1 file(s) remaining
Completed 225.1 MiB/286.0 MiB (166.6 MiB/s) with 1 file(s) remaining
Completed 225.4 MiB/286.0 MiB (166.7 MiB/s) with 1 file(s) remaining
Completed 225.6 MiB/286.0 MiB (166.8 MiB/s) with 1 file(s) remaining
Completed 225.9 MiB/286.0 MiB (166.8 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 226.1 MiB/286.0 MiB (166.9 MiB/s) with 1 file(s) remaining
Completed 226.4 MiB/286.0 MiB (167.0 MiB/s) with 1 file(s) remaining
Completed 226.6 MiB/286.0 MiB (167.1 MiB/s) with 1 file(s) remaining
Completed 226.9 MiB/286.0 MiB (167.1 MiB/s) with 1 file(s) remaining
Completed 227.1 MiB/286.0 MiB (167.0 MiB/s) with 1 file(s) remaining
Completed 227.4 MiB/286.0 MiB (167.1 MiB/s) with 1 file(s) remaining
Completed 227.6 MiB/286.0 MiB (167.2 MiB/s) with 1 file(s) remaining
Completed 227.9 MiB/286.0 MiB (167.3 MiB/s) with 1 file(s) remaining
Completed 228.1 MiB/286.0 MiB (167.5 MiB/s) with 1 file(s) remaining
Completed 228.4 MiB/286.0 MiB (167.6 MiB/s) with 1 file(s) remaining
Completed 228.6 MiB/286.0 MiB (167.7 MiB/s) with 1 file(s) remaining
Completed 228.9 MiB/286.0 MiB (167.8 MiB/s) with 1 file(s) remaining
Completed 229.1 MiB/286.0 MiB (167.9 MiB/s) with 1 file(s) remaining
Completed 229.4 MiB/286.0 MiB (168.0 MiB/s) with 1 file(s) remaining
Completed 229.6 MiB/286.0 MiB (168.0 MiB/s) with 1 file(s) remaining
Completed 229.9 MiB/286.0 MiB (168.0 MiB/s) with 1 file(s) remaining
Completed 230.1 MiB/286.0 MiB (168.1 MiB/s) with 1 file(s) remaining
Completed 230.4 MiB/286.0 MiB (168.1 MiB/s) with 1 file(s) remaining
Completed 230.6 MiB/286.0 MiB (168.3 MiB/s) with 1 file(s) remaining
Completed 230.9 MiB/286.0 MiB (168.3 MiB/s) with 1 file(s) remaining
Completed 231.1 MiB/286.0 MiB (168.4 MiB/s) with 1 file(s) remaining
Completed 231.4 MiB/286.0 MiB (168.5 MiB/s) with 1 file(s) remaining
Completed 231.6 MiB/286.0 MiB (168.6 MiB/s) with 1 file(s) remaining
Completed 231.9 MiB/286.0 MiB (168.7 MiB/s) with 1 file(s) remaining
Completed 232.1 MiB/286.0 MiB (168.8 MiB/s) with 1 file(s) remaining
Completed 232.4 MiB/286.0 MiB (168.7 MiB/s) with 1 file(s) remaining
Completed 232.6 MiB/286.0 MiB (168.8 MiB/s) with 1 file(s) remaining
Completed 232.9 MiB/286.0 MiB (168.7 MiB/s) with 1 file(s) remaining
Completed 233.1 MiB/286.0 MiB (168.9 MiB/s) with 1 file(s) remaining
Completed 233.4 MiB/286.0 MiB (168.8 MiB/s) with 1 file(s) remaining
Completed 233.6 MiB/286.0 MiB (168.9 MiB/s) with 1 file(s) remaining
Completed 233.9 MiB/286.0 MiB (169.0 MiB/s) with 1 file(s) remaining
Completed 234.1 MiB/286.0 MiB (169.0 MiB/s) with 1 file(s) remaining
Completed 234.4 MiB/286.0 MiB (169.0 MiB/s) with 1 file(s) remaining
Completed 234.6 MiB/286.0 MiB (169.2 MiB/s) with 1 file(s) remaining
Completed 234.9 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 235.1 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 235.4 MiB/286.0 MiB (169.2 MiB/s) with 1 file(s) remaining
Completed 235.6 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 235.9 MiB/286.0 MiB (169.4 MiB/s) with 1 file(s) remaining
Completed 236.1 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 236.4 MiB/286.0 MiB (169.4 MiB/s) with 1 file(s) remaining
Completed 236.6 MiB/286.0 MiB (169.2 MiB/s) with 1 file(s) remaining
Completed 236.9 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 237.1 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 237.4 MiB/286.0 MiB (169.2 MiB/s) with 1 file(s) remaining
Completed 237.6 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 237.9 MiB/286.0 MiB (169.3 MiB/s) with 1 file(s) remaining
Completed 238.1 MiB/286.0 MiB (169.4 MiB/s) with 1 file(s) remaining
Completed 238.4 MiB/286.0 MiB (169.5 MiB/s) with 1 file(s) remaining
Completed 238.6 MiB/286.0 MiB (169.5 MiB/s) with 1 file(s) remaining
Completed 238.9 MiB/286.0 MiB (169.4 MiB/s) with 1 file(s) remaining
Completed 239.1 MiB/286.0 MiB (169.5 MiB/s) with 1 file(s) remaining
Completed 239.4 MiB/286.0 MiB (169.6 MiB/s) with 1 file(s) remaining
Completed 239.6 MiB/286.0 MiB (169.7 MiB/s) with 1 file(s) remaining
Completed 239.9 MiB/286.0 MiB (169.8 MiB/s) with 1 file(s) remaining
Completed 240.1 MiB/286.0 MiB (169.8 MiB/s) with 1 file(s) remaining
Completed 240.4 MiB/286.0 MiB (169.9 MiB/s) with 1 file(s) remaining
Completed 240.6 MiB/286.0 MiB (169.7 MiB/s) with 1 file(s) remaining
Completed 240.9 MiB/286.0 MiB (169.7 MiB/s) with 1 file(s) remaining
Completed 241.1 MiB/286.0 MiB (169.7 MiB/s) with 1 file(s) remaining
Completed 241.4 MiB/286.0 MiB (169.8 MiB/s) with 1 file(s) remaining
Completed 241.6 MiB/286.0 MiB (169.8 MiB/s) with 1 file(s) remaining
Completed 241.9 MiB/286.0 MiB (169.9 MiB/s) with 1 file(s) remaining
Completed 242.1 MiB/286.0 MiB (169.9 MiB/s) with 1 file(s) remaining
Completed 242.4 MiB/286.0 MiB (170.0 MiB/s) with 1 file(s) remaining
Completed 242.6 MiB/286.0 MiB (170.0 MiB/s) with 1 file(s) remaining
Completed 242.9 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 243.1 MiB/286.0 MiB (170.2 MiB/s) with 1 file(s) remaining
Completed 243.4 MiB/286.0 MiB (170.2 MiB/s) with 1 file(s) remaining
Completed 243.6 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 243.9 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 244.1 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 244.4 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 244.6 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 244.9 MiB/286.0 MiB (169.9 MiB/s) with 1 file(s) remaining
Completed 245.1 MiB/286.0 MiB (169.9 MiB/s) with 1 file(s) remaining
Completed 245.4 MiB/286.0 MiB (170.0 MiB/s) with 1 file(s) remaining
Completed 245.6 MiB/286.0 MiB (170.0 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 245.9 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 246.1 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 246.4 MiB/286.0 MiB (170.0 MiB/s) with 1 file(s) remaining
Completed 246.6 MiB/286.0 MiB (170.1 MiB/s) with 1 file(s) remaining
Completed 246.9 MiB/286.0 MiB (170.2 MiB/s) with 1 file(s) remaining
Completed 247.1 MiB/286.0 MiB (170.3 MiB/s) with 1 file(s) remaining
Completed 247.4 MiB/286.0 MiB (170.4 MiB/s) with 1 file(s) remaining
Completed 247.6 MiB/286.0 MiB (170.5 MiB/s) with 1 file(s) remaining
Completed 247.9 MiB/286.0 MiB (170.5 MiB/s) with 1 file(s) remaining
Completed 248.1 MiB/286.0 MiB (170.6 MiB/s) with 1 file(s) remaining
Completed 248.4 MiB/286.0 MiB (170.5 MiB/s) with 1 file(s) remaining
Completed 248.6 MiB/286.0 MiB (170.6 MiB/s) with 1 file(s) remaining
Completed 248.9 MiB/286.0 MiB (170.7 MiB/s) with 1 file(s) remaining
Completed 249.1 MiB/286.0 MiB (170.6 MiB/s) with 1 file(s) remaining
Completed 249.4 MiB/286.0 MiB (170.7 MiB/s) with 1 file(s) remaining
Completed 249.6 MiB/286.0 MiB (170.7 MiB/s) with 1 file(s) remaining
Completed 249.9 MiB/286.0 MiB (170.7 MiB/s) with 1 file(s) remaining
Completed 250.1 MiB/286.0 MiB (170.7 MiB/s) with 1 file(s) remaining
Completed 250.4 MiB/286.0 MiB (170.9 MiB/s) with 1 file(s) remaining
Completed 250.6 MiB/286.0 MiB (170.8 MiB/s) with 1 file(s) remaining
Completed 250.9 MiB/286.0 MiB (170.9 MiB/s) with 1 file(s) remaining
Completed 251.1 MiB/286.0 MiB (171.0 MiB/s) with 1 file(s) remaining
Completed 251.4 MiB/286.0 MiB (171.0 MiB/s) with 1 file(s) remaining
Completed 251.6 MiB/286.0 MiB (171.1 MiB/s) with 1 file(s) remaining
Completed 251.9 MiB/286.0 MiB (171.1 MiB/s) with 1 file(s) remaining
Completed 252.1 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 252.4 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 252.6 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 252.9 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 253.1 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 253.4 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 253.6 MiB/286.0 MiB (171.5 MiB/s) with 1 file(s) remaining
Completed 253.9 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 254.1 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 254.4 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 254.6 MiB/286.0 MiB (171.7 MiB/s) with 1 file(s) remaining
Completed 254.9 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 255.1 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 255.4 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 255.6 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 255.9 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 256.1 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 256.4 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 256.6 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 256.9 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 257.1 MiB/286.0 MiB (171.2 MiB/s) with 1 file(s) remaining
Completed 257.4 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 257.6 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 257.9 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 258.1 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 258.4 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 258.6 MiB/286.0 MiB (171.5 MiB/s) with 1 file(s) remaining
Completed 258.9 MiB/286.0 MiB (171.5 MiB/s) with 1 file(s) remaining
Completed 259.1 MiB/286.0 MiB (171.5 MiB/s) with 1 file(s) remaining
Completed 259.4 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 259.6 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 259.9 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 260.1 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 260.4 MiB/286.0 MiB (171.3 MiB/s) with 1 file(s) remaining
Completed 260.6 MiB/286.0 MiB (171.4 MiB/s) with 1 file(s) remaining
Completed 260.9 MiB/286.0 MiB (171.5 MiB/s) with 1 file(s) remaining
Completed 261.1 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 261.4 MiB/286.0 MiB (171.6 MiB/s) with 1 file(s) remaining
Completed 261.6 MiB/286.0 MiB (171.7 MiB/s) with 1 file(s) remaining
Completed 261.9 MiB/286.0 MiB (171.8 MiB/s) with 1 file(s) remaining
Completed 262.1 MiB/286.0 MiB (171.8 MiB/s) with 1 file(s) remaining
Completed 262.4 MiB/286.0 MiB (171.8 MiB/s) with 1 file(s) remaining
Completed 262.6 MiB/286.0 MiB (171.9 MiB/s) with 1 file(s) remaining
Completed 262.9 MiB/286.0 MiB (171.9 MiB/s) with 1 file(s) remaining
Completed 263.1 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 263.4 MiB/286.0 MiB (172.1 MiB/s) with 1 file(s) remaining
Completed 263.6 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 263.9 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 264.1 MiB/286.0 MiB (172.1 MiB/s) with 1 file(s) remaining
Completed 264.4 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 264.6 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 264.9 MiB/286.0 MiB (171.9 MiB/s) with 1 file(s) remaining
Completed 265.1 MiB/286.0 MiB (171.9 MiB/s) with 1 file(s) remaining
Completed 265.4 MiB/286.0 MiB (172.0 MiB/s) with 1 file(s) remaining
Completed 265.6 MiB/286.0 MiB (172.1 MiB/s) with 1 file(s) remaining
Completed 265.9 MiB/286.0 MiB (172.2 MiB/s) with 1 file(s) remaining
Completed 266.1 MiB/286.0 MiB (172.3 MiB/s) with 1 file(s) remaining
Completed 266.4 MiB/286.0 MiB (172.3 MiB/s) with 1 file(s) remaining
Completed 266.6 MiB/286.0 MiB (172.3 MiB/s) with 1 file(s) remaining
Completed 266.9 MiB/286.0 MiB (172.4 MiB/s) with 1 file(s) remaining
Completed 267.1 MiB/286.0 MiB (172.4 MiB/s) with 1 file(s) remaining
Completed 267.4 MiB/286.0 MiB (172.5 MiB/s) with 1 file(s) remaining
Completed 267.6 MiB/286.0 MiB (172.6 MiB/s) with 1 file(s) remaining
Completed 267.9 MiB/286.0 MiB (172.6 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 268.1 MiB/286.0 MiB (172.6 MiB/s) with 1 file(s) remaining
Completed 268.4 MiB/286.0 MiB (172.7 MiB/s) with 1 file(s) remaining
Completed 268.6 MiB/286.0 MiB (172.7 MiB/s) with 1 file(s) remaining
Completed 268.9 MiB/286.0 MiB (172.8 MiB/s) with 1 file(s) remaining
Completed 269.1 MiB/286.0 MiB (172.8 MiB/s) with 1 file(s) remaining
Completed 269.4 MiB/286.0 MiB (172.9 MiB/s) with 1 file(s) remaining
Completed 269.6 MiB/286.0 MiB (172.9 MiB/s) with 1 file(s) remaining
Completed 269.9 MiB/286.0 MiB (173.0 MiB/s) with 1 file(s) remaining
Completed 270.1 MiB/286.0 MiB (173.0 MiB/s) with 1 file(s) remaining
Completed 270.4 MiB/286.0 MiB (173.0 MiB/s) with 1 file(s) remaining
Completed 270.6 MiB/286.0 MiB (173.2 MiB/s) with 1 file(s) remaining
Completed 270.9 MiB/286.0 MiB (173.2 MiB/s) with 1 file(s) remaining
Completed 271.1 MiB/286.0 MiB (173.3 MiB/s) with 1 file(s) remaining
Completed 271.4 MiB/286.0 MiB (173.3 MiB/s) with 1 file(s) remaining
Completed 271.6 MiB/286.0 MiB (173.4 MiB/s) with 1 file(s) remaining
Completed 271.9 MiB/286.0 MiB (173.4 MiB/s) with 1 file(s) remaining
Completed 272.1 MiB/286.0 MiB (173.4 MiB/s) with 1 file(s) remaining
Completed 272.4 MiB/286.0 MiB (173.4 MiB/s) with 1 file(s) remaining
Completed 272.6 MiB/286.0 MiB (173.4 MiB/s) with 1 file(s) remaining
Completed 272.9 MiB/286.0 MiB (173.5 MiB/s) with 1 file(s) remaining
Completed 273.1 MiB/286.0 MiB (173.6 MiB/s) with 1 file(s) remaining
Completed 273.4 MiB/286.0 MiB (173.6 MiB/s) with 1 file(s) remaining
Completed 273.6 MiB/286.0 MiB (173.7 MiB/s) with 1 file(s) remaining
Completed 273.9 MiB/286.0 MiB (173.7 MiB/s) with 1 file(s) remaining
Completed 274.1 MiB/286.0 MiB (173.8 MiB/s) with 1 file(s) remaining
Completed 274.4 MiB/286.0 MiB (173.8 MiB/s) with 1 file(s) remaining
Completed 274.6 MiB/286.0 MiB (173.8 MiB/s) with 1 file(s) remaining
Completed 274.9 MiB/286.0 MiB (173.9 MiB/s) with 1 file(s) remaining
Completed 275.1 MiB/286.0 MiB (173.9 MiB/s) with 1 file(s) remaining
Completed 275.4 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 275.6 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 275.9 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 276.1 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 276.4 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 276.6 MiB/286.0 MiB (174.3 MiB/s) with 1 file(s) remaining
Completed 276.9 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 277.1 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 277.4 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 277.6 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 277.9 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 278.1 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 278.4 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 278.6 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 278.9 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 279.1 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Completed 279.4 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 279.6 MiB/286.0 MiB (173.9 MiB/s) with 1 file(s) remaining
Completed 279.9 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 280.1 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 280.4 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 280.6 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 280.9 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 281.1 MiB/286.0 MiB (173.9 MiB/s) with 1 file(s) remaining
Completed 281.4 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 281.6 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 281.9 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 282.1 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 282.4 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 282.6 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 282.9 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 283.1 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 283.4 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 283.5 MiB/286.0 MiB (173.9 MiB/s) with 1 file(s) remaining
Completed 283.8 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 284.0 MiB/286.0 MiB (174.0 MiB/s) with 1 file(s) remaining
Completed 284.3 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 284.5 MiB/286.0 MiB (174.1 MiB/s) with 1 file(s) remaining
Completed 284.8 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 285.0 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 285.3 MiB/286.0 MiB (174.3 MiB/s) with 1 file(s) remaining
Completed 285.5 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 285.8 MiB/286.0 MiB (174.2 MiB/s) with 1 file(s) remaining
Completed 286.0 MiB/286.0 MiB (174.3 MiB/s) with 1 file(s) remaining
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>download: s3://openneuro.org/ds003477/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-model_residuals.nii.gz to ../../../../../../NI-edu-data/derivatives/pattern_estimation/sub-03/ses-1/model/sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-model_residuals.nii.gz
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Done!
</pre></div>
</div>
</div>
</div>
<p>We just downloaded two nifti files: one ending in <code class="docutils literal notranslate"><span class="pre">_beta.nii.gz</span></code> and one ending in <code class="docutils literal notranslate"><span class="pre">_varbeta.nii.gz</span></code>, which represent the parameter estimates (<span class="math notranslate nohighlight">\(\hat{\beta}\)</span>) of the single-trial model and the <em>variance</em> of the parameter estimates (<span class="math notranslate nohighlight">\(\mathrm{var}[\hat{\beta}]\)</span>) respectively:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Get directory with data</span>
<span class="n">pattern_dir</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;derivatives&#39;</span><span class="p">,</span> <span class="s1">&#39;pattern_estimation&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-03&#39;</span><span class="p">,</span> <span class="s1">&#39;ses-1&#39;</span><span class="p">,</span> <span class="s1">&#39;patterns&#39;</span><span class="p">)</span>

<span class="c1"># Check what&#39;s in the nibetaseries output directory</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="nb">sorted</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">listdir</span><span class="p">(</span><span class="n">pattern_dir</span><span class="p">))))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>sub-03_ses-1_task-face_run-1_events.tsv
sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz
sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_varbeta.nii.gz
</pre></div>
</div>
</div>
</div>
<p>These two files are both 4D nifti files, in which the fourth dimension does not represent time (as you may be used to), but trials! Below, we load them in and print its shape:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">betas_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">pattern_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03_ses-1_task-face_run-1_space-MNI152NLin2009cAsym_desc-trial_beta.nii.gz&#39;</span><span class="p">)</span>
<span class="n">R_4D</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">load_img</span><span class="p">(</span><span class="n">betas_path</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Shape of betas: </span><span class="si">{</span><span class="n">R_4D</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of betas: (73, 86, 66, 40)
</pre></div>
</div>
</div>
</div>
<p>Note that the data is, technically, not yet in the right format: it is formatted as an <span class="math notranslate nohighlight">\(X \times Y \times Z \times N\)</span> array (<span class="math notranslate nohighlight">\(N\)</span> = number of trials), while we should format our data as a <span class="math notranslate nohighlight">\(N \times K\)</span> array (where <span class="math notranslate nohighlight">\(K\)</span> is the product of the <span class="math notranslate nohighlight">\(X\)</span>, <span class="math notranslate nohighlight">\(Y\)</span>, and <span class="math notranslate nohighlight">\(Z\)</span> dimensions). We could reshape our data ourselves (e.g., by casting the data to a numpy array and using the <code class="docutils literal notranslate"><span class="pre">reshape</span></code> method) but instead, we’ll postpone this until the next section.</p>
<p>Also, lastly, we need to define a target variable. For the rest of the notebook, we’ll try to decode “smiling” faces from “neutral” faces (the variable “expression” in the event files). Note that the event file is included in the <code class="docutils literal notranslate"><span class="pre">pattern_estimation</span></code> directory we just downloaded.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="c1"># Load events-file corresponding to run 1</span>
<span class="n">events_file</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="s1">&#39;sub-03&#39;</span><span class="p">,</span> <span class="s1">&#39;ses-1&#39;</span><span class="p">,</span> <span class="s1">&#39;func&#39;</span><span class="p">,</span> <span class="s1">&#39;sub-03_ses-1_task-face_run-1_events.tsv&#39;</span><span class="p">)</span>
<span class="n">events</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">events_file</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="s1">&#39;</span><span class="se">\t</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="c1"># Filter out &#39;response&#39; and &#39;rating&#39; events</span>
<span class="n">events</span> <span class="o">=</span> <span class="n">events</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">events</span><span class="p">[</span><span class="s1">&#39;trial_type&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">contains</span><span class="p">(</span><span class="s1">&#39;STIM&#39;</span><span class="p">),</span> <span class="p">:]</span>

<span class="c1"># Extract the &quot;expression&quot; column (containing either &quot;smiling&quot; or &quot;neutral&quot;)</span>
<span class="n">S_expr</span> <span class="o">=</span> <span class="n">events</span><span class="p">[</span><span class="s1">&#39;expression&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="c1"># Encode the string labels into integers</span>
<span class="n">S_expr</span> <span class="o">=</span> <span class="n">lab_enc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">S_expr</span><span class="p">)</span>
<span class="n">S_expr</span>  <span class="c1"># smiling = 1, neutral = 0</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1,
       1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0])
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): The patterns we just loaded in were already normalized to a common (MNI) template. This is convenient when we want to apply masks derived from atlases (which are often defined in MNI space). But can you also think of an argument for analyzing the data in subject-native space (i.e., data that has not been normalized to a common template)?
</div><p>YOUR ANSWER HERE</p>
<div class="section" id="roi-selection">
<h3>ROI selection<a class="headerlink" href="#roi-selection" title="Permalink to this headline">¶</a></h3>
<p>An often used method to reduce the number of brain features is to restrict analyses to a particular region-of-interest (ROI), which can either be defined anatomically (e.g., the amygdala) or functionally (e.g., the voxels that activate significantly more to faces than to houses in a separate localizer run). For this section, we’ll focus on selecting a subset of voxels based on an anatomical ROI. What ROI we can use depends on the <em>space</em> of the data, i.e., whether the data has been normalized to a common template (usually MNI152) or not. Previously, we loaded in data that has been normalized to “MNI152NLin2009cAsym” space (the specific MNI flavor used by Fmriprep). As such, we can use ROIs from atlases that are defined in MNI space, such as the Harvard-Oxford atlas, which we can load using Nilearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_atlas_harvard_oxford</span>

<span class="c1"># ho_atlas is a dictionary with the keys &quot;labels&quot; and &quot;maps&quot;</span>
<span class="c1"># We use the subcortical &quot;maxprob&quot; atlas, thresholded at 25 probability</span>
<span class="n">ho_atlas</span> <span class="o">=</span> <span class="n">fetch_atlas_harvard_oxford</span><span class="p">(</span><span class="s1">&#39;sub-maxprob-thr25-2mm&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now, as you (hopefully) remember from the Nilearn notebook, we can check out which ROIs this atlas contains by looking at the ‘labels’ key from the atlas object:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ho_atlas</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;Background&#39;,
 &#39;Left Cerebral White Matter&#39;,
 &#39;Left Cerebral Cortex &#39;,
 &#39;Left Lateral Ventrical&#39;,
 &#39;Left Thalamus&#39;,
 &#39;Left Caudate&#39;,
 &#39;Left Putamen&#39;,
 &#39;Left Pallidum&#39;,
 &#39;Brain-Stem&#39;,
 &#39;Left Hippocampus&#39;,
 &#39;Left Amygdala&#39;,
 &#39;Left Accumbens&#39;,
 &#39;Right Cerebral White Matter&#39;,
 &#39;Right Cerebral Cortex &#39;,
 &#39;Right Lateral Ventricle&#39;,
 &#39;Right Thalamus&#39;,
 &#39;Right Caudate&#39;,
 &#39;Right Putamen&#39;,
 &#39;Right Pallidum&#39;,
 &#39;Right Hippocampus&#39;,
 &#39;Right Amygdala&#39;,
 &#39;Right Accumbens&#39;]
</pre></div>
</div>
</div>
</div>
<p>To demonstrate ROI selection, let’s focus on the right amygdala. To get the index of the right amygdala, we can do the following:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">r_amygd_idx</span> <span class="o">=</span> <span class="n">ho_atlas</span><span class="p">[</span><span class="s1">&#39;labels&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;Right Amygdala&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Index of right amygdala:&quot;</span><span class="p">,</span> <span class="n">r_amygd_idx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Index of right amygdala: 20
</pre></div>
</div>
</div>
</div>
<p>Let’s check the shape of the map stored in the “maps” key-value pair in the <code class="docutils literal notranslate"><span class="pre">ho_map</span></code> variable (a <code class="docutils literal notranslate"><span class="pre">Nifti1Image</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">nibabel</span> <span class="k">as</span> <span class="nn">nib</span>
<span class="n">ho_map</span> <span class="o">=</span> <span class="n">ho_atlas</span><span class="p">[</span><span class="s1">&#39;maps&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of map:&quot;</span><span class="p">,</span> <span class="n">ho_map</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of map: (91, 109, 91)
</pre></div>
</div>
</div>
</div>
<p>But there seems to be a problem! The map has more voxels than our data (<span class="math notranslate nohighlight">\(73 \times 86 \times 66\)</span>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of our data:&quot;</span><span class="p">,</span> <span class="n">R_4D</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of our data: (73, 86, 66, 40)
</pre></div>
</div>
</div>
</div>
<p>This is because the Harvard-Oxford atlas is defined in 2 millimeter space, while Fmriprep outputs preprocessed data in the original resolution of the functional data (here: 2.7 mm<span class="math notranslate nohighlight">\(^3\)</span>). To fix this, we can downsample the map to the resolution of our data using <code class="docutils literal notranslate"><span class="pre">resample_to_img</span></code> from Nilearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">image</span>
<span class="n">ho_map_resamp</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resample_to_img</span><span class="p">(</span><span class="n">ho_map</span><span class="p">,</span> <span class="n">R_4D</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of resampled map:&quot;</span><span class="p">,</span> <span class="n">ho_map_resamp</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of resampled map: (73, 86, 66)
</pre></div>
</div>
</div>
</div>
<p>Now, we can create an ROI by looking at which voxels in the Harvard-Oxford contain the label corresponding to our right amygdala label (i.e., 20):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Compare map with right amygdala label, creating a boolean array (True, False)</span>
<span class="n">r_amygd_roi_bool</span> <span class="o">=</span> <span class="n">ho_map_resamp</span><span class="o">.</span><span class="n">get_fdata</span><span class="p">()</span> <span class="o">==</span> <span class="n">r_amygd_idx</span>
</pre></div>
</div>
</div>
</div>
<p>In Nilearn, however, (ROI) masks should be Nifti objects with only two values: ones for voxels included in the mask and zeros for excluded voxels. Our <code class="docutils literal notranslate"><span class="pre">r_amygd_roi</span></code> now has boolean values, <code class="docutils literal notranslate"><span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">False</span></code>. Let’s convert this boolean array to integers (0, 1) and then make it a <code class="docutils literal notranslate"><span class="pre">Nifti1Image</span></code> object:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># The method .astype allows you to cast data into a different data type (here: int)</span>
<span class="c1"># We&#39;ll reuse the affine from the `ho_map_resamp` object</span>
<span class="n">r_amygd_roi</span> <span class="o">=</span> <span class="n">nib</span><span class="o">.</span><span class="n">Nifti1Image</span><span class="p">(</span><span class="n">r_amygd_roi_bool</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">affine</span><span class="o">=</span><span class="n">ho_map_resamp</span><span class="o">.</span><span class="n">affine</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of amygdala ROI:&quot;</span><span class="p">,</span> <span class="n">r_amygd_roi</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of amygdala ROI: (73, 86, 66)
</pre></div>
</div>
</div>
</div>
<p>And let’s plot it using Nilearn to check if everything worked as expected:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">plotting</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">r_amygd_roi</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_150_1.png" src="../../_images/decoding_analyses_150_1.png" />
</div>
</div>
<p>Looks good! Now, <em>finally</em>, we can apply the ROI to our data in the same way we’d apply a mask: using the <code class="docutils literal notranslate"><span class="pre">apply_mask</span></code> function from Nilearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn</span> <span class="kn">import</span> <span class="n">masking</span>
<span class="n">R_ramyg</span> <span class="o">=</span> <span class="n">masking</span><span class="o">.</span><span class="n">apply_mask</span><span class="p">(</span><span class="n">R_4D</span><span class="p">,</span> <span class="n">r_amygd_roi</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of indexed data:&quot;</span><span class="p">,</span> <span class="n">R_ramyg</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of indexed data: (40, 136)
</pre></div>
</div>
</div>
</div>
<p>Alright, that took some code, but we finally achieved what we wanted: a subset of voxels for our ROI (128 in total) for all our trials (40), neatly packaged in an <span class="math notranslate nohighlight">\(N \times K\)</span> array!</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Repeat the ROI indexing process for our data (<tt>R_4D</tt>), but this time using an ROI of the left hippocampus. Store the results (a 2D array) in a variable named <tt>R_lhippocampus</tt>.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="k">assert</span><span class="p">(</span><span class="n">R_lhippocampus</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="mi">40</span><span class="p">,</span> <span class="mi">258</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="pca">
<h3>PCA<a class="headerlink" href="#pca" title="Permalink to this headline">¶</a></h3>
<p>There are many methods for feature extraction, like “downsampling” to ROI-averages (i.e. averaging voxel patterns in brain regions) and dimensionality-reduction techniques like PCA. Scikit-learn provides some of these techniques as “transformer” objects, which again have a <code class="docutils literal notranslate"><span class="pre">fit()</span></code> and <code class="docutils literal notranslate"><span class="pre">transform</span></code> method. We’ll showcase this on the amygdala-restricted patterns we defined earlier.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>
<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="n">pca</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_ramyg</span><span class="p">)</span>
<span class="n">R_ramyg_pca10</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">R_ramyg</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape after PCA:&quot;</span><span class="p">,</span> <span class="n">R_ramyg_pca10</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape after PCA: (40, 10)
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'><b>ToDo</b> (2 points): In the previous cell, we fitted the PCA to the entire dataset (all samples in <tt>R_ramyg</tt>), but again, ideally we'd add this a a step to our analysis pipeline and also cross-validate this procedure! Write a completely ) cross-validated decoding pipeline with 5 stratified folds that includes standardization (using <tt>RobustScaler</tt>), PCA dimenensionality reduction (using 10 components), and a logistic regression model which aims to predict expression (smiling vs. neutral). Keep track of the foldwise cross-validated accuracy on the test set and store the average accuracy in a variable named <tt>acc_av_todo</tt>.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement the ToDo here.&#39;&#39;&#39;</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_pca_pipe</span>    
<span class="n">test_pca_pipe</span><span class="p">(</span><span class="n">R_ramyg</span><span class="p">,</span> <span class="n">S_expr</span><span class="p">,</span> <span class="n">acc_av_todo</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="region-averaging">
<h3>Region averaging<a class="headerlink" href="#region-averaging" title="Permalink to this headline">¶</a></h3>
<p>So far, we have restricted our analyses mostly to voxel patterns within a single ROI. For some research questions, however, you might want to include whole-brain patterns (for example, if you believe your experimental feature of interest is represented in whole-brain networks). This means, however, that you might be dealing with a lot of voxels (i.e., columns in your pattern matrix)! Again, you could reduce the number of features using dimensionality reduction techniques such as PCA. An alternative is to not use the activity of <em>voxels</em> as features, but the region-average activity! These regions can for example be derived from an existing anatomical atlas or parcellation or even from your own data (by fitting a clustering algorithm on the underlying timeseries).</p>
<p>You can do both (using existing atlases/parcellations or creating your own parcellation) using Nilearn. Here, we’ll  demonstrate how to “downsample” your whole-brain voxel patterns to region-average patterns using the existing <a class="reference external" href="https://academic.oup.com/cercor/article/28/9/3095/3978804">Shaefer et al. (2018)</a> parcellation, which we can load in using Nilearn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.datasets</span> <span class="kn">import</span> <span class="n">fetch_atlas_schaefer_2018</span>
<span class="c1"># It can return different number of ROIs; we&#39;ll set it to 100</span>
<span class="n">schaefer_parc</span> <span class="o">=</span> <span class="n">fetch_atlas_schaefer_2018</span><span class="p">(</span><span class="n">n_rois</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">resolution_mm</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Note that the Schaefer parcellation is defined MNI space with a 2 millimeter resolution. Our data has the original BOLD resolution (<span class="math notranslate nohighlight">\(2.7 \times 2.7 \times 2.97\)</span>), so in order to use it on our data, we need to resample it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Set interpolation to nearest, because we&#39;re dealing with discrete integers</span>
<span class="n">schaefer_rois</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">resample_to_img</span><span class="p">(</span><span class="n">schaefer_parc</span><span class="p">[</span><span class="s1">&#39;maps&#39;</span><span class="p">],</span> <span class="n">R_4D</span><span class="p">,</span> <span class="n">interpolation</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">)</span>

<span class="c1"># Let&#39;s also plot it:</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">schaefer_rois</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_165_0.png" src="../../_images/decoding_analyses_165_0.png" />
</div>
</div>
<p>Note that, unlike the probabilistic ROIs that we used, the Schaefer parcellation is discrete: every voxel belongs to only a single region. As such, the ‘maps’ map in the <code class="docutils literal notranslate"><span class="pre">schaef_parc</span></code> object is a single volume with integers:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">roi_ints</span> <span class="o">=</span> <span class="n">schaefer_rois</span><span class="o">.</span><span class="n">get_fdata</span><span class="p">()</span>

<span class="c1"># Let&#39;s check out the unique values in the volume</span>
<span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">roi_ints</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,
        11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,
        22.,  23.,  24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,
        33.,  34.,  35.,  36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,
        44.,  45.,  46.,  47.,  48.,  49.,  50.,  51.,  52.,  53.,  54.,
        55.,  56.,  57.,  58.,  59.,  60.,  61.,  62.,  63.,  64.,  65.,
        66.,  67.,  68.,  69.,  70.,  71.,  72.,  73.,  74.,  75.,  76.,
        77.,  78.,  79.,  80.,  81.,  82.,  83.,  84.,  85.,  86.,  87.,
        88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,  96.,  97.,  98.,
        99., 100.])
</pre></div>
</div>
</div>
</div>
<p>Importantly, here, voxels with the value 0 represent background voxels (not belonging to any region). Now, using the <code class="docutils literal notranslate"><span class="pre">NiftiLabelsMasker</span></code> class from Nilearn, we can easly compute the ROI-average activity for each of our samples across the 100 ROIs in the Schaefer parcellation.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Read through the <a href="https://nilearn.github.io/modules/generated/nilearn.input_data.NiftiLabelsMasker.html#nilearn.input_data.NiftiLabelsMasker">documentation</a> of the <tt>NiftiLabelsMasker</tt> class. Then, initialize a <tt>NiftiLabelsMasker</tt> object with <tt>labels_img=schaefer_rois</tt> and a "mean" <tt>strategy</tt>. Then, using this object, transform our whole-brain 4D patterns (the variable <tt>R_4D</tt>) into a 2D array (shape $40 \times 100$) and store it in a variable named <tt>R_schaefer</tt>.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">nilearn.input_data</span> <span class="kn">import</span> <span class="n">NiftiLabelsMasker</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>    
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_niftilabelsmasker</span>
<span class="n">test_niftilabelsmasker</span><span class="p">(</span><span class="n">schaefer_rois</span><span class="p">,</span> <span class="n">R_4D</span><span class="p">,</span> <span class="n">R_schaefer</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="searchlight-analysis">
<h3>Searchlight analysis<a class="headerlink" href="#searchlight-analysis" title="Permalink to this headline">¶</a></h3>
<p>One last technique that we want to discuss before moving on to statistical testing of decoding results is <em>searchlight analysis</em> (although it’s not <em>really</em> a feature selection/extraction technique). <a class="reference external" href="https://www.pnas.org/content/103/10/3863.short">Searchlight analysis</a> is a decoding-based analysis that is kind of a hybrid between univariate and multivariate analysis: it analyzes local voxel <em>patterns</em> but does that for every location in the brain. It does so by defining a spherical “searchlight” of voxels around a particular center voxel (with a particular radius). Within this searchlight, a (cross-validated) decoding analysis is performed and the result, usually a foldwise average model performance score (e.g., accuracy), is assigned to the center voxel. Then, the searchlight moved to the next voxel and a new decoding analysis performed; this process is repeated until each voxel has been the center voxel (and has been assigned a model performance score). As such, at the end of the searchlight analysis, you have an entire volume of (average) model performances, not just a single one!</p>
<p>Nilearn contains an efficient implementation of a searchlight analysis:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">nilearn.decoding</span> <span class="kn">import</span> <span class="n">SearchLight</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (0 points): Read through the <a href='https://nilearn.github.io/modules/generated/nilearn.decoding.SearchLight.html'>documentation</a> of the Searchlight estimator.
</div><p>Just like other Nilearn (and scikit-learn) classes, we first need to initialize a <code class="docutils literal notranslate"><span class="pre">Searchlight</span></code> object. Upon initialization, the <code class="docutils literal notranslate"><span class="pre">Searchlight</span></code> class needs a couple of parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">mask_img</span></code>: a binary mask that indicates which voxels contain actual brain;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">process_mask_img</span></code>: a binary mask that indicates which voxels should be analyzed;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">radius</span></code>: radius (in mm) of the searchlight sphere;</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">estimator</span></code>: a scikit-learn compatible estimator (which can be a classifier/regression model or a <code class="docutils literal notranslate"><span class="pre">Pipeline</span></code>!)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code>: how many CPUs to use</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">scoring</span></code>: a string indicating which scoring method to (e.g., ‘accuracy’, ‘roc_auc’, etc.)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">cv</span></code>: either an integer (referring to the number of desired folds) or a cross-validation object (e.g., a <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> object);</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">verbose</span></code>: whether it should print out stuff while performing the fit (<code class="docutils literal notranslate"><span class="pre">True</span></code> or <code class="docutils literal notranslate"><span class="pre">False</span></code>)</p></li>
</ul>
<p>Now, let’s go through these arguments one by one. First, to determine a brain mask, let’s just simply include all voxels that contain at least <em>some</em> signal across trials (i.e., where the sum across trials is not 0):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">brain_mask</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">math_img</span><span class="p">(</span><span class="s1">&#39;(img.sum(axis=3) != 0).astype(int)&#39;</span><span class="p">,</span> <span class="n">img</span><span class="o">=</span><span class="n">R_4D</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">brain_mask</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_176_0.png" src="../../_images/decoding_analyses_176_0.png" />
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): Why don't the inferior temporal lobes and the orbitofrontal cortex include any signal? Write your explanation in the text box below. Hint: think about the preprocessing tutorials from the previous course! 
</div><p>YOUR ANSWER HERE</p>
<p>For the <code class="docutils literal notranslate"><span class="pre">process_mask_img</span></code>, you could of course select the same mask (<code class="docutils literal notranslate"><span class="pre">brain_mask</span></code>), but for this tutorial, that would take too long. Instead, we’ll only analyze a single axial slice (the 22nd slice):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create empty volume</span>
<span class="n">sl_mask</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">brain_mask</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Set the 22nd slice to 1</span>
<span class="n">sl_mask</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">21</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="c1"># Create a Nifti1Image object from it using the &quot;image.new_img_like&quot; function</span>
<span class="c1"># from Nilearn</span>
<span class="n">sl_mask</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">brain_mask</span><span class="p">,</span> <span class="n">sl_mask</span><span class="p">)</span>

<span class="c1"># Of course, we only want to analyze the voxels from that slice that</span>
<span class="c1"># are ALSO in the brain mask, so let&#39;s intersect them:</span>
<span class="n">sl_mask</span> <span class="o">=</span> <span class="n">masking</span><span class="o">.</span><span class="n">intersect_masks</span><span class="p">((</span><span class="n">brain_mask</span><span class="p">,</span> <span class="n">sl_mask</span><span class="p">),</span> <span class="n">threshold</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="c1"># Let&#39;s plot it:</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_roi</span><span class="p">(</span><span class="n">sl_mask</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_180_0.png" src="../../_images/decoding_analyses_180_0.png" />
</div>
</div>
<p>Lastly, we need to create an “estimator” and a cross-validation object. Let’s go for a simple pipeline with scaling and a <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> classifier and a <code class="docutils literal notranslate"><span class="pre">StratifiedKFold</span></code> CV scheme:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sl_cv</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">sl_estimator</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>
<p>Finally, we can initialize the <code class="docutils literal notranslate"><span class="pre">Searchlight</span></code> object:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sl</span> <span class="o">=</span> <span class="n">SearchLight</span><span class="p">(</span>
    <span class="n">mask_img</span><span class="o">=</span><span class="n">brain_mask</span><span class="p">,</span>
    <span class="n">process_mask_img</span><span class="o">=</span><span class="n">sl_mask</span><span class="p">,</span>
    <span class="n">radius</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>  <span class="c1"># we&#39;ll use a 5 mm radius</span>
    <span class="n">estimator</span><span class="o">=</span><span class="n">sl_estimator</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>  <span class="c1"># use only 1 core (for your own analyses, you might want to increase this!)</span>
    <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;roc_auc&#39;</span><span class="p">,</span>  <span class="c1"># use AUROC as model performance metric</span>
    <span class="n">cv</span><span class="o">=</span><span class="n">sl_cv</span><span class="p">,</span>
    <span class="n">verbose</span><span class="o">=</span><span class="kc">True</span>  <span class="c1"># print a progressbar while fitting</span>
<span class="p">);</span>
</pre></div>
</div>
</div>
</div>
<p>To actually perform the searchlight analysis, we call the <code class="docutils literal notranslate"><span class="pre">fit</span></code> method with our data (a 4D nifti file, with the samples, <span class="math notranslate nohighlight">\(N\)</span>, in the fourth dimension) and target (the variable it needs to predict). The cell below might take a minute or two to run!</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sl</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_4D</span><span class="p">,</span> <span class="n">S_expr</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<p>After fitting, the <code class="docutils literal notranslate"><span class="pre">Searchlight</span></code> object’s <code class="docutils literal notranslate"><span class="pre">scores_</span></code> attribute contains the voxelwise decoding scores (here: average AUROC scores across the five folds) as a 3D numpy array (with the same shape as our brain mask):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape scores_:&quot;</span><span class="p">,</span> <span class="n">sl</span><span class="o">.</span><span class="n">scores_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape scores_: (73, 86, 66)
</pre></div>
</div>
</div>
</div>
<p>Let’s convert it to a <code class="docutils literal notranslate"><span class="pre">Nifti1Image</span></code> object so that we can plot it using Nilearn. We’ll set the (somewhat arbitrarily chosen) threshold to 0.65:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">score_img</span> <span class="o">=</span> <span class="n">image</span><span class="o">.</span><span class="n">new_img_like</span><span class="p">(</span><span class="n">brain_mask</span><span class="p">,</span> <span class="n">sl</span><span class="o">.</span><span class="n">scores_</span><span class="p">)</span>
<span class="n">plotting</span><span class="o">.</span><span class="n">plot_stat_map</span><span class="p">(</span><span class="n">score_img</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="mf">0.65</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_190_0.png" src="../../_images/decoding_analyses_190_0.png" />
</div>
</div>
<p>If you want to know more about searchlight analyses, we recommend <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811913002917?casa_token=R268PUFghLUAAAAA:-BQTf_rGHdG-0HrGdfb23nwzUzyt65oO9cZhwNGfH7DSOAx7ZQGqRwqfhTrzKO7BZWHI-lWEW5I">this article</a>. That said, let’s continue with the last part of this tutorial: permutation testing!</p>
</div>
</div>
<div class="section" id="significance-tests-and-permutation-testing">
<h2>Significance tests and permutation testing<a class="headerlink" href="#significance-tests-and-permutation-testing" title="Permalink to this headline">¶</a></h2>
<p>Suppose you ran your decode pipeline on twenty subjects and accordingly collected a set of twenty model performance scores (e.g., accuracy for a two-class target). Inevitably, some scores will be higher (e.g., 0.9) than others (e.g., 0.7), and some may even be at or below chance level (e.g., 0.45). In the same vein, suppose you ran your decode pipeline across the gray-matter density patterns of a 100 subjects (of which 50 are diagnosed with major depression and 50 are healthy controls) in a 10-fold cross-validation scheme, yielding tne (foldwise) model performance scores. Again, the magnitude of these scores may differ. How do we determine if these scores are, in fact, significantly higher than we’d expect by chance?</p>
<p>Significance tests for within-subject decoding analyses can be done in two ways. The “easy” way is to simply do a one-sample <span class="math notranslate nohighlight">\(t\)</span>-test against chance-level (e.g., 0.5 for a two-class target) on the subject-wise model performance scores. For example, suppose that our analyses have produced the following model performance scores (e.g., accuracy, averaged across folds):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># acc_scores are the average (across folds) accuracy score</span>
<span class="n">acc_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="mf">0.85</span><span class="p">,</span> <span class="mf">0.65</span><span class="p">,</span> <span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.45</span><span class="p">,</span> <span class="mf">0.55</span><span class="p">,</span> <span class="mf">0.50</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>As it is reasonable to assume that subjects are independent, we can do a one-sample <span class="math notranslate nohighlight">\(t\)</span>-test against a <span class="math notranslate nohighlight">\(H_{0}\)</span> of 0.5:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_1samp</span>
<span class="n">tvalue</span><span class="p">,</span> <span class="n">pvalue</span> <span class="o">=</span> <span class="n">ttest_1samp</span><span class="p">(</span><span class="n">acc_scores</span><span class="p">,</span> <span class="n">popmean</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;T-value: </span><span class="si">%.3f</span><span class="s2">, p-value: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">tvalue</span><span class="p">,</span> <span class="n">pvalue</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>T-value: 2.717, p-value: 0.024
</pre></div>
</div>
</div>
</div>
<p>If we’d use a significance level (<span class="math notranslate nohighlight">\(\alpha\)</span>) of 0.05, this would mean that our result is statistically significant — yay! This simple approach is, however, technically not a completely valid (random effects) analysis as shown by <a class="reference external" href="https://www.sciencedirect.com/science/article/pii/S1053811916303470?casa_token=XqSuI7NmrQMAAAAA:AKGyrgT-Z12RwzyRSzE7L5cTsezjtSu3VRSKddahRSNDsz4XltgsMp7kjnxlz5avIqsltySRQbw">Allefeld and colleagues (2016)</a>, because a one-sample t-test assumes a symmetric distribution centered at chance-level, but below chance-level model performance <em>in the population</em> is impossible. This is like testing commute time of people against a null-hypothesis of 0, which doesn’t make sense, because you cannot have a negative commute time! Allefeld and colleagues propose a solution, which they call “prevalence inference”, which involves intricate permutation testing procedures and is a bit too complicated for this course. If you ever need to evaluate decoding performance at the group-level, though, we highly recommend trying to implement this method.</p>
<div class='alert alert-success'>
    <b>Tip</b>: If you want to know more about prevalence inference and want to see some example code, you can check out <a href="https://github.com/lukassnoek/random_notebooks/blob/master/prevalence_inference.ipynb">this notebook</a>.
</div><p>That said, let’s look at how we’d statistically test the results of <em>between-subject</em> analyses. We cannot use a simple one-sample <span class="math notranslate nohighlight">\(t\)</span>-test for between-subject results, because data points in between-subject analyses — usually the model performance scores associated with different folds in K-fold CV — are <em>not independent</em>, which is an important assumption of all parametric statistics (such as <span class="math notranslate nohighlight">\(t\)</span>-tests). Dependence between data points is created because the same samples may be included in different folds. As such, we need a different, non-parameteric approach to evaluate statistical significance: permutation testing.</p>
<p>In the previous sections of this tutorial, we worked with within-subject data from a single subject, but for this section, we’ll need some between-subject data. For this, we’ll use voxel-based morphometry (VBM) data from 47 subjects. We’ll use these voxelwise gray matter volume patterns in the bilateral caudate to predict subject gender (male vs. female). Although theoretically meaningless, this allows us to demonstrate permutation testing.</p>
<p>First, let’s load in and prepare the data:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;vbm_analysis_data.npz&#39;</span><span class="p">,</span> <span class="s1">&#39;rb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f_in</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f_in</span><span class="p">)</span>
    <span class="n">R</span><span class="p">,</span> <span class="n">S</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;R&#39;</span><span class="p">],</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;S&#39;</span><span class="p">]</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;R shape:&quot;</span><span class="p">,</span> <span class="n">R</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;S shape:&quot;</span><span class="p">,</span> <span class="n">S</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>R shape: (47, 901)
S shape: (47,)
</pre></div>
</div>
</div>
</div>
<p>As you can see, we have data from 47 subjects with 901 voxels from the bilateral caudate.</p>
<div class="section" id="getting-your-observed-performance-score">
<h3>Getting your <em>observed</em> performance score<a class="headerlink" href="#getting-your-observed-performance-score" title="Permalink to this headline">¶</a></h3>
<p>Before you start with anything related to permutation testing, you first need to get your performance score that you would like to get a <span class="math notranslate nohighlight">\(p\)</span>-values for. In between-subject decoding analyses, this is usually the average accuracy (or whatever other metric) across folds. So, when you would implement a 3-fold cross-validation scheme, your observed performance score would be the average of the accuracy-estimates across those 3 folds. You know what? Let’s implement exactly that:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">solver</span><span class="o">=</span><span class="s1">&#39;lbfgs&#39;</span><span class="p">,</span> <span class="n">class_weight</span><span class="o">=</span><span class="s1">&#39;balanced&#39;</span><span class="p">))</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>  <span class="c1"># for reproducibility</span>

<span class="c1"># We&#39;ll pick 3 folds</span>
<span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>

<span class="n">performance</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">S</span><span class="p">):</span>
    <span class="n">R_train</span><span class="p">,</span> <span class="n">R_test</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">train_idx</span><span class="p">,</span> <span class="p">:],</span> <span class="n">R</span><span class="p">[</span><span class="n">test_idx</span><span class="p">,</span> <span class="p">:]</span>
    <span class="n">S_train</span><span class="p">,</span> <span class="n">S_test</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">S</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    
    <span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
    <span class="n">preds</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
    <span class="n">performance</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">))</span>
    
<span class="n">observed_acc</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">performance</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Mean accuracy across folds = </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">observed_acc</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mean accuracy across folds = 0.636
</pre></div>
</div>
</div>
</div>
<p>Alright, not bad! 63.6% correct is higher than chance, but is it also <em>significantly</em> higher than chance? For that, we need to “simulate” a null-distribution through permutation!</p>
</div>
<div class="section" id="getting-your-permuted-performance-distribution">
<h3>Getting your <em>permuted</em> performance distribution<a class="headerlink" href="#getting-your-permuted-performance-distribution" title="Permalink to this headline">¶</a></h3>
<p>The goal of permutation tests are to create a null-distribution of your observed measure, in this case: (average) classification accuracy. The null-distribution refers to the distribution of classification accuracies that would arise if you would repeat an experiment with noisy data in which there is no effect (i.e. the null-hypothesis is true).</p>
<p>Thus, we need to somehow repeat the above “experiment” (i.e. the analysis which yielded the observed performance of 51.1%) yet while the null-hypothesis is true (i.e. there is no effect, only noise). Well, as the term “permutation” suggest, we can simply randomly shuffly the train-labels (<code class="docutils literal notranslate"><span class="pre">S_train</span></code>) to generate random labels. Now, if we would fit the classifier on {<code class="docutils literal notranslate"><span class="pre">R_train</span></code>, and <code class="docutils literal notranslate"><span class="pre">S_train</span></code>}, then practically it would fit on noise. In fact, by random shuffling of the train-labels, we simulated the scenario in which (on average) the null-hypothesis would be true.</p>
<p>So, what we need to do in order to create a null-distribution of classification-accuracies is to run our original analysis (in the code cell above) many times (i.e. “repeat the experiment”), yet with random labeling of our train-samples. We expect that the mean of these null-accuracies would center around .5 (assumed chance level), but simply due to random noise, our simulated null-distribution will contain values (sometimes substantially) above and below chance level.</p>
<p>Anyway, look at the code-cell below. It contains exactly the same analysis as in the above code-block, yet now it is looped 100 times, and just before fitting (within every fold separately) we shuffle the train-labels to generate a random mapping between <code class="docutils literal notranslate"><span class="pre">R_train</span></code> and <code class="docutils literal notranslate"><span class="pre">S_train</span></code>. After every “experiment” (or simply “permutation”) we average the permuted accuracy scores across folds and store them (in the variable <code class="docutils literal notranslate"><span class="pre">permuted_accuracies</span></code>). Now, let’s run the code cell below (may take minute or two):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">tqdm.notebook</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="n">n_permutations</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">permuted_accuracies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n_permutations</span><span class="p">)</span>

<span class="c1"># the tqdm thingie will print a nice progressbar below</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_permutations</span><span class="p">)):</span>

    <span class="n">folds</span> <span class="o">=</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">S</span><span class="p">)</span>
    <span class="n">fold_accuracies</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">skf</span><span class="o">.</span><span class="n">get_n_splits</span><span class="p">())</span>

    <span class="k">for</span> <span class="n">ii</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">folds</span><span class="p">):</span>
    
        <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span> <span class="o">=</span> <span class="n">R</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">R</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
        <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">train_idx</span><span class="p">],</span> <span class="n">S</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
    
        <span class="c1"># Here we shuffle the S-train labels!!!</span>
        <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">S_train</span><span class="p">)</span>
        
        <span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">R_train</span><span class="p">,</span> <span class="n">S_train</span><span class="p">)</span>
        <span class="n">preds</span> <span class="o">=</span> <span class="n">pipe</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">R_test</span><span class="p">)</span>
        <span class="n">fold_accuracies</span><span class="p">[</span><span class="n">ii</span><span class="p">]</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">S_test</span><span class="p">,</span> <span class="n">preds</span><span class="p">)</span>
    
    <span class="n">permuted_accuracies</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">fold_accuracies</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<script type="application/vnd.jupyter.widget-view+json">
{"version_major": 2, "version_minor": 0, "model_id": "48134ff0bd2844278bde5784c66ce185"}
</script></div>
</div>
<p>Okay, we now got our simulated null-distribution values stored in the variable <code class="docutils literal notranslate"><span class="pre">permuted_accuracies</span></code>. Let’s look at how the distribution actually looks like (and how the observed accuracy relates to the permuted scores):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Permuted null-distribution&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">permuted_accuracies</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Average accuracy across folds&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Frequency&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">observed_acc</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Observed score&#39;</span><span class="p">],</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/decoding_analyses_207_0.png" src="../../_images/decoding_analyses_207_0.png" />
</div>
</div>
<p>Now, the ‘formula’ for the <span class="math notranslate nohighlight">\(p\)</span>-value in a permutation test is as follows: given <span class="math notranslate nohighlight">\(P\)</span> permutations, it’s the following (in pseudo-notation):</p>
<div class="amsmath math notranslate nohighlight" id="equation-3b4b38c2-35ec-4165-98e7-a5339b6fa177">
<span class="eqno">(98)<a class="headerlink" href="#equation-3b4b38c2-35ec-4165-98e7-a5339b6fa177" title="Permalink to this equation">¶</a></span>\[\begin{align}
p = \frac{\sum_{i=1}^{P}{(\mathrm{permuted}_{i} \geq \mathrm{observed})} + 1}{P+1}
\end{align}\]</div>
<p>where <span class="math notranslate nohighlight">\((\mathrm{permuted}_{i} \geq \mathrm{observed})\)</span> evaluates to 1 if true, otherwise 0. Put differently: the <span class="math notranslate nohighlight">\(p\)</span>-value, here, expresses the proportion of permutation-values that is equal to or higher than the observed value. Graphically, we can visualize the <span class="math notranslate nohighlight">\(p\)</span>-value as the area of the (simulated!) null-distribution right of the dotted red line in the figure above.</p>
<div class='alert alert-warning'>
<b>ToDo</b> (1 point): 
Calculate the $p$-value corresponding to the observed accuracy given our permuted null-distribution. Store it in a variable named <tt>pval_permutation</tt>. 
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># calculate p-value</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo.&#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_perm_pval</span>
<span class="n">test_perm_pval</span><span class="p">(</span><span class="n">permuted_accuracies</span><span class="p">,</span> <span class="n">observed_acc</span><span class="p">,</span> <span class="n">pval_permutation</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): For this final ToDo, we are going to throw you in at the deep end. Instead of a classification analysis, you are going to implement a regression analysis, in which you'll try to predict 'average attractiveness' (i.e., the attractiveness ratings for our stimuli given by an external set of subjects), which we defined for you already (the variable <tt>S</tt>, below). For the patterns, you can reuse the <tt>R_4D</tt> variable. However, you need to index this with a "Frontal Orbital Cortex" ROI from the Harvard-Oxford atlas (also defined below: <tt>ho_atlas</tt>). Note, you have to define the ROI yourself (including resampling to match the resolution of the patterns). <br><br>Then, construct a pipeline with a <tt>StandardScaler</tt> and a <tt>Ridge</tt> regression model (from the <tt>linear_model</tt> module; do not use any specific arguments during initialization). Using a 4-fold cross-validation routine (using the <tt>KFold</tt> class from the <tt>model_selection</tt> module), compute the cross-validated mean squared error (either manually or using the <tt>mean_squared_error</tt> function from the <tt>metrics</tt> module) each iteration. Finally, average the four mean squared error values and store this in a variable named <tt>av_mse</tt>. <br>
<p>A couple of pointers:</p>
<ul class="simple">
<li><p>You need to import all (new) classes and functions yourself;</p></li>
<li><p>Realize that scikit-learn uses a consistent interface for its classes, whether they are regression-related or classification-related (e.g., a regression model has largely the same methods as classification models);</p></li>
</ul>
<p>Good luck!</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="n">S</span> <span class="o">=</span> <span class="n">events</span><span class="p">[</span><span class="s1">&#39;average_attractiveness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">ho_atlas</span> <span class="o">=</span> <span class="n">fetch_atlas_harvard_oxford</span><span class="p">(</span><span class="s1">&#39;cort-maxprob-thr50-2mm&#39;</span><span class="p">)</span>

<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nipa.week_2</span> <span class="kn">import</span> <span class="n">test_regression_todo</span>
<span class="n">test_regression_todo</span><span class="p">(</span><span class="n">R_4D</span><span class="p">,</span> <span class="n">events</span><span class="p">,</span> <span class="n">av_mse</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This notebook discussed the basics of decoding analyses. There are many more topics that we didn’t discuss (such as regularization, hyperparameter optimalization, prevalence inference), but hopefully you can get started with implementing your own decoding analyses after having completed this notebook!</p>
</div>
</div>
</div>


<script type="application/vnd.jupyter.widget-state+json">
{"state": {"c54d2fd465aa4fc79c87daaf1c98d337": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "4cefb5a3f3264d9aacd06fff8a94e2bd": {"model_name": "ProgressStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "ProgressStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "bar_color": null, "description_width": ""}}, "e8e2fcb50c14479e8e7a6cb87d025589": {"model_name": "FloatProgressModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "FloatProgressModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "ProgressView", "bar_style": "success", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_c54d2fd465aa4fc79c87daaf1c98d337", "max": 100.0, "min": 0.0, "orientation": "horizontal", "style": "IPY_MODEL_4cefb5a3f3264d9aacd06fff8a94e2bd", "value": 100.0}}, "1f2ac2fae84e45d8a076da78293e933f": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "ffa8dfa486d64b52bc90c01eb8b0aa00": {"model_name": "DescriptionStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "2c698230e83c4d5ba3302b90816c645a": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_1f2ac2fae84e45d8a076da78293e933f", "placeholder": "\u200b", "style": "IPY_MODEL_ffa8dfa486d64b52bc90c01eb8b0aa00", "value": "100%"}}, "499e872b282a4acba10353b854e67025": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "15d8da1421634325a5db865e4651ed81": {"model_name": "DescriptionStyleModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "DescriptionStyleModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "StyleView", "description_width": ""}}, "12b6b92d40b2482fb94e1be37eb2b0e4": {"model_name": "HTMLModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HTMLModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HTMLView", "description": "", "description_tooltip": null, "layout": "IPY_MODEL_499e872b282a4acba10353b854e67025", "placeholder": "\u200b", "style": "IPY_MODEL_15d8da1421634325a5db865e4651ed81", "value": " 100/100 [00:07&lt;00:00, 13.97it/s]"}}, "cbdf2f07361846499195a0ee9c0115cf": {"model_name": "LayoutModel", "model_module": "@jupyter-widgets/base", "model_module_version": "1.2.0", "state": {"_model_module": "@jupyter-widgets/base", "_model_module_version": "1.2.0", "_model_name": "LayoutModel", "_view_count": null, "_view_module": "@jupyter-widgets/base", "_view_module_version": "1.2.0", "_view_name": "LayoutView", "align_content": null, "align_items": null, "align_self": null, "border": null, "bottom": null, "display": null, "flex": null, "flex_flow": null, "grid_area": null, "grid_auto_columns": null, "grid_auto_flow": null, "grid_auto_rows": null, "grid_column": null, "grid_gap": null, "grid_row": null, "grid_template_areas": null, "grid_template_columns": null, "grid_template_rows": null, "height": null, "justify_content": null, "justify_items": null, "left": null, "margin": null, "max_height": null, "max_width": null, "min_height": null, "min_width": null, "object_fit": null, "object_position": null, "order": null, "overflow": null, "overflow_x": null, "overflow_y": null, "padding": null, "right": null, "top": null, "visibility": null, "width": null}}, "48134ff0bd2844278bde5784c66ce185": {"model_name": "HBoxModel", "model_module": "@jupyter-widgets/controls", "model_module_version": "1.5.0", "state": {"_dom_classes": [], "_model_module": "@jupyter-widgets/controls", "_model_module_version": "1.5.0", "_model_name": "HBoxModel", "_view_count": null, "_view_module": "@jupyter-widgets/controls", "_view_module_version": "1.5.0", "_view_name": "HBoxView", "box_style": "", "children": ["IPY_MODEL_2c698230e83c4d5ba3302b90816c645a", "IPY_MODEL_e8e2fcb50c14479e8e7a6cb87d025589", "IPY_MODEL_12b6b92d40b2482fb94e1be37eb2b0e4"], "layout": "IPY_MODEL_cbdf2f07361846499195a0ee9c0115cf"}}}, "version_major": 2, "version_minor": 0}
</script>


    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./fMRI-pattern-analysis/week_2"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        
            



<div class='prev-next-bottom'>
    
    <div id="prev">
        <a class="left-prev" href="../week_1/design_and_pattern_estimation.html" title="previous page">
            <i class="prevnext-label fas fa-angle-left"></i>
            <div class="prevnext-info">
                <p class="prevnext-label">previous</p>
                <p class="prevnext-title">Experimental design and pattern estimation</p>
            </div>
        </a>
    </div>
     <div id="next">
        <a class="right-next" href="../week_3/rsa.html" title="next page">
            <div class="prevnext-info">
                <p class="prevnext-label">next</p>
                <p class="prevnext-title">Representational Similarity Analysis</p>
            </div>
            <i class="prevnext-label fas fa-angle-right"></i>
        </a>
     </div>

</div>
        
        </div>
    </div>
    <footer class="footer">
    <div class="container">
      <p>
        
          By Lukas Snoek<br/>
        
            &copy; Copyright 2021.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.1c5a1a01449ed65a7b51.js"></script>

  
  </body>
</html>