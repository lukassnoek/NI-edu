
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Design of experiments &#8212; NI-edu</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.20.1/dist/embed-amd.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Neurodesign (tutorial)" href="neurodesign.html" />
    <link rel="prev" title="Design of experiments" href="../../section_intros/3_design_of_experiments_T.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/fmri.gif" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">NI-edu</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../index.html">
                    Welcome to NI-edu
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../getting_started/about.html">
   About this course
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../getting_started/installation.html">
   Installation
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  fMRI-introduction
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/1_python.html">
   Python for (f)MRI analysis
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../other/python_recap.html">
     Python recap
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_1/python_for_mri.html">
     Working with MRI data in Python (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/2_glm.html">
   Using the GLM to model fMRI data
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_2/glm_part1_estimation.html">
     The GLM: estimation (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="glm_part2_inference.html">
     The GLM: inference (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../../section_intros/3_design_of_experiments_T.html">
   Design of experiments
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active">
    <a class="current reference internal" href="#">
     Design of experiments (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="neurodesign.html">
     Neurodesign (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/4_preprocessing.html">
   Preprocessing
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_4/temporal_preprocessing.html">
     Temporal preprocessing (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_4/spatial_preprocessing.html">
     Spatial preprocessing (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_4/fmriprep.html">
     Fmriprep (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/5_multilevel.html">
   First &amp; run-level analyses
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_5/linux_and_the_command_line.html">
     Linux and the CMD (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_5/first_level_analyses.html">
     First level analyses (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_5/run_level_analyses.html">
     Run-level analyses (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/6_grouplevel.html">
   Group-level analyses
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_6/group_level_analyses.html">
     Group-level analyses (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_6/MCC.html">
     Multiple comparison correction (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_6/ROI_analysis.html">
     ROI analysis (T)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../section_intros/7_nilearn.html">
   Introduction to Nilearn
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_7/nilearn.html">
     Introduction to Nilearn (T)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../week_7/nilearn_stats.html">
     Statistics with Nilearn (T)
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  fMRI-pattern-analysis
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../fMRI-pattern-analysis/week_1/design_and_pattern_estimation.html">
   Design and pattern estimation (T)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fMRI-pattern-analysis/week_2/decoding_analyses.html">
   Machine learning/decoding (T)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../fMRI-pattern-analysis/week_3/rsa.html">
   Representational Similarity Analysis (T)
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Misc
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/bibliography.html">
   Bibliography
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/for_educators.html">
   For educators
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/CONTRIBUTING.html">
   Contributing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../misc/CONDUCT.html">
   Code of Conduct
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/lukassnoek/NI-edu/master?urlpath=tree/NI-edu/fMRI-introduction/week_3/design_of_experiments.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://neuroimaging.lukas-snoek.com/hub/user-redirect/git-pull?repo=https%3A//github.com/lukassnoek/NI-edu&urlpath=tree/NI-edu/NI-edu/fMRI-introduction/week_3/design_of_experiments.ipynb&branch=master"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on JupyterHub"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_jupyterhub.svg">
  </span>
<span class="headerbtn__text-container">JupyterHub</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/lukassnoek/NI-edu"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/lukassnoek/NI-edu/issues/new?title=Issue%20on%20page%20%2FfMRI-introduction/week_3/design_of_experiments.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/lukassnoek/NI-edu/edit/master/NI-edu/fMRI-introduction/week_3/design_of_experiments.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/fMRI-introduction/week_3/design_of_experiments.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-designs-factorial-and-parametric-designs">
   Types of designs: factorial and parametric designs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factorial-designs">
     Factorial designs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-designs">
     Parametric designs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#design-variance-efficiency">
   Design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-effects">
     Optimizing “effects”
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#psychological-factors">
       Psychological factors
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#design-factors">
       Design factors
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-design-variance">
     Optimizing design variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-effects-noise-and-design-variance">
     Summary: effects, noise, and design variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-calculate-design-variance-and-efficiency-in-python">
     How to calculate design variance and efficiency in Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-effect-of-predictor-variance-on-design-variance-efficiency">
   The effect of predictor variance on design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-example-of-the-effect-of-high-design-variance">
     An example of the effect of (high) design variance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-effect-of-predictor-covariance-on-design-variance-efficiency">
   The effect of predictor covariance on design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multicollinearity">
     Multicollinearity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-multiple-contrasts">
     Evaluating multiple contrasts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-should-we-design-our-experiment-to-maximize-efficiency">
   How should we design our experiment to maximize efficiency?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimation-vs-detection">
     Estimation vs. detection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#event-related-vs-blocked-designs">
     Event-related vs. blocked designs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-paradox-of-efficiency">
     The “paradox” of efficiency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#improving-design-efficiency-for-event-related-designs-using-jittering">
     Improving design efficiency for event-related designs using jittering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-how-to-optimize-your-design-for-efficiency">
     Summary: how to optimize your design for efficiency
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Design of experiments</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#types-of-designs-factorial-and-parametric-designs">
   Types of designs: factorial and parametric designs
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#factorial-designs">
     Factorial designs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#parametric-designs">
     Parametric designs
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#design-variance-efficiency">
   Design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-effects">
     Optimizing “effects”
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#psychological-factors">
       Psychological factors
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#design-factors">
       Design factors
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#optimizing-design-variance">
     Optimizing design variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-effects-noise-and-design-variance">
     Summary: effects, noise, and design variance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#how-to-calculate-design-variance-and-efficiency-in-python">
     How to calculate design variance and efficiency in Python
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-effect-of-predictor-variance-on-design-variance-efficiency">
   The effect of predictor variance on design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#an-example-of-the-effect-of-high-design-variance">
     An example of the effect of (high) design variance
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-effect-of-predictor-covariance-on-design-variance-efficiency">
   The effect of predictor covariance on design variance/efficiency
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#multicollinearity">
     Multicollinearity
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#evaluating-multiple-contrasts">
     Evaluating multiple contrasts
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#how-should-we-design-our-experiment-to-maximize-efficiency">
   How should we design our experiment to maximize efficiency?
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#estimation-vs-detection">
     Estimation vs. detection
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#event-related-vs-blocked-designs">
     Event-related vs. blocked designs
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#the-paradox-of-efficiency">
     The “paradox” of efficiency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#improving-design-efficiency-for-event-related-designs-using-jittering">
     Improving design efficiency for event-related designs using jittering
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#summary-how-to-optimize-your-design-for-efficiency">
     Summary: how to optimize your design for efficiency
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="design-of-experiments">
<h1>Design of experiments<a class="headerlink" href="#design-of-experiments" title="Permalink to this headline">#</a></h1>
<p>This notebook is about the statistical considerations related to fMRI experimental design. Make sure you do the other lab (<code class="docutils literal notranslate"><span class="pre">glm_part2_inference.ipynb</span></code>) first!</p>
<p>Experimental designs for fMRI studies come in different flavors, depending on what hypotheses you have about the phenomenon of interest and how you manipulate this. Apart from the different types of experimental designs (e.g., subtractive, factorial, parametric), there are a couple of general recommendations w.r.t. experimental design that can optimize the chance of finding positive results, which will be discussed in this notebook as well. These recommendations have to do with the specific ordering and timing of the events in your experiment. For example, suppose you show images of cats (condition: “C”) and dogs (condition: “D”) to subjects in the scanner, and you’re interested if the brain responds differently to images of dogs compared to images of cats. What ordering (“CCCCDDDD” or “CDCDCDCD” or “CCDCDDCD”?) and timing (how long should I wait to present another stimulus?) of the stimuli will yield the best (here: highest) effect possible, and why?</p>
<p><strong>What you’ll learn</strong>: after this lab, you’ll …</p>
<ul class="simple">
<li><p>understand what ‘design variance’ is and how it relates to ‘efficiency’</p></li>
<li><p>understand the effect of design variance <em>t</em>-values</p></li>
<li><p>know how to calculate design variance in Python</p></li>
</ul>
<p><strong>Estimated time needed to complete</strong>: 4-6 hours<br></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># First some imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">nilearn.glm.first_level.hemodynamic_models</span> <span class="kn">import</span> <span class="n">glover_hrf</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">pearsonr</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
</div>
</div>
<div class="section" id="types-of-designs-factorial-and-parametric-designs">
<h2>Types of designs: factorial and parametric designs<a class="headerlink" href="#types-of-designs-factorial-and-parametric-designs" title="Permalink to this headline">#</a></h2>
<p>In the previous tutorial (‘the GLM: part 2’), we discussed contrasts at length and how to use contrast-vectors to specify simple hypotheses (e.g., happy faces &gt; sad faces). The contrast-vectors from last week’s lab were examples of either simple contrasts-against-baseline (<span class="math notranslate nohighlight">\(H_{0}: \beta = 0\)</span>) or examples of <em>subtractive designs</em> (also called categorical designs; e.g., <span class="math notranslate nohighlight">\(H_{0}: \beta_{1} - \beta_{2} = 0\)</span>). There are, however, more types of designs possible, like <em>factorial</em> and <em>parametric</em> designs. In this first section, we’ll discuss these two designs shortly and have you implement GLMs to test hypotheses forwarded by these designs.</p>
<div class="section" id="factorial-designs">
<h3>Factorial designs<a class="headerlink" href="#factorial-designs" title="Permalink to this headline">#</a></h3>
<p>Factorial designs are designs in which each event (e.g., stimulus) may be represented by a combination of different conditions. For example, you could show images of squares and circles (condition 1: shape) which may be either green or red (condition 2: color). See the image below for a visualization of these conditions and the associated contrasts.</p>
<p><img alt="" src="https://docs.google.com/drawings/d/e/2PACX-1vROtTEQm-rUlrDMJWlUwmbMVkjhDHrs9snSAPL4K86CtOKpd3EFZz-z4lWVEXeS6qnaZeFCqwCO9C90/pub?w=1120&amp;h=527" /></p>
<p>Before we’ll explain this figure in more detail, let’s generate some data. We’ll assume that the TR is 1 second and that all onsets are always syncronized with the TR (so there won’t be onsets at, e.g., 10.295 seconds). This way, we can ignore the downsampling issue. We’ll convolve the data with an HRF already and plot the design matrix below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">niedu.utils.nii</span> <span class="kn">import</span> <span class="n">simulate_signal</span>

<span class="n">exp_length</span> <span class="o">=</span> <span class="mi">160</span>
<span class="n">TR</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">xmax</span> <span class="o">=</span> <span class="n">exp_length</span> <span class="o">//</span> <span class="n">TR</span>

<span class="n">y</span><span class="p">,</span> <span class="n">X</span> <span class="o">=</span> <span class="n">simulate_signal</span><span class="p">(</span>
    <span class="n">onsets</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
        <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">40</span><span class="p">,</span> <span class="mi">80</span><span class="p">,</span> <span class="mi">120</span><span class="p">,</span>  <span class="c1"># red squares</span>
         <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">90</span><span class="p">,</span> <span class="mi">130</span><span class="p">,</span>  <span class="c1"># red circles</span>
         <span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">140</span><span class="p">,</span>  <span class="c1"># green squares</span>
         <span class="mi">30</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">110</span><span class="p">,</span> <span class="mi">150</span><span class="p">]</span>  <span class="c1"># green circles</span>
    <span class="p">),</span>
    <span class="n">conditions</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;rq&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;rc&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;gs&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span> <span class="o">+</span> <span class="p">[</span><span class="s1">&#39;gc&#39;</span><span class="p">]</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span>
    <span class="n">TR</span><span class="o">=</span><span class="n">TR</span><span class="p">,</span>
    <span class="n">duration</span><span class="o">=</span><span class="n">exp_length</span><span class="p">,</span>
    <span class="n">icept</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">params_canon</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
    <span class="n">rnd_seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
    <span class="n">plot</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="p">:</span><span class="mi">5</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">4</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;g&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.3</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (seconds/TRs)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Activity (A.U.)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;red squares&#39;</span><span class="p">,</span> <span class="s1">&#39;red circles&#39;</span><span class="p">,</span> <span class="s1">&#39;green squares&#39;</span><span class="p">,</span> <span class="s1">&#39;green circles&#39;</span><span class="p">],</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_4_0.png" src="../../_images/design_of_experiments_4_0.png" />
</div>
</div>
<p>We have also the time series of a (hypothetical) fMRI voxel, loaded and plotted below:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">xmax</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">0.75</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (seconds/TRs)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Activity (A.U.)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_6_0.png" src="../../_images/design_of_experiments_6_0.png" />
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): Time to refresh your memory on how to implement the GLM! Run linear regression with the design specified above (i.e., the <tt>X</tt> variable). Store the resulting parameters (i.e., the "betas") in a new variable named <tt>betas_todo</tt>. Check whether the design already includes an intercept!
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.linalg</span> <span class="kn">import</span> <span class="n">inv</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo&#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_glm_refresher</span>
<span class="n">test_glm_refresher</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">betas_todo</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alright, now, from the figure above, you can see there are many different contrast possible! First of all, we can test for <em>main effects</em>: these are effects of a single condition, collapsing over the other(s). For example, testing whether red stimuli lead to different activity levels than green stimuli (regardless of shape) would be a test of a main effect. Technically, main effects within factorial designs are tested with F-tests, which are undirectional tests, which mean that they test for <em>any</em> difference between conditions (e.g., <em>either</em> that red &gt; green <em>or</em> green &gt; red). However, this rarely happens in cognitive neuroscience, as most hypotheses are directional (e.g., red &gt; green), so we’ll focus on those types of hypotheses in factorial designs here.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Define a contrast-vector below (which should be a numpy array with 5 values) with the name <tt>cvec_red_green</tt> that would test the hypothesis that red stimuli evoke more activity than green stimuli (regardless of shape).
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_red_larger_than_green</span>
<span class="n">test_red_larger_than_green</span><span class="p">(</span><span class="n">cvec_red_green</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Another hypothesis that you could have is that circles evoke more activity than squares (regardless of color). Define a contrast-vector below (which should be a numpy array with 5 values) with the name <tt>cvec_circle_square</tt> that would test this hypothesis.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_circles_larger_than_squares</span>
<span class="n">test_circles_larger_than_squares</span><span class="p">(</span><span class="n">cvec_circle_square</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Alright, these (directional) main effects should be familiar as they don’t differ very much from those that you saw last week. However, factorial designs are unique in that they, additionally, can test for <em>interactions</em> between conditions. Again, technically, (undirectional) F-tests should be used, but again, these are rarely used in cognitive neuroscience.</p>
<p>So, let’s define a directional interaction effect. Suppose that, for some reason, I believe that red stimuli evoke more activity than green stimuli, but more so for circles than for squares. In other words:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f57ffbc7-188f-425b-a514-5a7e122d883f">
<span class="eqno">(33)<a class="headerlink" href="#equation-f57ffbc7-188f-425b-a514-5a7e122d883f" title="Permalink to this equation">#</a></span>\[\begin{align}
(\hat{\beta}_{\mathrm{red, circle}} - \hat{\beta}_{\mathrm{green,circle}}) &gt; (\hat{\beta}_{\mathrm{red, square}} - \hat{\beta}_{\mathrm{green,square}})
\end{align}\]</div>
<p>It turns out, there is a very nice trick to figure out the corresponding contrast for this interaction: you can simply (elementwise) multiply the contrast vector for “red &gt; green” and the contrast vector for “circle &gt; squares”!</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Define a contrast vector below, named <tt>cvec_interaction</tt>, that tests the hypothesis that red stimuli evoke more activity than green stimuli, but more so for circles than for squares (i.e., the one from the example above).
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_interaction</span>
<span class="n">test_interaction</span><span class="p">(</span><span class="n">cvec_interaction</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s practice working with interactions once more.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Define a contrast vector below, named <tt>cvec_interaction2</tt>, that tests the hypothesis that squares evoke more activity than circles, but less so for green stimuli than for red stimuli.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_interaction2</span>
<span class="n">test_interaction2</span><span class="p">(</span><span class="n">cvec_interaction2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="parametric-designs">
<h3>Parametric designs<a class="headerlink" href="#parametric-designs" title="Permalink to this headline">#</a></h3>
<p>So far, we have discussed only designs with conditions that are categorical, such as “male vs. female faces”  and “circles vs. squares”. The independent variables in your experimental design, however, do not <em>have</em> to be categorical! They can be continuous or ordinal, meaning that a particular variable might have different values (or “weights”) across trials. Designs involving continuously varying properties are often called <em>parametric designs</em> or <em>parametric modulation</em>.</p>
<p>In parametric designs, we assume that our design affects the voxel response in two ways:</p>
<ol class="simple">
<li><p>An “unmodulated” response (a response to the stimulus/task <em>independent</em> of parametric value);</p></li>
<li><p>A parametric modulation of the response</p></li>
</ol>
<p>To make this more tangible, let’s consider an example. Suppose that we have fMRI data from a reward-study. On every trial in this experiment, trials would start with a word “guess” on the screen for 1 second. Then, participants had to guess a number between 1 and 10 (which they indicated using an MRI-compatible button box). Before the experiment started, participants were told that the closer they were to the “correct” number (which was predetermined by the experimenter for every trial), the larger the reward they would get: 1 euro when their guess was correct and 10 cents less for every number that they were off (e.g., when the “correct” number was 7 and they would guess 5, then they’d receive 80 eurocents). After the participant’s response and a inter-stimulus interval of 4 seconds, participants would see the amount they won on the screen.</p>
<p><img alt="" src="https://docs.google.com/drawings/d/e/2PACX-1vQE7azl2uFrK7sWOEvb-OgnFefGbFmwpPB6QmYZj8fPNRXaOulZYnXJZWD5FRnqGq_F5nNVw5oUCyLX/pub?w=950&amp;h=397" /></p>
<p>One hypothesis you might be interested in is whether there are voxels/brain regions which response is modulated by the reward magnitude (e.g., higher activity for larger rewards, or vice versa). Before we go on, let’s create some (hypothetical) experimental data. Suppose that the experiment lasted 10 minutes and contained 30 trials with varying reward magnitude, and fMRI was acquired with a TR of 1 second and onsets of the reward presentations were synchronized with the TR (again, while this is not very realistic, this obviates the need for up/downsampling).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">exp_time</span> <span class="o">=</span> <span class="mi">60</span> <span class="o">*</span> <span class="mi">10</span>  <span class="c1"># i.e., 14 minutes in seconds</span>
<span class="n">n_trials</span> <span class="o">=</span> <span class="mi">30</span>
<span class="n">reward_onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">exp_time</span><span class="p">,</span> <span class="n">exp_time</span> <span class="o">/</span> <span class="n">n_trials</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of trials: </span><span class="si">%i</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">reward_onsets</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>

<span class="n">reward_magnitudes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">reward_onsets</span><span class="o">.</span><span class="n">size</span><span class="p">)</span> <span class="o">/</span> <span class="mi">10</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">reward_magnitudes</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">reward_magnitudes</span><span class="o">.</span><span class="n">size</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Trial number, 0-</span><span class="si">%i</span><span class="s1"> (NOT TIME)&#39;</span> <span class="o">%</span> <span class="n">n_trials</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Reward (in euro)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Number of trials: 30
</pre></div>
</div>
<img alt="../../_images/design_of_experiments_26_1.png" src="../../_images/design_of_experiments_26_1.png" />
</div>
</div>
<p>Now, in non-parametric designs, we would create regressors with zeros everywhere and ones at the onset of stimuli (or whatever we think will impact the fMRI data). However, in parametric designs, we create two regressors for every parametric modulation: one for the unmodulated response and one for the modulated response.</p>
<p>Let’s start with the unmodulated response. This predictor is created like we did before: convolving a stick predictor with an HRF:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">x_unmod</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">exp_time</span><span class="p">)</span>
<span class="n">x_unmod</span><span class="p">[</span><span class="n">reward_onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">x_unmod</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">x_unmod</span><span class="p">,</span> <span class="n">hrf</span><span class="p">)[:</span><span class="n">exp_time</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_unmod</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">exp_time</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (sec./vols)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Activation (A.U.)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Unmodulated regressor&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_28_0.png" src="../../_images/design_of_experiments_28_0.png" />
</div>
</div>
<p>Now, the parametrically modulated regressor is created as follows: instead of creating an initial array with zeros and <em>ones</em> at indices corresponding to the reward onset, we use the (mean-subtracted) <em>reward magnitude</em>. It is important to subtract the mean from the parametric modulation values, because this will “decorrelate” the modulated regressor from the unmodulated regressor (such that the modulated regressor explains only variance that is due to modulation of the response, not the common response towards the stimulus/task). In other words, subtracting the mean from the parametric regressor <em>orthogonalises</em> the parametric regressor with respect to the unmodulated regressor.</p>
<p>Then, the predictor is again convolved with the HRF to create the final modulated predictor.</p>
<div class='alert alert-success'>
    <b>Tip</b>: Check out <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0126255">this excellent paper</a> by Mumford and colleagues (2015), which discusses orthogonalization in fMRI designs and when it is (in)appropriate. <a href="https://www.youtube.com/watch?v=2W7Rso-4Hqg">This video</a> also nicely explains orthogonalization in the context of parametric modulation analyses.
</div><p>Let’s try to create a modulated regression in a ToDo!</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Subtract the mean from the parametric modulation values (<tt>reward_magnitudes</tt>) and save this in a new variable named <tt>reward_magnitudes_ms</tt> (note: no for-loop necessary!). Now, create a new zeros-filled predictor, and set the values corresponding to the reward onsets to the mean-subtract reward magnitudes. Then, convolve the predictor with the HRF (use the variable <tt>hrf</tt> defined earlier). Make sure to trim off the excess values. Store the result in a variable named <tt>x_mod</tt>. Also plot the modulated regressor.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Implement your ToDo here. &#39;&#39;&#39;</span>
<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_parametric_modulation</span>
<span class="n">test_parametric_modulation</span><span class="p">(</span><span class="n">reward_onsets</span><span class="p">,</span> <span class="n">reward_magnitudes</span><span class="p">,</span> <span class="n">exp_time</span><span class="p">,</span> <span class="n">hrf</span><span class="p">,</span> <span class="n">x_mod</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
    <b>ToDo</b> (1 point): Now, stack an intercept, the unmodulated regressor, and the modulated regressor in a single design matrix (with three columns; you might have to create a singleton axis with <tt>np.newaxis</tt>!). Make sure the order of the columns is as follows: intercept, unmodulated regressor, modulated regressor. Then, run linear regression with this design matrix on the variable <tt>y_reward_signal</tt> below. Save the parameters in a variable named <tt>betas_reward</tt>.
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement your ToDo here</span>
<span class="n">y_reward_signal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;y_reward_signal.npy&#39;</span><span class="p">)</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the ToDo above. &#39;&#39;&#39;</span>
<span class="n">np</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_array_almost_equal</span><span class="p">(</span><span class="n">betas_reward</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">,</span> <span class="mf">2.19</span><span class="p">]),</span> <span class="n">decimal</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Well done!&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
    <b>ToThink</b> (1 point): Interpret the direction of the effect of the unmodulated and modulated predictors. How does this voxel respond to the reward events?
</div><p>YOUR ANSWER HERE</p>
</div>
</div>
<div class="section" id="design-variance-efficiency">
<h2>Design variance/efficiency<a class="headerlink" href="#design-variance-efficiency" title="Permalink to this headline">#</a></h2>
<p>Alright, hopefully you now know how to design contrasts for factorial and parameteric designs! This section has a slightly different focus, namely the mathematics behind design variance and efficiency! Remember that we wouldn’t tell you what “design variance” was in the previous two GLM tutorials? Well, this week we’re going to discuss and explain it <em>extensively</em>! Before we delve into this topic, let’s first recap the (conceptual) formula for the <em>t</em>-value from last week (the relevance of this will become clear shortly).</p>
<p>Last week, you learned about the GLM and how to apply it to fMRI data to find out how much influence each predictor in your design has on the signal of a voxel. Crucially, you learned that you shouldn’t look at raw beta-parameters to infer the effect of predictors, but that you should look at <em>normalized beta-parameters</em> — the <strong><em>t</em>-value</strong>. Remember the formula for the <em>t</em>-value for a given contrast (<span class="math notranslate nohighlight">\(c\)</span>)?</p>
<div class="amsmath math notranslate nohighlight" id="equation-69eb41e4-7b82-403f-852b-0b1daea10107">
<span class="eqno">(34)<a class="headerlink" href="#equation-69eb41e4-7b82-403f-852b-0b1daea10107" title="Permalink to this equation">#</a></span>\[\begin{align}
t_{\mathbf{c}\hat{\beta}} = \frac{\mathrm{effect}}{\sqrt{\mathrm{noise \cdot design\ variance}}} = \frac{\mathbf{c}\hat{\beta}}{\sqrt{\frac{SSE}{\mathrm{DF}} \cdot \mathrm{design\ variance}}}
\end{align}\]</div>
<p>The formula for the <em>t</em>-value embodies the concept that the statistics you (should) care about, <em>t</em>-values, depend both on the <strong>effect</strong> (sometimes confusingly called the “signal”; <span class="math notranslate nohighlight">\(\hat{\beta}\)</span>), the <strong>noise</strong> (<span class="math notranslate nohighlight">\(\hat{\sigma}^{2} = \frac{SSE}{\mathrm{DF}}\)</span>), and the <strong>“design variance”</strong>.</p>
<p>So, to find optimal (i.e. largest) <em>t</em>-values, we should try to optimize both the effect of our predictors (i.e. the betas), try to minimize the errors (<span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span>), and try to minimize the design variance of our model. In this lab, we’ll shortly discuss the “effect” component (<span class="math notranslate nohighlight">\(\hat{\beta}\)</span>) and thereafter we’ll discuss in detail the “design variance” part. We won’t discuss the “noise” part, as this will be the topic of next week (preprocessing).</p>
<div class="section" id="optimizing-effects">
<h3>Optimizing “effects”<a class="headerlink" href="#optimizing-effects" title="Permalink to this headline">#</a></h3>
<div class="section" id="psychological-factors">
<h4>Psychological factors<a class="headerlink" href="#psychological-factors" title="Permalink to this headline">#</a></h4>
<p>As discussed above, the “effect” part of the conceptual formula for the t-statistic refers to the <span class="math notranslate nohighlight">\(\beta\)</span>-parameter in the statistical formula. It may sound weird to try to “optimize” your effect, because there is no way to magically acquire a better/stronger effect from your data, right? (Well, apart from using a better/stronger MRI-scanner.) Actually, don’t forget that the effect you’re measuring is coming from the brain of a <em>human</em> beings (your subjects)! There are real and important psychological influences that affect the strength of your signal, and thus influence eventually the size of your <span class="math notranslate nohighlight">\(\beta\)</span>-parameter.</p>
<p>So, what are these psychological influences? Well, think about inattention/boredom, anxiety, sleepiness (don’t underestimate how many subjects fall asleep in the scanner!), and subjects not understanding your task. As an extreme example: suppose you’re showing your subject some visual stimuli in order to measure the effect of some visual property (e.g., object color) in the visual cortex. Imagine that your subject finds the task so boring that he/she falls asleep; the <span class="math notranslate nohighlight">\(\beta\)</span>-parameters in this scenario are going to be <em>much</em> lower than when the subject wouldn’t have fallen asleep, of course! Sure, this is an extreme (but not uncommon!) example, but it shows the potential influence of psychological factors on the “effect” you’re measuring in your data!</p>
<p>In short, when designing an experiment, you want to continually ask yourself: “Are subjects really doing/thinking the way I want them to?”, and consequently: “Am I really measuring what I think I’m measuring?”</p>
<p>(The effect of psychological aspects on the measured effect is thoroughly explained in the video <a class="reference external" href="https://www.youtube.com/watch?v=lwy2k8YQ-cM">Psychological principles in experimental design</a> from Tor Wager, which you can also find on Canvas.)</p>
</div>
<div class="section" id="design-factors">
<h4>Design factors<a class="headerlink" href="#design-factors" title="Permalink to this headline">#</a></h4>
<p>Apart from taking psychological factors into account when designing your experiment, there are also design-technical factors that influence the (potential) strength of your signal: using blocked designs. We will, however, discuss this topic in a later section, because you need a better understanding of another part of the conceptual <em>t</em>-value formula first: design variance.</p>
</div>
</div>
<div class="section" id="optimizing-design-variance">
<h3>Optimizing design variance<a class="headerlink" href="#optimizing-design-variance" title="Permalink to this headline">#</a></h3>
<p>So, last week we talked quite a bit about this mysterious term “design variance” and we promised to discuss it the next week. That’s exactly what we’re going to do now. As we shortly explained last week, <em>design variance is the part of the standard error caused by the design-matrix (<span class="math notranslate nohighlight">\(X\)</span>)</em>. Importantly, design variance is closely related to the <em>efficiency</em> of the design matrix (<span class="math notranslate nohighlight">\(X\)</span>), i.e., efficiency is the inverse of design variance:</p>
<div class="amsmath math notranslate nohighlight" id="equation-04c53cb2-a9c2-45ee-bbfe-011d1accc4fa">
<span class="eqno">(35)<a class="headerlink" href="#equation-04c53cb2-a9c2-45ee-bbfe-011d1accc4fa" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{efficiency} = \frac{1}{\mathrm{design\ variance}}
\end{align}\]</div>
<p>This term, efficiency, will be important in the rest of this notebook.</p>
<p>As these terms are inversely related, high design variance means low efficiency (which we don’t want) and low design variance means high efficiency (which we want). Phrased differently, high design variance means that your design-matrix is (relatively) <em>inefficient</em> for our goal to measure significant effects (i.e., high <em>t</em>-values). But, as you might have noticed, this definition is kind of circular. What causes low design variance (high efficiency), or: what constitutes an efficient design?</p>
<p>Basicially, two factors contribute to an efficient design:</p>
<ol class="simple">
<li><p>The predictors in your design should have <strong>high variance</strong> (i.e. they should vary a lot relative to their mean)</p></li>
<li><p>The predictors should <strong>not</strong> have <strong>high covariance</strong> (i.e. they should not correlate between each other a lot)</p></li>
</ol>
<p>In general, for any <strong>contrast between two <span class="math notranslate nohighlight">\(\beta\)</span>-parameters corresponding to predictor <span class="math notranslate nohighlight">\(j\)</span> and <span class="math notranslate nohighlight">\(k\)</span></strong>, we can define their design variance as follows*:</p>
<div class="amsmath math notranslate nohighlight" id="equation-57f2d29d-cb69-4154-af6b-b062ec264e97">
<span class="eqno">(36)<a class="headerlink" href="#equation-57f2d29d-cb69-4154-af6b-b062ec264e97" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{design\ variance}_{j,k} = \frac{1}{\mathrm{var}[X_{j}] + \mathrm{var}[X_{k}] - 2\cdot \mathrm{cov}[X_{j}, X_{k}]}
\end{align}\]</div>
<p>As such, efficiency for this contrast would the inverse:</p>
<div class="amsmath math notranslate nohighlight" id="equation-c0e6a3fc-d180-4a83-a67f-b2697ff65e1e">
<span class="eqno">(37)<a class="headerlink" href="#equation-c0e6a3fc-d180-4a83-a67f-b2697ff65e1e" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{efficiency}_{j,k} = \mathrm{var}[X_{j}] + \mathrm{var}[X_{k}] - 2\cdot \mathrm{cov}[X_{j}, X_{k}]
\end{align}\]</div>
<p>As you can see, design variance thus depends on the variance of the predictors <em>and</em> the covariance between predictors. Note that this formulation only applies to contrasts involving more than one parameter. For <strong>contrasts against baseline, in which only one parameter is tested (e.g. predictor <span class="math notranslate nohighlight">\(j\)</span>)</strong>, there is only one variance term (the other variance term and the covariance term are dropped out):</p>
<div class="amsmath math notranslate nohighlight" id="equation-be23565b-e8ac-4333-b808-c8ad5f257f32">
<span class="eqno">(38)<a class="headerlink" href="#equation-be23565b-e8ac-4333-b808-c8ad5f257f32" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{design\ variance}_{j} = \frac{1}{\mathrm{var}[X_{j}]}
\end{align}\]</div>
<p>It is of course kind of annoying to have two different definitions (and computations) of design variance, which depend on whether you want to test a parameter against baseline or against another parameter. Therefore, people usually use the vectorized computation (i.e. using matrix multiplication), which allows you to define the formula for design variance <em>for any contrast-vector <span class="math notranslate nohighlight">\(\mathbf{c}\)</span></em>:</p>
<div class="amsmath math notranslate nohighlight" id="equation-4682f852-f287-45a4-9154-a8ff3a3e66a2">
<span class="eqno">(39)<a class="headerlink" href="#equation-4682f852-f287-45a4-9154-a8ff3a3e66a2" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{design\ variance} = \frac{1}{\mathrm{var}[X_{j}] + \mathrm{var}[X_{k}] - 2\cdot \mathrm{cov}[X_{j}, X_{k}]} = \mathbf{c}(\mathbf{X}^T\mathbf{X})^{-1}\mathbf{c}^{T}
\end{align}\]</div>
<p>While this notation, <span class="math notranslate nohighlight">\(\mathbf{c}(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{c}\)</span>, may seem quite different than the above definitions using the <span class="math notranslate nohighlight">\(\mathrm{var}\)</span> and <span class="math notranslate nohighlight">\(\mathrm{cov}\)</span> terms, it is mathematically doing the same thing. The term <span class="math notranslate nohighlight">\((X^{T}X)^{-1}\)</span> represents (the inverse of) the variance-covariance matrix of the design (<span class="math notranslate nohighlight">\(X\)</span>) and <strong>c</strong> (contrast vector) is used only to “extract” the relevant variances and covariance for the particular contrast out of the entire covariance matrix of <span class="math notranslate nohighlight">\(X\)</span>.</p>
<p>While appearing more complex, the advantage of the vectorized definition, however, is that it works for both contrasts against baseline (e.g. <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">0,</span> <span class="pre">1]</span></code>) and contrasts between parameters (e.g. <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">-1]</span></code>). Now, if we plug in this mathematical definition of design variance in the formula of the standard error of a given contrast, we get:</p>
<div class="amsmath math notranslate nohighlight" id="equation-68c0f4ff-4fe5-4661-a6af-4cacf9948144">
<span class="eqno">(40)<a class="headerlink" href="#equation-68c0f4ff-4fe5-4661-a6af-4cacf9948144" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{SE}_{\mathbf{c}\hat{\beta}} = \sqrt{\mathrm{noise} \cdot \mathrm{design\ variance}} = \sqrt{\hat{\sigma}^{2}\mathbf{c}(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{c}^{T}}
\end{align}\]</div>
<p>Now, we can write out the entire formula for the <em>t</em>-statistic:</p>
<div class="amsmath math notranslate nohighlight" id="equation-71426b79-cc2d-46d6-aad7-d85f97c0ee6f">
<span class="eqno">(41)<a class="headerlink" href="#equation-71426b79-cc2d-46d6-aad7-d85f97c0ee6f" title="Permalink to this equation">#</a></span>\[\begin{align}
t_{\mathbf{c}\hat{\beta}} = \frac{\mathbf{c}\hat{\beta}}{\sqrt{\hat{\sigma}^{2}\mathbf{c}(X'X)^{-1}\mathbf{c}'}} = \frac{\mathrm{effect}}{\sqrt{\mathrm{noise} \cdot \mathrm{design\ variance}}}
\end{align}\]</div>
<hr class="docutils" />
<p>* Actually, design variance does not depend on the “variance” and “covariance”, but on the sums-of-squares of each predictor <span class="math notranslate nohighlight">\(j\)</span> (<span class="math notranslate nohighlight">\(\mathrm{SS}_{X_{j}}\)</span>) and sums-of-squares cross-products (<span class="math notranslate nohighlight">\(\mathrm{SS}_{X_{j}, X_{k}}\)</span>), respectively. These are just the variance and covariance terms, but without dividing by <span class="math notranslate nohighlight">\(N - 1\)</span>! We used the terms variance and covariance here because they are more intuitive.</p>
</div>
<div class="section" id="summary-effects-noise-and-design-variance">
<h3>Summary: effects, noise, and design variance<a class="headerlink" href="#summary-effects-noise-and-design-variance" title="Permalink to this headline">#</a></h3>
<p>Alright, that’s a lot of math. Sorry about that. But the above formula nicely illustrates that, to obtain large effects (i.e. <em>t</em>-values), you need three things:</p>
<ol class="simple">
<li><p>A large response/effect (i.e. <span class="math notranslate nohighlight">\(\beta\)</span>)</p></li>
<li><p>An efficient design or, in other words, low design variance (i.e. high variance, low covariance: <span class="math notranslate nohighlight">\(\frac{1}{c(X^{T}X)^{-1}c'}\)</span>)</p></li>
<li><p>Low noise/unexplained variance (i.e. low <span class="math notranslate nohighlight">\(\mathrm{SSE}\ /\ \mathrm{DF}\)</span>)</p></li>
</ol>
<p>This week, we’ll discuss how to optimize (2): the efficiency from the design. Next week, we’ll discuss how to minimize (3): noise (unexplained variance).</p>
<p>If you remember these three components and how they conceptually relate to the effect we want to measure (<em>t</em>-values), you understand the most important aspect of experimental design in fMRI! In the rest of the tutorial, we’re going to show you <strong>why</strong> you want high variance and low covariance in your design (<span class="math notranslate nohighlight">\(X\)</span>) and <strong>how</strong> to achieve this by designing your experiment in a specific way.</p>
<div class='alert alert-warning'>
<b>ToDo</b> (0 points)
<p>In the previous section, you’ve seen a lot of math and definitions of (statistical) concepts. Especially the part on the inverses (e.g. efficiency is the inverse of design-variance, and vice versa).</p>
<p>It is important to understand how all the concepts (signal/beta, noise/SSE, design variance, efficiency) relate to each other and to the thing we’re after: strong effects (high <em>t</em>-values)!</p>
<p>Therefore, we captured the <em>conceptual</em> formula in a function below named <tt>conceptual_tvalue_calculator</tt>, which takes three inputs — signal, noise, and design variance — and outputs the effect (<em>t</em>-value) and design efficiency.</p>
<p>In the cell below, we call the function with some particular values for the three input-arguments (<tt>SIGNAL</tt>, <tt>NOISE</tt>, <tt>DESIGN_VARIANCE</tt>). For this (ungraded) ToDo, try to change these input parameters and try to understand how changing the inputs changes the outputs!</p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">conceptual_tvalue_calculator</span><span class="p">(</span><span class="n">signal</span><span class="p">,</span> <span class="n">noise</span><span class="p">,</span> <span class="n">design_variance</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot; Calculate the effect (t-value) from the signal, noise, and design variance components.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    signal : int/float</span>
<span class="sd">    noise : int/float</span>
<span class="sd">    design_variance : int/float</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    effect : float</span>
<span class="sd">    efficiency : float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">efficiency</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">design_variance</span>
    <span class="n">effect</span> <span class="o">=</span> <span class="n">signal</span> <span class="o">/</span> <span class="p">(</span><span class="n">noise</span> <span class="o">*</span> <span class="n">design_variance</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">effect</span><span class="p">,</span> <span class="n">efficiency</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Change the capitalized variables to see what effect it has on the t-value and efficiency</span>
<span class="n">SIGNAL</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">NOISE</span> <span class="o">=</span> <span class="mf">2.8</span>
<span class="n">DESIGN_VARIANCE</span> <span class="o">=</span> <span class="mf">0.02</span>

<span class="n">effect</span><span class="p">,</span> <span class="n">efficiency</span> <span class="o">=</span> <span class="n">conceptual_tvalue_calculator</span><span class="p">(</span><span class="n">signal</span><span class="o">=</span><span class="n">SIGNAL</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="n">NOISE</span><span class="p">,</span> <span class="n">design_variance</span><span class="o">=</span><span class="n">DESIGN_VARIANCE</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Effect (&#39;t-value&#39;): </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">effect</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Efficiency: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">efficiency</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Effect (&#39;t-value&#39;): 8.929
Efficiency: 50.000
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
<b>ToThink</b> (1 point): Researchers do not need to acquire (fMRI) data ($\mathbf{y}$) to calculate the efficiency of their design ($\mathbf{X}$). Why? 
</div><p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="how-to-calculate-design-variance-and-efficiency-in-python">
<h3>How to calculate design variance and efficiency in Python<a class="headerlink" href="#how-to-calculate-design-variance-and-efficiency-in-python" title="Permalink to this headline">#</a></h3>
<p>As discussed in the previous section, the formula for design variance (and efficiency) is often expressed using linear algebra notation:</p>
<div class="amsmath math notranslate nohighlight" id="equation-2657475d-79e7-4013-acdb-0c89afa3340c">
<span class="eqno">(42)<a class="headerlink" href="#equation-2657475d-79e7-4013-acdb-0c89afa3340c" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{design\ variance} = \mathbf{c}(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{c}^{T}
\end{align}\]</div>
<p>You have seen the <span class="math notranslate nohighlight">\((\mathbf{X}^{T}\mathbf{X})\)</span> earlier when we discussed the solution for finding the least squares solution. Now, design variance is calculated by pre and postmultiplying this term with the (transpose of the) contrast vector (denoted with <code class="docutils literal notranslate"><span class="pre">c</span></code> and <code class="docutils literal notranslate"><span class="pre">c.T</span></code>). As such, so the full design variance calculation can be implemented in python as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">design_var</span> <span class="o">=</span> <span class="n">c</span> <span class="o">@</span> <span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">c</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
<p>Given that efficiency is the inverse of design variance:</p>
<div class="amsmath math notranslate nohighlight" id="equation-59c9f6fa-ae9b-4842-84bd-86c57fc01d61">
<span class="eqno">(43)<a class="headerlink" href="#equation-59c9f6fa-ae9b-4842-84bd-86c57fc01d61" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{efficiency} = \frac{1}{\mathbf{c}(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{c}^{T}}
\end{align}\]</div>
<p>… we can calculate efficiency as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">efficiency</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">c</span> <span class="o">@</span> <span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">c</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
<p>You’ll have to implement this yourself in a later ToDo! But first, let’s go into more detail <em>why</em> high variance and low covariance are important to get large effects!</p>
</div>
</div>
<div class="section" id="the-effect-of-predictor-variance-on-design-variance-efficiency">
<h2>The effect of predictor variance on design variance/efficiency<a class="headerlink" href="#the-effect-of-predictor-variance-on-design-variance-efficiency" title="Permalink to this headline">#</a></h2>
<p>As explained in the previous section, design variance depends on (1) predictor variance and (2) predictor covariance. In this section, we’ll focus on predictor variance. In the next section, we’ll focus on predictor covariance.</p>
<p>As you probably know, <em>variance</em> is a statistical property of a random variable that describes the average squared deviation from the variable’s mean. Formally, for any variable <span class="math notranslate nohighlight">\(x\)</span> with mean <span class="math notranslate nohighlight">\(\bar{x}\)</span> and length <span class="math notranslate nohighlight">\(N\)</span>, its sample variance is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-5e57c599-2cef-4c01-b821-f485d5ee28d8">
<span class="eqno">(44)<a class="headerlink" href="#equation-5e57c599-2cef-4c01-b821-f485d5ee28d8" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathbf{var}[x] = \frac{1}{N - 1}\sum_{i=1}^{N}(x - \bar{x})^{2}
\end{align}\]</div>
<p>So, the more values of a variable deviate from its mean on average, the more variance it has.</p>
<p>To demonstrate the effect of predictor variance on design variance/efficiency, we will focus (for simplicity) on non-time series designs that have just a single condition and thus a single predictor (apart from the intercept). In these examples, we’ll focus on why high variance is important.</p>
<div class="section" id="an-example-of-the-effect-of-high-design-variance">
<h3>An example of the effect of (high) design variance<a class="headerlink" href="#an-example-of-the-effect-of-high-design-variance" title="Permalink to this headline">#</a></h3>
<p>To start, we want to show you — conceptually — why it is important to have a lot of variance in your predictors for a low standard error of your beta, and thus high t-values. We’re going to show you an example of ‘regular’ linear regression (so no time-series signal, but the example holds for MRI data).</p>
<p>Suppose we want to investigate the effect of someone’s IQ on their income (<span class="math notranslate nohighlight">\(\mathbf{X} = IQ\)</span>, <span class="math notranslate nohighlight">\(\mathbf{y} = income\)</span>). We’ve gathered some data, which we’ll as usual represent as an independent variable (<span class="math notranslate nohighlight">\(\mathbf{X}\)</span>) and a dependent variable (<span class="math notranslate nohighlight">\(\mathbf{y}\)</span>). We’ll also run the regression analysis and calculate the beta-parameters, MSE and <em>t</em>-value (corresponding to the IQ-parameter “against baseline”).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">niedu.utils.nii</span> <span class="kn">import</span> <span class="n">calculate_stats_for_iq_income_dataset</span>

<span class="c1"># Load the data</span>
<span class="n">iq_income_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;iq_variance_example.npz&#39;</span><span class="p">)</span>
<span class="n">X_lowvar</span> <span class="o">=</span> <span class="n">iq_income_data</span><span class="p">[</span><span class="s1">&#39;X_lv&#39;</span><span class="p">]</span>
<span class="n">y_lowvar</span> <span class="o">=</span> <span class="n">iq_income_data</span><span class="p">[</span><span class="s1">&#39;y_lv&#39;</span><span class="p">]</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape X: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">X_lowvar</span><span class="o">.</span><span class="n">shape</span><span class="p">,))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape y: </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">y_lowvar</span><span class="o">.</span><span class="n">shape</span><span class="p">,))</span>

<span class="n">beta_lv</span><span class="p">,</span> <span class="n">mse_lv</span><span class="p">,</span> <span class="n">tval_lv</span> <span class="o">=</span> <span class="n">calculate_stats_for_iq_income_dataset</span><span class="p">(</span><span class="n">iq_income_data</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;lowvar&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Relation between IQ (X) and income (y)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_lowvar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_lowvar</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Income (x 1000 euro)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;IQ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="p">(</span><span class="mi">116</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span> 
    <span class="p">(</span><span class="mi">116</span> <span class="o">*</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">128</span> <span class="o">*</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">118</span><span class="p">,</span> <span class="mi">66</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\hat{\beta}_</span><span class="si">{IQ}</span><span class="s1"> = </span><span class="si">%.3f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">118</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="s1">&#39;MSE = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mse_lv</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">116</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape X: (100, 2)
Shape y: (100,)
</pre></div>
</div>
<img alt="../../_images/design_of_experiments_51_1.png" src="../../_images/design_of_experiments_51_1.png" />
</div>
</div>
<p>This is pretty awesome data! On average, our prediction is on average less than 1 point off (i.e., <span class="math notranslate nohighlight">\(\mathrm{MSE} &lt; 1\)</span>)! But you might also have noticed that the <em>range</em> of values for <span class="math notranslate nohighlight">\(X\)</span> (i.e., IQ) is quite limited: we only measured people with IQs between about 118 and 127. This is quite a narrow range — in other words: little variance — knowing that IQ varies according to a normal distribution with mean 100 and standard deviation 15. In other words, we have a pretty good model, but it is only based on a specific range of the IQ-variable.</p>
<p>Think about it this way: this model captures the relationship between IQ and income, but only for relatively high-intelligence people. Sure, you can extrapolate to IQ-values like 80 and 90, but this extrapolation is quite uncertain because you’ve never even measured someone with that IQ-value!</p>
<p>So, for comparison, let’s a similar dataset with IQ and income, but this time with a much larger range of the IQ-variable. We’ll plot the two datasets (the low-variance and high-variance data) next to each other.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_highvar</span> <span class="o">=</span> <span class="n">iq_income_data</span><span class="p">[</span><span class="s1">&#39;X_hv&#39;</span><span class="p">]</span>
<span class="n">y_highvar</span> <span class="o">=</span> <span class="n">iq_income_data</span><span class="p">[</span><span class="s1">&#39;y_hv&#39;</span><span class="p">]</span>

<span class="n">x_lim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">65</span><span class="p">,</span> <span class="mi">130</span><span class="p">)</span>
<span class="n">y_lim</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">80</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Low-variance data (zoomed out)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_lowvar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_lowvar</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Income (x 1000 euro)&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;IQ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_lim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">y_lim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_lim</span><span class="p">,</span> <span class="p">(</span><span class="n">x_lim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_lim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\hat{\beta}_</span><span class="si">{IQ}</span><span class="s1"> = </span><span class="si">%.3f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">beta_lv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="s1">&#39;MSE = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mse_lv</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="c1"># Now, do the same calculations for the highvar data</span>
<span class="n">beta_hv</span><span class="p">,</span> <span class="n">mse_hv</span><span class="p">,</span> <span class="n">tval_hv</span> <span class="o">=</span> <span class="n">calculate_stats_for_iq_income_dataset</span><span class="p">(</span><span class="n">iq_income_data</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;highvar&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;High-variance data&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_highvar</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_highvar</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="n">x_lim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="n">y_lim</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;IQ&#39;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_lim</span><span class="p">,</span> <span class="p">(</span><span class="n">x_lim</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta_hv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_hv</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x_lim</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">beta_hv</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">beta_hv</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="sa">r</span><span class="s1">&#39;$\hat{\beta}_</span><span class="si">{IQ}</span><span class="s1"> = </span><span class="si">%.3f</span><span class="s1">$&#39;</span> <span class="o">%</span> <span class="n">beta_hv</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">70</span><span class="p">,</span> <span class="mi">65</span><span class="p">,</span> <span class="s1">&#39;MSE = </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">mse_hv</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_53_0.png" src="../../_images/design_of_experiments_53_0.png" />
</div>
</div>
<p>As you can see from the plots of the two datasets side-by-side, both the low-variance (left) and the high-variance plot (right) capture approximately the model: for each increase in an IQ-point, people earn about 1000 (low-variance model) / 959 (high-variance model) euro extra (these are reflected by the beta-parameters!).</p>
<p>But, you also see that the MSE for the high-variance model is <em>much</em> higher, which is also evident from the residuals (distance of the red points from the blue line).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mse_ratio</span> <span class="o">=</span> <span class="n">mse_hv</span> <span class="o">/</span> <span class="n">mse_lv</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The MSE of the high-variance data is </span><span class="si">%.3f</span><span class="s2"> times larger than the low-variance data!&quot;</span> <span class="o">%</span> <span class="n">mse_ratio</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The MSE of the high-variance data is 23.279 times larger than the low-variance data!
</pre></div>
</div>
</div>
</div>
<p>Given these statistics, you might guess that the t-value of the IQ-parameter in the high-variance model would be way lower than the same parameter in the low-variance model, right? Well, let’s check it out:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We calcalated the t-values earlier with the calculate_stats_for_iq_income_dataset function</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;T-value low-variance model: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">tval_lv</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;T-value high-variance model: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">tval_hv</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>T-value low-variance model: 21.189
T-value high-variance model: 31.156
</pre></div>
</div>
</div>
</div>
<p>You probably by now understand what’s the culprit: the design-variance! Given that the effect (<span class="math notranslate nohighlight">\(\hat{\beta}_{IQ}\)</span>) is about the same for the two models and the MSE is higher for the high-variance model, the logical conclusion is that <em>the design-variance of the high-variance model must be waaaaay lower</em>.</p>
<div class='alert alert-warning'>
    <b>ToDo</b> (2 points): Use the two design-matrices (<tt>X_highvar</tt> and <tt>X_lowvar</tt>) to calculate the design-variances of both the low-variance and the high-variance dataset for the "contrast against baseline", i.e., $H_{0}: \beta_{IQ} = 0$ and $H_{a}: \beta_{IQ} \neq 0$. Then, divide the design-variance of the low-variance dataset by the high-variance dataset and store this in the variable <tt>desvar_ratio</tt> (this indicates how much higher the design-variance of the low-variance dataset is compared to the high-variance dataset). Make sure to use an appropriate contrast-vector!
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement your ToDo here</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_lowvar_vs_highvar_iq_design</span>
<span class="n">test_lowvar_vs_highvar_iq_design</span><span class="p">(</span><span class="n">X_lowvar</span><span class="p">,</span> <span class="n">X_highvar</span><span class="p">,</span> <span class="n">desvar_ratio</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
<b>ToDo</b> (1 point): Design efficiency (and design-variance) is a metric without a clear unit of measurement; herefore, efficiency (and design variance) should always be interpreted in relative terms. To show this, we are going to look at the weight-height example from last week, in which we used weight as a predictor for height. Now, we're going to rescale the predictor ('weight') such that it represents weight in <em>grams</em> instead of *kilos* (as was originally the case).
<p>Calculate efficiency for both the weight-in-kilos data (<tt>X_kilos</tt>) and the weight-in-grams data (<tt>X_grams</tt>). Store the efficiency for the weight-in-kilos data in a variable named <tt>efficiency_kilos</tt> and the efficiency for the weight-in-grams data in a variable named <tt>efficiency_grams</tt>.</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">np</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;weight_height_data.npz&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">data</span><span class="p">:</span>
    <span class="n">X_kilos</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span>
    <span class="n">X_grams</span> <span class="o">=</span> <span class="n">X_kilos</span> <span class="o">*</span> <span class="mi">1000</span>
    
    <span class="c1"># We&#39;ll stack an intercept for you!</span>
    <span class="n">intercept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">X_kilos</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">X_kilos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">intercept</span><span class="p">,</span> <span class="n">X_kilos</span><span class="p">))</span>
    <span class="n">X_grams</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">intercept</span><span class="p">,</span> <span class="n">X_grams</span><span class="p">))</span>

<span class="c1"># Start your ToDo here</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_design_variance_scaling</span>
<span class="n">test_design_variance_scaling</span><span class="p">(</span><span class="n">X_kilos</span><span class="p">,</span> <span class="n">X_grams</span><span class="p">,</span> <span class="n">efficiency_kilos</span><span class="p">,</span> <span class="n">efficiency_grams</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
<b>ToThink</b> (1 point): If you've done the above ToDo correctly, you should see that (everything else being equal) the design with weight in grams is a 1,000,000 times more efficient than the design with weight in kilos.
<p>Why is the efficiency a million times higher and not 1000 times higher (as the scale-difference would suggest)?</p>
</div><p>YOUR ANSWER HERE</p>
</div>
</div>
<div class="section" id="the-effect-of-predictor-covariance-on-design-variance-efficiency">
<h2>The effect of predictor covariance on design variance/efficiency<a class="headerlink" href="#the-effect-of-predictor-covariance-on-design-variance-efficiency" title="Permalink to this headline">#</a></h2>
<div class="section" id="multicollinearity">
<h3>Multicollinearity<a class="headerlink" href="#multicollinearity" title="Permalink to this headline">#</a></h3>
<p>In the previous section, we discussed the influence of predictor variance - <span class="math notranslate nohighlight">\(\mathrm{var}[\mathbf{X}_{j}]\)</span> - on the design-variance term, showing that high variance leads to (relatively) low design variance (and thus high efficiency).</p>
<p>We know, however, that design variance <em>also</em> depends on the <em>covariance</em> between predictors - <span class="math notranslate nohighlight">\(\mathrm{cov}[\mathbf{X}_{j}, \mathbf{X}_{k}]\)</span>. This “covariance between predictors” is also known as <strong>multicollinearity</strong>.</p>
<p>Specifically, the <strong>higher</strong> the covariance (multicollinearity), the <strong>lower</strong> the design efficiency (the worse our design is). Conceptually, you can think of high covariance between predictors as causing <em>uncertainty</em> of the estimation of your beta-estimates: if your predictors are correlated, the GLM “doesn’t know” what (de)activation it should assign to which predictor. This uncertainty due to correlated predictors is reflected in a (relatively) higher design variance term.</p>
<p>Anyway, let’s look at some (simulated) data. This time (unlike the variance-example), we’re going to look at fMRI timeseries data. We’ll simulate a design with two predictors, we’ll calculate the correlation between the two predictors, and the efficiency of the design for the difference contrast between the predictors (<code class="docutils literal notranslate"><span class="pre">c</span> <span class="pre">=</span> <span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">-1]</span></code>).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_two_predictors</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">360</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">TR</span><span class="o">=</span><span class="mi">2</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39; Simulates two predictors with evenly spaced trials,</span>
<span class="sd">    shifted a given number of time-points. &#39;&#39;&#39;</span>
    
    <span class="n">offset</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">stop</span> <span class="o">=</span> <span class="mi">300</span>
    <span class="n">space</span> <span class="o">=</span> <span class="mi">60</span>
    <span class="n">pred1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">pred1</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span><span class="n">stop</span><span class="p">:</span><span class="n">space</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">pred2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
    <span class="n">pred2</span><span class="p">[(</span><span class="n">offset</span> <span class="o">+</span> <span class="n">shift</span><span class="p">):</span><span class="n">stop</span><span class="p">:</span><span class="n">space</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

    <span class="n">hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">hrf</span> <span class="o">/=</span> <span class="n">hrf</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
    <span class="n">pred1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">pred1</span><span class="p">,</span> <span class="n">hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">TR</span><span class="p">)]</span>
    <span class="n">pred2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">pred2</span><span class="p">,</span> <span class="n">hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">:</span><span class="nb">int</span><span class="p">(</span><span class="n">TR</span><span class="p">)]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">pred1</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">pred2</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]))</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># We set the &quot;shift&quot; (distance between predictor 1 and 2 to 30 seconds)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">simulate_two_predictors</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">TR</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">cvec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">corr</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">eff</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">cvec</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">cvec</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;Corr predictors: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">corr</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s1">&#39;Efficiency: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">eff</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">175</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Predictor 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Predictor 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (volumes)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Activation (A.U.)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Almost no collinearity&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance predictor 1: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance predictor 2: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_68_0.png" src="../../_images/design_of_experiments_68_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance predictor 1: 0.048
Variance predictor 2: 0.048
</pre></div>
</div>
</div>
</div>
<p>As you can see, the predictors are almost perfectly uncorrelated - <span class="math notranslate nohighlight">\(\mathrm{corr}(\mathbf{X}_{1}, \mathbf{X}_{2}) \approx 0\)</span> - which corresponds to a design efficiency of 4.539. Remember, the absolute value of efficiency is not interpretable, but we can interpret it <em>relative to other designs</em>. As such, we can investigate how a design with more correlated predictors will change in terms of efficiency.</p>
<p>To do so, we can simply “shift” the second predictor (blue line) to the left (i.e., the stimuli of predictor 2 follow the stimuli of predictor 1 more quickly). Let’s check out what happens to the efficiency if we induce corelation this way:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We set shift to 4 seconds (instead of 30 like before)</span>
<span class="n">X2</span> <span class="o">=</span> <span class="n">simulate_two_predictors</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">TR</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">corr2</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">eff2</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="n">cvec</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X2</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">cvec</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">,</span> <span class="s1">&#39;Corr predictors: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">corr2</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">text</span><span class="p">(</span><span class="mi">150</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">,</span> <span class="s1">&#39;Efficiency: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span> <span class="n">eff2</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">175</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Predictor 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Predictor 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (volumes)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Activation (A.U.)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Quite a bit of collinearity&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance predictor 1: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Variance predictor 2: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">np</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_70_0.png" src="../../_images/design_of_experiments_70_0.png" />
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Variance predictor 1: 0.048
Variance predictor 2: 0.048
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Let&#39;s calculate the reduction in efficiency</span>
<span class="n">reduction_eff</span> <span class="o">=</span> <span class="p">((</span><span class="n">eff</span> <span class="o">-</span> <span class="n">eff2</span><span class="p">)</span> <span class="o">/</span> <span class="n">eff</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Efficiency is reduced with </span><span class="si">%.1f%%</span><span class="s2"> when increasing the correlation to </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">reduction_eff</span><span class="p">,</span> <span class="n">corr2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Efficiency is reduced with 71.8% when increasing the correlation to 0.703
</pre></div>
</div>
</div>
</div>
<p>As you can see, increasing correlation between predictors has the effect of reducing efficiency, even if the predictor variance stays the same! Like we discussed earlier, this is because correlation between predictors reflects <em>ambiguity</em> about the “source” of an effect.</p>
<p>To get a better intuition of this ambiguity, suppose that for the above design (with the correlated predictors), we observe the following signal (we just simulate the signal as the linear sum of the predictors + noise; sort of a “reverse linear regression”):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Here we simulate a signal based on the predictors + noise</span>
<span class="n">some_noise</span> <span class="o">=</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">,</span> <span class="n">X2</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
<span class="n">sim_signal</span> <span class="o">=</span> <span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span> <span class="o">+</span> <span class="n">X2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span>  <span class="o">+</span> <span class="n">some_noise</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X2</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">sim_signal</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">175</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Predictor 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Predictor 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Signal&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper right&#39;</span><span class="p">,</span> <span class="n">frameon</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (volumes)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Activation (A.U.)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Simulated data + multicollinear predictors&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_73_0.png" src="../../_images/design_of_experiments_73_0.png" />
</div>
</div>
<p>Now, if we calculate the beta-parameters of both predictors, we see that they both are given approximately equal “importance” (i.e., their beta-parameters are about equally high):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">betas</span> <span class="o">=</span> <span class="n">inv</span><span class="p">(</span><span class="n">X2</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X2</span><span class="p">)</span> <span class="o">@</span> <span class="n">X2</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">sim_signal</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Betas (w/o intercept): </span><span class="si">%r</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">betas</span><span class="p">[</span><span class="mi">1</span><span class="p">:])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Betas (w/o intercept): array([1.92571203, 1.84414847])
</pre></div>
</div>
</div>
</div>
<p>However, it is unclear to the GLM whether the peaks in the signal (green line) are caused by predictor 1 or predictor 2! While the betas themselves are not affected on average (i.e., there is no <em>bias</em>), this “uncertainty” (or “ambiguity”) is reflected in the GLM through a relatively higher design variance term, that will subsequently lead to (relatively) lower <em>t</em>-values!</p>
<div class='alert alert-info'>
<b>ToThink</b> (1 point): Suppose that due to a mistake in your experimental paradigm, you actually present the two classes of stimuli (reflecting predictor 1 and predictor 2 in the above example) at the same time (blue and orange predictors completely overlap). As it turns out, you cannot (reliably) calculate the design variance for such a design. Explain concisely why this is the case.
</div><p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="evaluating-multiple-contrasts">
<h3>Evaluating multiple contrasts<a class="headerlink" href="#evaluating-multiple-contrasts" title="Permalink to this headline">#</a></h3>
<p>Thus far, we only evaluated the efficiency for a <em>single</em> contrast, like one particular predictor against baseline, e.g. <code class="docutils literal notranslate"><span class="pre">contrast_vec</span> <span class="pre">=</span> <span class="pre">np.array([0,</span> <span class="pre">1,</span> <span class="pre">0])</span></code>. Often, though, you might be interested in <em>more than one contrast</em>. For example, you might be interested in the contrast of predictor “A” against baseline, predictor “B” against baseline, and the difference between predictor “A” and “B”*. We can simply extend our formula for efficiency to allow more than one contrast. For <span class="math notranslate nohighlight">\(K\)</span> contrasts, efficiency is defined as:</p>
<div class="amsmath math notranslate nohighlight" id="equation-f50bb5b7-7e3b-4178-bdd6-ef3b5a78b10c">
<span class="eqno">(45)<a class="headerlink" href="#equation-f50bb5b7-7e3b-4178-bdd6-ef3b5a78b10c" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathrm{efficiency} = \frac{K}{\sum_{k=1}^{K} \mathbf{c}_{k}(\mathbf{X}^{T}\mathbf{X})^{-1}\mathbf{c}_{k}^{T}}
\end{align}\]</div>
<p>This specific calculation of efficiency is also referred to as “A optimality”. From the formula, you can see that the overall efficiency for multiple contrasts is basically (but not precisely) the “average” of the efficiencies for the individual contrasts.</p>
<p>Let’s practice the Python-implementation of overall efficiency for multiple contrasts in a short assignment (graded with hidden tests).</p>
<hr class="docutils" />
<p>* Note that evaluating different contrasts separately is not the same as doing an F-test (like we discussed in week 2)!</p>
<div class='alert alert-warning'>
<b>ToDo</b> (1 point):
With the data from the correlation-simulation (i.e., the variable <tt>X</tt>), calculate the efficiency for the set of the following contrasts:
<ul class="simple">
<li><p>predictor 1 against baseline</p></li>
<li><p>predictor 2 against baseline</p></li>
<li><p>prediction 1 - predictor 2</p></li>
</ul>
<p>You have to define the contrasts yourself.</p>
<p>Store the overall efficiency in a variable named <tt>overall_eff</tt>. Hint: you probably need a for loop (or a list comprehension).</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement your ToDo here using X</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">simulate_two_predictors</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">350</span><span class="p">,</span> <span class="n">shift</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">TR</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_overall_eff</span>
<span class="n">test_overall_eff</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">overall_eff</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="how-should-we-design-our-experiment-to-maximize-efficiency">
<h2>How should we design our experiment to maximize efficiency?<a class="headerlink" href="#how-should-we-design-our-experiment-to-maximize-efficiency" title="Permalink to this headline">#</a></h2>
<p>Alright, thus far we talked about <strong>why</strong> you want high predictor variance and low predictor covariance for optimal estimation of effects (i.e., t-values). But this leaves us with the question: <strong>how</strong> should we design our experiment such that it has high variance and low covariance?</p>
<p>The answer is (as is often the case): it depends.</p>
<div class="section" id="estimation-vs-detection">
<h3>Estimation vs. detection<a class="headerlink" href="#estimation-vs-detection" title="Permalink to this headline">#</a></h3>
<p>The specific design of your experiment (how the stimuli are ordered and their timing) mainly depends on the <em>type of question</em> you’re investigating with your fMRI experiment. These types of questions are usually divided into two categories within (univariate) fMRI studies:</p>
<p><strong>1) You want to know whether different conditions activate voxel activity differently.</strong></p>
<p>We’ve learned how to do this in week 2: essentially, you want to estimate just a beta-parameter (reflecting activation/deactivation) of your stimulus-regressors. This is a question about HRF-<em>amplitude</em> only. The far majority of fMRI research falls in this category (and it’s the type we’ll focus on in this course). It is often said that this type of research focuses on <strong>detection</strong> of a signal’s response. For this question, designs are often based on canonical HRF-based convolution (or based on a basis set).</p>
<p><strong>2) You want investigate how different conditions influence voxel activity not only by investigating the “amplitude” parameter of the HRF, but also parameters relating to other properties of the shape of the HRF (like width, lag, strenght of undershoot, etc.).</strong></p>
<p>A small proportion of fMRI studies have this goal. Examples are studies that investigate <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1053811907010877">how the shape of the HRF changes with age</a> or that investigate <a class="reference external" href="http://www.sciencedirect.com/science/article/pii/S1053811907001371">differences in HRF shape across clinical populations</a>. We won’t focus on this type of research in this course, but you should know that you can also investigate other parameters of the HRF in neuroimaging research! It if often said that this type of research focuses on <strong>estimation</strong> of the (shape of the) signal’s response. Often, “finite impulse reponse” (FIR) models are used for these types of studies (which you might have seen in the videos).</p>
<p>The far majority of the fMRI studies focus on questions about <strong>detection</strong>, i.e., based on analysis of the “amplitude” of the HRF. This is why we won’t discuss the estimation approach (and associated models, like the FIR-based GLM) in the rest of this lab and the course in general.</p>
<p>Now, given that we aim for detection, how should we design our experiment? Well, there are two “main” types of designs: event-related designs and blocked designs, which are discussed in the next section.</p>
</div>
<div class="section" id="event-related-vs-blocked-designs">
<h3>Event-related vs. blocked designs<a class="headerlink" href="#event-related-vs-blocked-designs" title="Permalink to this headline">#</a></h3>
<p>As you’ve probably read in the book or seen in the videos, event-related and blocked designs differ in the <em>ordering</em> of the stimuli. Basically, event-related designs are designs in which the stimuli from different conditions are ordered randomly, while blocked designs are designs in which the stimuli of the same condition are grouped together in “blocks”. Below, we visualized an example of each design side-by-side:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">180</span>
<span class="n">dg_hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

<span class="n">blocked_pred1_onsets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">30</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">90</span><span class="p">,</span> <span class="mi">110</span><span class="p">))</span>
<span class="n">blocked_pred2_onsets</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="mi">70</span><span class="p">))</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">130</span><span class="p">,</span> <span class="mi">150</span><span class="p">))</span>
<span class="n">N_stim</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">blocked_pred1_onsets</span><span class="p">)</span>
<span class="n">blocked_pred1</span><span class="p">,</span> <span class="n">blocked_pred2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">blocked_pred1</span><span class="p">[</span><span class="n">blocked_pred1_onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">blocked_pred2</span><span class="p">[</span><span class="n">blocked_pred2_onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">icept</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">X_blocked</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
    <span class="n">icept</span><span class="p">,</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">blocked_pred1</span><span class="p">,</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">blocked_pred2</span><span class="p">,</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Event onsets (BLOCKED)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="k">for</span> <span class="n">onset</span> <span class="ow">in</span> <span class="n">blocked_pred1_onsets</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">onset</span><span class="p">,</span> <span class="n">onset</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">onset</span> <span class="ow">in</span> <span class="n">blocked_pred2_onsets</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">onset</span><span class="p">,</span> <span class="n">onset</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">)</span>
    
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Convolved predictors (BLOCKED)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_blocked</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_blocked</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (volumes)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">er_stims</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">er_pred1_onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">er_stims</span><span class="p">,</span> <span class="n">N_stim</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">er_stims_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">o</span> <span class="k">for</span> <span class="n">o</span> <span class="ow">in</span> <span class="n">er_stims</span> <span class="k">if</span> <span class="n">o</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">er_pred1_onsets</span><span class="p">])</span>
<span class="n">er_pred2_onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">er_stims_new</span><span class="p">,</span> <span class="n">N_stim</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">er_pred1</span><span class="p">,</span> <span class="n">er_pred2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">N</span><span class="p">)</span>
<span class="n">er_pred1</span><span class="p">[</span><span class="n">er_pred1_onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">er_pred2</span><span class="p">[</span><span class="n">er_pred2_onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Event onsets (EVENT-RELATED)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="k">for</span> <span class="n">onset</span> <span class="ow">in</span> <span class="n">er_pred1_onsets</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">onset</span><span class="p">,</span> <span class="n">onset</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">onset</span> <span class="ow">in</span> <span class="n">er_pred2_onsets</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">((</span><span class="n">onset</span><span class="p">,</span> <span class="n">onset</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">)</span>

<span class="n">X_er</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
    <span class="n">icept</span><span class="p">,</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">er_pred1</span><span class="p">,</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span>
    <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">er_pred2</span><span class="p">,</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Convolved predictors (EVENT-RELATED)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_er</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:blue&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_er</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;tab:orange&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">ls</span><span class="o">=</span><span class="s1">&#39;--&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (volumes)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_86_0.png" src="../../_images/design_of_experiments_86_0.png" />
</div>
</div>
<p>As you can see in the plot above, a blocked design groups trials of the same condition together in blocks, while the event-related design is completely random in the sequence of trials. Note that designs can of course also be a “mixture” between blocked and event-related (e.g., largely random with some “blocks” in between).</p>
<p>So, if we’re interested in detection (i.e., the amplitude of the response), what should we choose?
Well, the answer is simple: <strong>blocked designs</strong>.</p>
<p>This is because blocked designs simply (almost always) have lower design variance because of:</p>
<ul class="simple">
<li><p>lower covariance (“correlation”)</p></li>
<li><p>higher variance (“spread”)</p></li>
</ul>
<p>Let’s check this for the designs from the plot. First, we’ll look at the predictor covariance, but because predictor correlation is often more interpretable (correlation = standardized covariance), we’ll calculate that instead:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_blocked</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X_blocked</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_blocked</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">corr_er</span> <span class="o">=</span> <span class="n">pearsonr</span><span class="p">(</span><span class="n">X_er</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_er</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Correlation blocked: </span><span class="si">%.3f</span><span class="s2">. Correlation event-related: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">corr_blocked</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">corr_er</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Correlation blocked: -0.238. Correlation event-related: -0.268
</pre></div>
</div>
</div>
</div>
<div class='alert alert-warning'>
<b>ToDo</b> (1 point):
<p>We’ve seen that predictor correlation is lower in blocked designs than in event-related designs. But what about predictor variance? Calculate predictor variance for predictor 1 (column 2) and predictor 2 (column 3) for both the blocked design (<tt>X_blocked</tt>) and the event-related design (<tt>X_er</tt>).</p>
<p>Remember: (sample) variance is the summed squared deviation of values from a variable’s mean divided by the number of observations minus 1, or formally:</p>
<div class="amsmath math notranslate nohighlight" id="equation-9cf38ada-d006-4fcb-a664-9ba428c7ae87">
<span class="eqno">(46)<a class="headerlink" href="#equation-9cf38ada-d006-4fcb-a664-9ba428c7ae87" title="Permalink to this equation">#</a></span>\[\begin{align}
\mathbf{var}[x] = \frac{1}{N - 1}\sum_{i=1}^{N}(x - \bar{x})^{2}
\end{align}\]</div>
<p>Store the variance of the four predictors (2 predictions <span class="math notranslate nohighlight">\(\times\)</span> 2 designs) in the following variables:</p>
<ul class="simple">
<li><p><tt>blocked_pred1_var</tt></p></li>
<li><p><tt>blocked_pred2_var</tt></p></li>
<li><p><tt>er_pred1_var</tt></p></li>
<li><p><tt>er_pred2_var</tt></p></li>
</ul>
<p>Note: do <strong>not</strong> use the numpy function <tt>np.var</tt> for this ToDo (also because it’s going to give you the wrong answer).</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Implement your ToDo here</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="sd">&#39;&#39;&#39; Tests the above ToDo. &#39;&#39;&#39;</span>
<span class="kn">from</span> <span class="nn">niedu.tests.nii.week_3</span> <span class="kn">import</span> <span class="n">test_variance_computation</span>    
<span class="n">test_variance_computation</span><span class="p">(</span><span class="n">X_blocked</span><span class="p">,</span> <span class="n">X_er</span><span class="p">,</span> <span class="n">blocked_pred1_var</span><span class="p">,</span> <span class="n">blocked_pred2_var</span><span class="p">,</span> <span class="n">er_pred1_var</span><span class="p">,</span> <span class="n">er_pred2_var</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class='alert alert-info'>
<b>ToThink</b> (1 point): One property/characteristic (or assumption) of the BOLD-response is especially important in generating high predictor variance, which becomes especially clear in blocked designs. Which property is this? Write your answer in the cell below.
</div><p>YOUR ANSWER HERE</p>
<div class='alert alert-warning'>
<b>ToDo/ToThink</b> (2 points)
<p>As you’ve seen in the previous ToDo, blocked designs have larger predictor variance and (everything else being equal) are more efficient. In fact, up to a certain point, the larger the blocks of trials, the more efficient the design. This may, at first sight, reflect idea in most psychological research that more trials (events) lead to more power.</p>
<p>In fMRI designs, however, this is <em>not</em> the case, because at a certain point, longer blocks yield a <em>less</em> efficient design. Below, we define a function that simulates a single predictor for a blocked-design with a variable amount of trials in it (for a fixed experiment duration of 500 seconds and a TR of 1). So, for example, if we call the function with <tt>trials=10</tt>, it will create a design and predictor with a block of 10 consecutive stimuli (all lasting a second). We’ll also plot the predictor after simulating the data.</p>
<p>Now, suppose I would like to evaluate the contrast of that single predictor against baseline. In the text-cell below, argue why adding more trials does not necessarily mean a more efficient design, assuming some fixed length of the experiment.</p>
<p>Hint: set the number of trials very high (e.g. <tt>N_TRIALS = 500</tt>) and see what happens with the predictor.<br></p>
</div><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_single_predictor</span><span class="p">(</span><span class="n">trials</span><span class="p">,</span> <span class="n">time_exp</span><span class="o">=</span><span class="mi">500</span><span class="p">):</span>

    <span class="k">if</span> <span class="n">trials</span> <span class="o">&gt;</span> <span class="n">time_exp</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Cannot have more trials than timepoints!&quot;</span><span class="p">)</span>

    <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">time_exp</span><span class="p">)</span>
    <span class="n">onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span> 
    <span class="n">pred</span><span class="p">[</span><span class="n">onsets</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">dg</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">pred_conv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">dg</span><span class="p">)[:</span><span class="n">time_exp</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">time_exp</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">pred_conv</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">X</span>

<span class="c1"># We&#39;ll call the function above here:</span>
<span class="n">contrast</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>

<span class="c1"># you can change this variable to investigate the effect of increasing/decreasing the amount of trials</span>
<span class="n">N_TRIALS</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">simulate_single_predictor</span><span class="p">(</span><span class="n">trials</span><span class="o">=</span><span class="n">N_TRIALS</span><span class="p">)</span>

<span class="c1"># ... and plot the predictor</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">500</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Simulated design/predictor with </span><span class="si">%i</span><span class="s2"> trials&quot;</span> <span class="o">%</span> <span class="n">N_TRIALS</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Time (seconds/volumes)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Activation (A.U.)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_95_0.png" src="../../_images/design_of_experiments_95_0.png" />
</div>
</div>
<p>YOUR ANSWER HERE</p>
</div>
<div class="section" id="the-paradox-of-efficiency">
<h3>The “paradox” of efficiency<a class="headerlink" href="#the-paradox-of-efficiency" title="Permalink to this headline">#</a></h3>
<p>So, we’ve discussed blocked and event-related designs and we’ve come to the conclusion that blocked designs are simply more efficient than event-related designs. “So, we should always use blocked designs?”, you may ask.</p>
<p>Well, no.</p>
<p>We’ve discussed the mathematics behind design variance, efficiency, and t-value in detail, but we shouldn’t forget that ultimately <strong>we’re measuring the data from a living human beings in the MRI-scanner</strong>, who tend to get bored, fall asleep, and otherwise not pay attention if the task they’re doing is monotonous, predictable or simply uninteresting!</p>
<p>Blocked designs, however, are (usually) exactly this: designs that are experienced as predictable, monotonous, and (relatively) boring! Like we said earlier, the effects we’re going to measure depend on three things - effects, noise, and design efficiency - and psychological factors may strongly influence the “effect” part and thus affect the statistics we’re interested in (i.e., t-values). In addition to psychological factors like boredom and inattention, blocked designs may also lead to unwanted effects like habituation (attenuation of the BOLD-response after repeated stimulation), which violate the assumption of the BOLD-response as being ‘linear time-invariant’ (LTI). In other words, the BOLD-response may stop ‘behaving’ like we assume it behaves when we use blocked designs.</p>
<p>This is, essentially, the paradox of designing fMRI experiments: the most efficient designs are also the designs that (potentially) lead to the lowest signal or otherwise unintended effects (due to boredom, predictability, habituation, etc.).</p>
<p>So, what do we do in practice? Usually, we use (semi-random) event-related designs. We lose some efficiency by using event-related designs instead of blocked designs, but we reduce the chance of psychological factors and other effects that reduce the measured signal or mess with the assumption of linear time-invariance.</p>
<p>Given that we’re going to use some event-related (i.e., “random”) design, let’s investigate how we can optimize this type of design.</p>
</div>
<div class="section" id="improving-design-efficiency-for-event-related-designs-using-jittering">
<h3>Improving design efficiency for event-related designs using jittering<a class="headerlink" href="#improving-design-efficiency-for-event-related-designs-using-jittering" title="Permalink to this headline">#</a></h3>
<p>Usually, events in an experimental design are separated by short periods without any event; this is called the “inter-stimulus interval” (ISI; also called stimulus onset asynchrony, SOA) - the time between successive stimuli. For example, the experiment from the image below has an ISI of 8 seconds:</p>
<p><img alt="img" src="https://docs.google.com/drawings/d/e/2PACX-1vQwC4chpnzsDEzKhrKH_WHhMX7vJswY4H0pkyIxdlxI_I2GG5e8i6lsiWUO0SUk7NBgdV-vXD5PIleJ/pub?w=950&amp;h=397" /></p>
<p>Let’s simulate some event-onsets and predictors for this experiment. We have two predictors (circles and squares). The stimuli (‘events’) take 1 second and the ISI is 8 seconds (like the figure above). Suppose we’re interested in both contrasts against baseline (circles against baseline; squares against baseline).</p>
<p>Now, let’s simulate one design (with a fixed ISI), calculate efficiency and plot it:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_data_fixed_ISI</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">420</span><span class="p">):</span>

    <span class="n">dg_hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="c1"># Create indices in regularly spaced intervals (9 seconds, i.e. 1 sec stim + 8 ISI)</span>
    <span class="n">stim_onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
    <span class="n">stimcodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">stim_onsets</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>  <span class="c1"># create codes for two conditions</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">stimcodes</span><span class="p">)</span>  <span class="c1"># random shuffle</span>
    <span class="n">stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="c1"># Fill stim array with codes at onsets</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">stim_onset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stim_onsets</span><span class="p">):</span>
        <span class="n">stim</span><span class="p">[</span><span class="n">stim_onset</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">stimcodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">2</span>
    
    <span class="n">stims_A</span> <span class="o">=</span> <span class="p">(</span><span class="n">stim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">stims_B</span> <span class="o">=</span> <span class="p">(</span><span class="n">stim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">reg_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">stims_A</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>
    <span class="n">reg_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">stims_B</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">reg_B</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">reg_A</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">reg_B</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]))</span>
    <span class="n">dvars</span> <span class="o">=</span> <span class="p">[(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">eff</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dvars</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">eff</span>

<span class="n">X</span><span class="p">,</span> <span class="n">eff</span> <span class="o">=</span> <span class="n">simulate_data_fixed_ISI</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>    
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Fixed ISI of 8 seconds (Efficiency = </span><span class="si">%.3f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">eff</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Predictor A&#39;</span><span class="p">,</span> <span class="s1">&#39;Predictor B&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amplitude (a.u.)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (TR)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_100_0.png" src="../../_images/design_of_experiments_100_0.png" />
</div>
</div>
<p>Often, though, researchers do not use a <em>fixed</em> ISI, but they vary the ISI from trial to trial. This process is called “jittering”. Usually, the ISIs are drawn randomly from a known distribution (e.g., truncated exponential or normal distribution). Compared to using fixed ISIs, jittering may yield more efficient designs by reducing covariance and increasing predictor variance. Let’s simulate another dataset, but this time with a variable ISI between 2-6 seconds (which is on average 4 seconds, but variable across trials):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">simulate_data_jittered_ISI</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">420</span><span class="p">):</span>
    
    <span class="n">dg_hrf</span> <span class="o">=</span> <span class="n">glover_hrf</span><span class="p">(</span><span class="n">tr</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">oversampling</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    
    <span class="n">stim_onsets</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="n">N</span> <span class="o">-</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
    <span class="n">stimcodes</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">stim_onsets</span><span class="o">.</span><span class="n">size</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">stimcodes</span><span class="p">)</span>

    <span class="c1"># Here, we pick some *deviations* from the standard ISI (i.e., 8),</span>
    <span class="c1"># so possible ISIs are (8 - 2, 8 - 1, 8 - 0, 8 + 1, 8 + 2)</span>
    <span class="n">ISIs</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">repeat</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">repeats</span><span class="o">=</span><span class="mi">11</span><span class="p">)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">ISIs</span><span class="p">)</span>
    
    <span class="n">stim</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">N</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">stim_onset</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">stim_onsets</span><span class="p">):</span>
        <span class="c1"># We subtract the stim-onset with -2, -1, 0, 1, or 2 (from ISIs)</span>
        <span class="c1"># to simulate jittering</span>
        <span class="n">stim</span><span class="p">[</span><span class="n">stim_onset</span> <span class="o">-</span> <span class="n">ISIs</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span> <span class="o">=</span> <span class="mi">1</span> <span class="k">if</span> <span class="n">stimcodes</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">==</span> <span class="mi">1</span> <span class="k">else</span> <span class="mi">2</span>
        
    <span class="n">stims_A</span> <span class="o">=</span> <span class="p">(</span><span class="n">stim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">stims_B</span> <span class="o">=</span> <span class="p">(</span><span class="n">stim</span> <span class="o">==</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>
    <span class="n">reg_A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">stims_A</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>
    <span class="n">reg_B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">convolve</span><span class="p">(</span><span class="n">stims_B</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(),</span> <span class="n">dg_hrf</span><span class="p">)[:</span><span class="n">N</span><span class="p">]</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="n">reg_B</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">reg_A</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">],</span> <span class="n">reg_B</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]))</span>

    <span class="c1"># Loop over the two contrasts</span>
    <span class="n">dvars</span> <span class="o">=</span> <span class="p">[(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span><span class="o">.</span><span class="n">T</span><span class="p">))</span>
             <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])]</span>
    <span class="n">eff</span> <span class="o">=</span> <span class="n">c</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dvars</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">eff</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>    
<span class="n">X</span><span class="p">,</span> <span class="n">eff</span> <span class="o">=</span> <span class="n">simulate_data_jittered_ISI</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Variable (jittered) ISI of 2-6 seconds (Efficiency = </span><span class="si">%.3f</span><span class="s1">)&#39;</span> <span class="o">%</span> <span class="n">eff</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Predictor A&#39;</span><span class="p">,</span> <span class="s1">&#39;Predictor B&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Amplitude (a.u.)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Time (TR)&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">N</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/design_of_experiments_102_0.png" src="../../_images/design_of_experiments_102_0.png" />
</div>
</div>
<p>As you can see in the plot above, jittering improved design efficiency quite a bit! It is important to realize that jittering does not <em>always</em> improve design efficiency, but by “injecting” randomness (by selecting semi-random ISIs) it allows for <em>a larger variety</em> of designs, which also include designs that happen to be more efficient than the fixed-ISI designs.</p>
<p>You’ll follow up on this idea in the next ToDo.</p>
<div class='alert alert-warning'>
<b>ToDo</b> (3 points)
<p>In the previous two examples (fixed-ISI and jittered ISI examples), we saw that the fixed-ISI design was less efficient than the jittered ISI design. In general, jittering increases the number of different designs you can simulate relative to fixed-ISI designs. A great way to visualize this is to simply run the simulation of fixed-ISI and jittered-ISI designs a number of times and plot the resulting efficiencies in two separate histograms. You should see that the histogram of efficiencies from fixed-ISI designs is quite a bit narrower than the histogram of efficiencies from jittered-ISI designs (but you might also also see that some jittered-ISI designs are <em>less</em> efficient that the average fixed-ISI design).</p>
<p>So, in this ToDo you will have to call the two simulation-functions (<tt>simulate_data_jittered_ISI</tt> and <tt>simulate_data_fixed_ISI</tt>) each 1000 times (use <tt>N=420</tt>, the default value) and keep track of the efficiency from both. Then, plot in <em>a single plot</em>, the histogram (using <tt>plt.hist</tt>) of the fixed-ISI efficiencies and the histogram of the jittered-ISI efficiencies. To plot two different histograms in a single plot, just call <tt>plt.hist</tt> twice (<em>before</em> calling <tt>plt.show</tt>); it will plot both histograms in the same plot.</p>
<p>Also, add a legend (showing which histogram refers to which efficiencies), give a sensible label to the x-axis and y-axis (if you don’t know what the axes of a histogram refer to, look it up!), and give the plot a descriptive title.</p>
<p>So, in summary, you have to do the following:</p>
<ul class="simple">
<li><p>run the two functions 1000 times each</p></li>
<li><p>with the resulting efficiency values (1000 for the fixed-ISI simulation function, and 1000 for the jittered-ISI simulation function), plot a histogram of the fixed-ISI efficiencies and a histogram of the jittered-ISI efficiencies in a single plot</p></li>
<li><p>add a legend, labels for the axes, and a title</p></li>
</ul>
<p>Hint: the functions output two things (the design and the efficiency); you only need the efficiency (second output)</p>
<p>This assignment is manually graded (no test-cell).</p>
</div><div class="cell tag_raises-exception tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># implement your ToDo here</span>
<span class="n">iterations</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="c1"># YOUR CODE HERE</span>
<span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="summary-how-to-optimize-your-design-for-efficiency">
<h3>Summary: how to optimize your design for efficiency<a class="headerlink" href="#summary-how-to-optimize-your-design-for-efficiency" title="Permalink to this headline">#</a></h3>
<p>So, in this section we discussed how to structure your experiment such that it yields a (relatively) high design efficiency, which will optimize our chance to find significant effects. How you do this depends on whether you aim for estimation (what is the shape of the HRF?) or for detection (what is the amplitude of the response?). Usually, we aim for detection; in that case, designs can be roughly grouped in two types: blocked designs an event-related designs. Purely statistically speaking, blocked designs are (almost always) more efficient, because they generally have lower covariance and higher variance than event-related designs. However, due to psychological factors and potential violations of the linear time-invariance of the BOLD-response, we often opt for event-related designs in the end. For event-related designs, we can increase our chance of finding a relatively efficient design by jittering our ISIs.</p>
<div class='alert alert-success'>
    <b>Tip!</b>
    Before handing in your notebooks, we recommend restarting your kernel (<em>Kernel</em> &rarr; <em>Restart & Clear Ouput</em>) and running all your cells again (manually, or by <em>Cell</em> &rarr; <em>Run all</em>). By running all your cells one by one (from "top" to "bottom" of the notebook), you may spot potential errors that are caused by accidentally overwriting your variables or running your cells out of order (e.g., defining the variable 'x' in cell 28 which you then use in cell 15).
</div></div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./fMRI-introduction/week_3"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../section_intros/3_design_of_experiments_T.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Design of experiments</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="neurodesign.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Neurodesign (tutorial)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Lukas Snoek<br/>
  
      &copy; Copyright 2021.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>